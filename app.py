if dates.isna().all():
            st.warning(f"Datas inv√°lidas em {title}")
            return None
        
        hoje = pd.Timestamp.now().normalize()
        aging_days = (hoje - dates).dt.days
        
        # Classifica√ß√£o de aging melhorada
        aging_ranges = [
            (0, 15, "0-15 dias", config.COLORS['success'], "Normal"),
            (16, 30, "16-30 dias", config.COLORS['info'], "Aten√ß√£o"),
            (31, 60, "31-60 dias", config.COLORS['warning'], "Preocupante"),
            (61, 90, "61-90 dias", config.COLORS['danger'], "Urgente"),
            (91, 180, "91-180 dias", "#8B0000", "Cr√≠tico"),
            (181, 365, "181-365 dias", "#4B0000", "Cr√≠tico Extremo"),
            (366, float('inf'), "> 365 dias", "#000000", "Emergencial")
        ]
        
        def classify_aging(days):
            for min_days, max_days, label, color, priority in aging_ranges:
                if min_days <= days <= max_days:
                    return label, color, priority
            return "Indefinido", "#808080", "Normal"
        
        # Aplicar classifica√ß√£o
        aging_classifications = aging_days.apply(
            lambda x: classify_aging(x) if pd.notna(x) else ("Indefinido", "#808080", "Normal")
        )
        
        df_analysis = df.copy()
        df_analysis["dias_pendentes"] = aging_days
        df_analysis["faixa_aging"] = [item[0] for item in aging_classifications]
        df_analysis["cor_aging"] = [item[1] for item in aging_classifications]
        df_analysis["prioridade"] = [item[2] for item in aging_classifications]
        
        # Estat√≠sticas detalhadas
        stats = {
            "total": len(df_analysis),
            "media_dias": float(aging_days.mean()) if not aging_days.empty else 0,
            "mediana_dias": float(aging_days.median()) if not aging_days.empty else 0,
            "max_dias": int(aging_days.max()) if not aging_days.empty else 0,
            "p75_dias": float(aging_days.quantile(0.75)) if not aging_days.empty else 0,
            "p90_dias": float(aging_days.quantile(0.9)) if not aging_days.empty else 0,
            "p95_dias": float(aging_days.quantile(0.95)) if not aging_days.empty else 0,
            "criticos": int((aging_days > config.BENCHMARKS['aging_critico']).sum()),
            "urgentes": int((aging_days > config.BENCHMARKS['aging_atencao']).sum()),
            "normais": int((aging_days <= 30).sum())
        }
        
        # Layout principal
        col1, col2, col3 = st.columns([0.4, 0.35, 0.25])
        
        with col1:
            st.markdown(f"#### üìä {title} - Distribui√ß√£o de Aging")
            
            # Distribui√ß√£o por faixa
            aging_dist = df_analysis["faixa_aging"].value_counts()
            aging_dist = aging_dist.reindex([
                label for _, _, label, _, _ in aging_ranges 
                if label in aging_dist.index
            ])
            
            # Cores correspondentes para o gr√°fico
            range_colors = {label: color for _, _, label, color, _ in aging_ranges}
            colors_for_plot = [range_colors.get(label, "#808080") for label in aging_dist.index]
            
            fig_aging = go.Figure(data=[
                go.Bar(
                    x=aging_dist.index,
                    y=aging_dist.values,
                    marker_color=colors_for_plot,
                    text=aging_dist.values,
                    textposition="outside"
                )
            ])
            
            fig_aging.update_layout(
                height=400,
                showlegend=False,
                xaxis_title="Faixa de Aging",
                yaxis_title="Quantidade",
                xaxis_tickangle=-45,
                plot_bgcolor='rgba(0,0,0,0)'
            )
            
            st.plotly_chart(fig_aging, use_container_width=True)
        
        with col2:
            st.markdown(f"#### üìà Estat√≠sticas de {title}")
            
            # Cards de estat√≠sticas principais
            stat_col1, stat_col2 = st.columns(2)
            
            with stat_col1:
                st.metric("üìã Total", format_number(stats["total"]))
                st.metric("üî¥ Cr√≠ticos", format_number(stats["criticos"]))
                st.metric("üìä M√©dia", f"{format_number(stats['media_dias'])} dias")
                st.metric("üìà P95", f"{format_number(stats['p95_dias'])} dias")
            
            with stat_col2:
                st.metric("‚è∞ M√°ximo", f"{format_number(stats['max_dias'])} dias")
                st.metric("üü° Urgentes", format_number(stats["urgentes"]))
                st.metric("üìä Mediana", f"{format_number(stats['mediana_dias'])} dias")
                st.metric("üìä P90", f"{format_number(stats['p90_dias'])} dias")
            
            # Indicador de sa√∫de geral
            if stats["total"] > 0:
                pct_criticos = (stats["criticos"] / stats["total"]) * 100
                pct_normais = (stats["normais"] / stats["total"]) * 100
                
                if pct_criticos > 30:
                    health_status = "üî¥ Cr√≠tica"
                    health_color = config.COLORS['danger']
                elif pct_criticos > 15:
                    health_status = "üü° Aten√ß√£o"
                    health_color = config.COLORS['warning']
                elif pct_normais > 60:
                    health_status = "üü¢ Saud√°vel"
                    health_color = config.COLORS['success']
                else:
                    health_status = "üü† Regular"
                    health_color = config.COLORS['warning']
                
                st.markdown(f"""
                <div style="background: {health_color}20; border: 2px solid {health_color}; 
                           border-radius: 12px; padding: 16px; text-align: center; margin-top: 16px;">
                    <strong>Sa√∫de Geral</strong><br>
                    <span style="font-size: 1.2em; color: {health_color};">{health_status}</span>
                </div>
                """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("#### üéØ Distribui√ß√£o por Prioridade")
            
            # Gr√°fico de pizza para prioridades
            priority_counts = df_analysis["prioridade"].value_counts()
            
            priority_colors = {
                "Normal": config.COLORS['success'],
                "Aten√ß√£o": config.COLORS['info'],
                "Preocupante": config.COLORS['warning'],
                "Urgente": config.COLORS['danger'],
                "Cr√≠tico": "#8B0000",
                "Cr√≠tico Extremo": "#4B0000",
                "Emergencial": "#000000"
            }
            
            fig_priority = go.Figure(data=[
                go.Pie(
                    labels=priority_counts.index,
                    values=priority_counts.values,
                    marker_colors=[priority_colors.get(label, "#808080") for label in priority_counts.index],
                    textinfo='label+percent',
                    textposition='inside'
                )
            ])
            
            fig_priority.update_layout(
                height=300,
                showlegend=False,
                margin=dict(t=20, b=20, l=20, r=20)
            )
            
            st.plotly_chart(fig_priority, use_container_width=True)
        
        # An√°lise por dimens√µes (se dispon√≠vel)
        if "unidade" in df_analysis.columns:
            st.markdown(f"#### üè¢ {title} por Unidade")
            
            unidade_aging = df_analysis.groupby("unidade").agg({
                "dias_pendentes": ["count", "mean", "max"],
                "prioridade": lambda x: (x.isin(["Cr√≠tico", "Cr√≠tico Extremo", "Emergencial"])).sum()
            }).round(1)
            
            unidade_aging.columns = ["Total", "M√©dia_Dias", "Max_Dias", "Casos_Cr√≠ticos"]
            unidade_aging = unidade_aging.sort_values("Casos_Cr√≠ticos", ascending=False).head(15)
            
            if not unidade_aging.empty:
                fig_unidade = px.bar(
                    unidade_aging.reset_index(),
                    x="unidade",
                    y="Casos_Cr√≠ticos",
                    color="M√©dia_Dias",
                    title=f"Top 15 Unidades - {title} Cr√≠ticos",
                    color_continuous_scale="Reds",
                    hover_data=["Total", "Max_Dias"]
                )
                
                fig_unidade.update_layout(
                    height=400,
                    xaxis_tickangle=-45,
                    plot_bgcolor='rgba(0,0,0,0)'
                )
                
                st.plotly_chart(fig_unidade, use_container_width=True)
        
        # Top casos mais antigos
        st.markdown(f"#### üî¥ Top 20 {title} Mais Antigos")
        oldest_cases = df_analysis.nlargest(20, "dias_pendentes")
        
        if not oldest_cases.empty:
            # Preparar colunas para exibi√ß√£o
            display_cols = []
            if "id" in oldest_cases.columns:
                display_cols.append("id")
            if "unidade" in oldest_cases.columns:
                display_cols.append("unidade")
            if "tipo" in oldest_cases.columns:
                display_cols.append("tipo")
            
            display_cols.extend(["dias_pendentes", "faixa_aging", "prioridade"])
            
            available_cols = [col for col in display_cols if col in oldest_cases.columns]
            
            if available_cols:
                # Aplicar cores baseadas na prioridade
                def color_priority(val):
                    if val in ["Cr√≠tico", "Cr√≠tico Extremo", "Emergencial"]:
                        return "background-color: #fee2e2"
                    elif val == "Urgente":
                        return "background-color: #fef3c7"
                    return ""
                
                styled_df = oldest_cases[available_cols].style.applymap(
                    color_priority, subset=["prioridade"] if "prioridade" in available_cols else []
                )
                
                st.dataframe(styled_df, use_container_width=True, height=400)
        
        return df_analysis, stats
    
    # An√°lise de laudos pendentes
    st.markdown("### üìã An√°lise de Laudos Pendentes")
    laudos_analysis, laudos_stats = analyze_aging_advanced(
        filtered_dataframes.get("detalhes_laudospendentes"),
        "Laudos Pendentes"
    )
    
    st.markdown("---")
    
    # An√°lise de exames pendentes
    st.markdown("### üî¨ An√°lise de Exames Pendentes")
    exames_analysis, exames_stats = analyze_aging_advanced(
        filtered_dataframes.get("detalhes_examespendentes"),
        "Exames Pendentes"
    )
    
    # An√°lise comparativa consolidada
    if laudos_stats and exames_stats:
        st.markdown("---")
        st.markdown("#### üìä An√°lise Comparativa Consolidada")
        
        comparison_data = pd.DataFrame({
            "M√©trica": ["Total", "M√©dia Dias", "Cr√≠ticos", "P90 Dias", "% Cr√≠ticos"],
            "Laudos": [
                laudos_stats["total"],
                round(laudos_stats["media_dias"], 1),
                laudos_stats["criticos"],
                round(laudos_stats["p90_dias"], 1),
                round((laudos_stats["criticos"] / laudos_stats["total"]) * 100, 1) if laudos_stats["total"] > 0 else 0
            ],
            "Exames": [
                exames_stats["total"],
                round(exames_stats["media_dias"], 1),
                exames_stats["criticos"],
                round(exames_stats["p90_dias"], 1),
                round((exames_stats["criticos"] / exames_stats["total"]) * 100, 1) if exames_stats["total"] > 0 else 0
            ]
        })
        
        col_comp1, col_comp2 = st.columns([0.6, 0.4])
        
        with col_comp1:
            # Gr√°fico comparativo
            fig_comparison = go.Figure()
            
            fig_comparison.add_trace(go.Bar(
                name='Laudos',
                x=['Total', 'Cr√≠ticos'],
                y=[laudos_stats["total"], laudos_stats["criticos"]],
                marker_color=config.COLORS['secondary']
            ))
            
            fig_comparison.add_trace(go.Bar(
                name='Exames',
                x=['Total', 'Cr√≠ticos'],
                y=[exames_stats["total"], exames_stats["criticos"]],
                marker_color=config.COLORS['success']
            ))
            
            fig_comparison.update_layout(
                title="Comparativo: Laudos vs Exames Pendentes",
                barmode='group',
                height=400,
                plot_bgcolor='rgba(0,0,0,0)'
            )
            
            st.plotly_chart(fig_comparison, use_container_width=True)
        
        with col_comp2:
            # Tabela comparativa detalhada
            st.markdown("**M√©tricas Comparativas**")
            
            # Formata√ß√£o para exibi√ß√£o
            display_comparison = comparison_data.copy()
            for col in ['Laudos', 'Exames']:
                display_comparison[col] = display_comparison[col].apply(
                    lambda x: f"{x:,.1f}".replace(",", ".") if isinstance(x, float) else f"{x:,}".replace(",", ".")
                )
            
            st.dataframe(display_comparison, use_container_width=True, hide_index=True)
            
            # Insights autom√°ticos
            total_laudos = laudos_stats["total"]
            total_exames = exames_stats["total"]
            
            if total_laudos > total_exames * 1.5:
                st.warning("‚ö†Ô∏è **Gargalo em Laudos**: Propor√ß√£o elevada de laudos pendentes")
            elif total_exames > total_laudos * 1.5:
                st.warning("‚ö†Ô∏è **Gargalo em Exames**: Propor√ß√£o elevada de exames pendentes")
            else:
                st.success("‚úÖ **Distribui√ß√£o Equilibrada**: Propor√ß√£o adequada entre laudos e exames")

# ============ ABA 5: ANALYTICS AVAN√áADO ============
with tab5:
    st.markdown('<h3 class="section-header">üìä Analytics Avan√ßado e Insights</h3>', unsafe_allow_html=True)
    
    # Sele√ß√£o do tipo de an√°lise
    analytics_type = st.selectbox(
        "üîç Tipo de An√°lise:",
        [
            "An√°lise de Sazonalidade",
            "Forecasting e Proje√ß√µes",
            "An√°lise de Outliers",
            "Correla√ß√µes Multivariadas",
            "Padr√µes de Workload",
            "An√°lise de Capacidade"
        ]
    )
    
    if analytics_type == "An√°lise de Sazonalidade":
        st.markdown("#### üìÖ An√°lise de Sazonalidade e Padr√µes Temporais")
        
        df_daily_atend = filtered_dataframes.get("Atendimentos_diario")
        df_daily_laudos = filtered_dataframes.get("Laudos_diario")
        
        if df_daily_atend is not None and not df_daily_atend.empty and "dia" in df_daily_atend.columns:
            # Prepara√ß√£o dos dados di√°rios
            daily_data = df_daily_atend.groupby("dia")["quantidade"].sum().reset_index()
            daily_data["dia"] = pd.to_datetime(daily_data["dia"])
            daily_data["dia_semana"] = daily_data["dia"].dt.day_name()
            daily_data["mes"] = daily_data["dia"].dt.month
            daily_data["ano"] = daily_data["dia"].dt.year
            daily_data["semana_ano"] = daily_data["dia"].dt.isocalendar().week
            
            col_season1, col_season2 = st.columns(2)
            
            with col_season1:
                # Padr√£o por dia da semana
                weekly_pattern = daily_data.groupby("dia_semana")["quantidade"].mean().reset_index()
                
                # Reordenar dias da semana
                day_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
                day_names_pt = ["Segunda", "Ter√ßa", "Quarta", "Quinta", "Sexta", "S√°bado", "Domingo"]
                
                weekly_pattern["ordem"] = weekly_pattern["dia_semana"].map(
                    {day: i for i, day in enumerate(day_order)}
                )
                weekly_pattern = weekly_pattern.sort_values("ordem")
                weekly_pattern["dia_pt"] = [
                    day_names_pt[day_order.index(day)] for day in weekly_pattern["dia_semana"]
                ]
                
                fig_weekly = px.bar(
                    weekly_pattern,
                    x="dia_pt",
                    y="quantidade",
                    title="Padr√£o Semanal - M√©dia de Atendimentos",
                    color="quantidade",
                    color_continuous_scale="Blues"
                )
                
                fig_weekly.update_layout(
                    height=400,
                    showlegend=False,
                    plot_bgcolor='rgba(0,0,0,0)'
                )
                
                st.plotly_chart(fig_weekly, use_container_width=True)
            
            with col_season2:
                # Padr√£o mensal
                monthly_pattern = daily_data.groupby("mes")["quantidade"].mean().reset_index()
                month_names = ["Jan", "Fev", "Mar", "Abr", "Mai", "Jun",
                              "Jul", "Ago", "Set", "Out", "Nov", "Dez"]
                monthly_pattern["mes_nome"] = monthly_pattern["mes"].map(
                    {i+1: month_names[i] for i in range(12)}
                )
                
                fig_monthly = px.line(
                    monthly_pattern,
                    x="mes_nome",
                    y="quantidade",
                    title="Padr√£o Sazonal - M√©dia Mensal",
                    markers=True,
                    line_shape="spline"
                )
                
                fig_monthly.update_traces(
                    line=dict(color=config.COLORS['success'], width=3),
                    marker=dict(size=8, color=config.COLORS['success'])
                )
                
                fig_monthly.update_layout(
                    height=400,
                    plot_bgcolor='rgba(0,0,0,0)'
                )
                
                st.plotly_chart(fig_monthly, use_container_width=True)
            
            # Heatmap de padr√µes
            st.markdown("#### üî• Heatmap de Atividade")
            
            if len(daily_data) > 30:  # M√≠nimo de dados para heatmap
                # Criar matriz para heatmap
                daily_data["dia_mes"] = daily_data["dia"].dt.day
                daily_data["mes_ano"] = daily_data["dia"].dt.strftime("%Y-%m")
                
                heatmap_data = daily_data.pivot_table(
                    values="quantidade",
                    index="mes_ano",
                    columns="dia_mes",
                    aggfunc="mean",
                    fill_value=0
                )
                
                fig_heatmap = px.imshow(
                    heatmap_data.values,
                    x=[f"Dia {i}" for i in heatmap_data.columns],
                    y=heatmap_data.index,
                    color_continuous_scale="Blues",
                    title="Heatmap de Atividade: Atendimentos por Dia do M√™s",
                    aspect="auto"
                )
                
                fig_heatmap.update_layout(
                    height=400,
                    xaxis_title="Dia do M√™s",
                    yaxis_title="Per√≠odo"
                )
                
                st.plotly_chart(fig_heatmap, use_container_width=True)
        
        else:
            st.info("üìù Carregue dados di√°rios para an√°lise de sazonalidade detalhada")
    
    elif analytics_type == "Forecasting e Proje√ß√µes":
        st.markdown("#### üîÆ Forecasting e Proje√ß√µes Futuras")
        
        df_atend = filtered_dataframes.get("Atendimentos_todos_Mensal")
        df_laudos = filtered_dataframes.get("Laudos_todos_Mensal")
        
        if df_atend is not None and not df_atend.empty:
            # Prepara√ß√£o dos dados para forecasting
            monthly_data = df_atend.groupby("anom√™s_dt")["quantidade"].sum().sort_index()
            
            if len(monthly_data) >= 6:  # M√≠nimo para previs√£o
                # Previs√£o simples usando m√©dia m√≥vel e tend√™ncia
                
                # √öltimos 6 meses para calcular tend√™ncia
                recent_data = monthly_data.tail(6)
                trend = (recent_data.iloc[-1] - recent_data.iloc[0]) / len(recent_data)
                
                # Sazonalidade (se houver dados suficientes)
                if len(monthly_data) >= 12:
                    seasonal_pattern = monthly_data.groupby(monthly_data.index.month).mean()
                else:
                    seasonal_pattern = None
                
                # Gerar previs√µes para pr√≥ximos 6 meses
                last_date = monthly_data.index[-1]
                forecast_dates = pd.date_range(
                    start=last_date + pd.DateOffset(months=1),
                    periods=6,
                    freq='MS'
                )
                
                forecast_values = []
                last_value = monthly_data.iloc[-1]
                
                for i, date in enumerate(forecast_dates):
                    # Tend√™ncia linear
                    trend_component = last_value + trend * (i + 1)
                    
                    # Componente sazonal
                    if seasonal_pattern is not None:
                        month = date.month
                        seasonal_component = seasonal_pattern.get(month, monthly_data.mean())
                        seasonal_factor = seasonal_component / monthly_data.mean()
                        forecast_value = trend_component * seasonal_factor
                    else:
                        forecast_value = trend_component
                    
                    forecast_values.append(max(0, forecast_value))  # N√£o pode ser negativo
                
                # Visualiza√ß√£o
                col_forecast1, col_forecast2 = st.columns([0.7, 0.3])
                
                with col_forecast1:
                    fig_forecast = go.Figure()
                    
                    # Dados hist√≥ricos
                    fig_forecast.add_trace(go.Scatter(
                        x=monthly_data.index,
                        y=monthly_data.values,
                        mode='lines+markers',
                        name='Dados Hist√≥ricos',
                        line=dict(color=config.COLORS['secondary'], width=3)
                    ))
                    
                    # Previs√µes
                    fig_forecast.add_trace(go.Scatter(
                        x=forecast_dates,
                        y=forecast_values,
                        mode='lines+markers',
                        name='Previs√£o',
                        line=dict(color=config.COLORS['warning'], width=3, dash='dash')
                    ))
                    
                    # Intervalo de confian√ßa (simples)
                    std_dev = monthly_data.std()
                    upper_bound = [v + std_dev for v in forecast_values]
                    lower_bound = [max(0, v - std_dev) for v in forecast_values]
                    
                    fig_forecast.add_trace(go.Scatter(
                        x=list(forecast_dates) + list(forecast_dates)[::-1],
                        y=upper_bound + lower_bound[::-1],
                        fill='toself',
                        fillcolor='rgba(255,165,0,0.2)',
                        line=dict(color='rgba(255,255,255,0)'),
                        name='Intervalo de Confian√ßa',
                        showlegend=True
                    ))
                    
                    fig_forecast.update_layout(
                        title="Previs√£o de Atendimentos - Pr√≥ximos 6 Meses",
                        height=500,
                        hovermode='x unified',
                        plot_bgcolor='rgba(0,0,0,0)'
                    )
                    
                    st.plotly_chart(fig_forecast, use_container_width=True)
                
                with col_forecast2:
                    st.markdown("**üìä Resumo das Previs√µes**")
                    
                    # Estat√≠sticas das previs√µes
                    forecast_mean = np.mean(forecast_values)
                    current_mean = monthly_data.tail(3).mean()
                    
                    st.metric(
                        "M√©dia Prevista",
                        format_number(forecast_mean),
                        f"{((forecast_mean - current_mean) / current_mean * 100):+.1f}%" if current_mean > 0 else None
                    )
                    
                    st.metric("Tend√™ncia", "üìà Crescente" if trend > 0 else "üìâ Decrescente")
                    
                    # Previs√µes detalhadas
                    st.markdown("**Previs√µes Mensais:**")
                    for date, value in zip(forecast_dates, forecast_values):
                        month_name = date.strftime("%b/%Y")
                        st.write(f"‚Ä¢ {month_name}: {format_number(value)}")
            
            else:
                st.info("üìù Dados insuficientes para forecasting (m√≠nimo 6 meses)")
        
        else:
            st.info("üìù Carregue dados mensais para an√°lise de forecasting")

# ============ ABA 6: RELAT√ìRIOS & EXPORTA√á√ÉO ============
with tab6:
    st.markdown('<h3 class="section-header">üìë Centro de Relat√≥rios e Exporta√ß√£o</h3>', unsafe_allow_html=True)
    
    # Sele√ß√£o do tipo de relat√≥rio
    col_report1, col_report2, col_report3 = st.columns([0.4, 0.3, 0.3])
    
    with col_report1:
        report_type = st.selectbox(
            "üìã Tipo de Relat√≥rio:",
            [
                "Relat√≥rio Executivo Completo",
                "Relat√≥rio de Produ√ß√£o",
                "Relat√≥rio de Pend√™ncias",
                "Relat√≥rio de Performance",
                "Relat√≥rio de Tend√™ncias",
                "Relat√≥rio Comparativo",
                "Dashboard Snapshot"
            ]
        )
    
    with col_report2:
        report_format = st.selectbox(
            "üìÑ Formato:",
            ["Markdown", "HTML", "JSON", "CSV"]
        )
    
    with col_report3:
        include_charts = st.checkbox("üìä Incluir Gr√°ficos", value=True)
        include_raw_data = st.checkbox("üìä Incluir Dados Brutos", value=False)
    
    def generate_comprehensive_report() -> str:
        """Gera relat√≥rio executivo completo e detalhado"""
        timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        period_text = f"{start_date.strftime('%d/%m/%Y')} a {end_date.strftime('%d/%m/%Y')}" if start_date and end_date else "Todo o per√≠odo"
        
        # Coleta de insights avan√ßados
        insights = []
        recommendations = []
        
        # An√°lise de tend√™ncias
        cresc_atend = production_metrics.get('crescimento_atendimentos', 0)
        cresc_laudos = production_metrics.get('crescimento_laudos', 0)
        
        if cresc_laudos and cresc_laudos > 15:
            insights.append(f"üìà **Crescimento Acelerado**: Laudos cresceram {format_number(cresc_laudos, 1)}% - performance excepcional")
        elif cresc_laudos and cresc_laudos < -15:
            insights.append(f"üìâ **Decl√≠nio Significativo**: Queda de {format_number(abs(cresc_laudos), 1)}% na produ√ß√£o de laudos")
            recommendations.append("üéØ **A√á√ÉO PRIORIT√ÅRIA**: Investigar causas da queda e implementar plano de recupera√ß√£o")
        
        # An√°lise de efici√™ncia
        taxa_conv = production_metrics.get('taxa_conversao', 0)
        if taxa_conv >= config.BENCHMARKS['taxa_conversao_excelente']:
            insights.append(f"üéØ **Excel√™ncia Operacional**: Taxa de convers√£o de {format_number(taxa_conv, 1)}% supera padr√£o de excel√™ncia")
        elif taxa_conv < config.BENCHMARKS['taxa_conversao_minima']:
            insights.append(f"‚ö†Ô∏è **Efici√™ncia Cr√≠tica**: Taxa de convers√£o de {format_number(taxa_conv, 1)}% abaixo do m√≠nimo")
            recommendations.append("üîß **MELHORIA URGENTE**: Revisar processo de convers√£o de atendimentos em laudos")
        
        # An√°lise de backlog
        backlog = pendency_metrics.get('backlog_meses', 0)
        if backlog > config.BENCHMARKS['backlog_critico']:
            insights.append(f"üö® **Backlog Cr√≠tico**: {format_number(backlog, 1)} meses de backlog - situa√ß√£o emergencial")
            recommendations.append("üö® **A√á√ÉO IMEDIATA**: Implementar for√ßa-tarefa para redu√ß√£o emergencial do backlog")
        elif backlog > config.BENCHMARKS['backlog_atencao']:
            insights.append(f"üü° **Backlog Elevado**: {format_number(backlog, 1)} meses - requer monitoramento intensivo")
            recommendations.append("üìã **PLANEJAMENTO**: Desenvolver cronograma de redu√ß√£o gradual do backlog")
        
        # An√°lise de aging
        aging_criticos = (pendency_metrics.get('laudos_pendentes', {}).get('criticos', 0) + 
                         pendency_metrics.get('exames_pendentes', {}).get('criticos', 0))
        total_pendentes = (pendency_metrics.get('laudos_pendentes', {}).get('total', 0) + 
                          pendency_metrics.get('exames_pendentes', {}).get('total', 0))
        
        if total_pendentes > 0:
            pct_criticos = (aging_criticos / total_pendentes) * 100
            if pct_criticos > 25:
                insights.append(f"üî¥ **Aging Cr√≠tico**: {format_number(pct_criticos, 1)}% dos casos com aging > 90 dias")
                recommendations.append("‚è∞ **GEST√ÉO DE AGING**: Priorizar casos mais antigos e implementar workflow de urg√™ncia")
        
        # Gerar recomenda√ß√µes estrat√©gicas
        if not recommendations:
            if efficiency_metrics.get('efficiency_score', 0) > 80:
                recommendations.append("‚ú® **EXCEL√äNCIA**: Manter padr√£o atual e considerar expans√£o de capacidade")
                recommendations.append("üìà **OTIMIZA√á√ÉO**: Documentar melhores pr√°ticas para replica√ß√£o")
            else:
                recommendations.append("üìä **MONITORAMENTO**: Manter acompanhamento cont√≠nuo dos indicadores")
                recommendations.append("üéØ **MELHORIA CONT√çNUA**: Buscar oportunidades de otimiza√ß√£o de processos")
        
        # Constru√ß√£o do relat√≥rio
        report = f"""# üìä RELAT√ìRIO EXECUTIVO CONSOLIDADO - {config.COMPANY}

**üïí Data de Gera√ß√£o:** {timestamp}  
**üìÖ Per√≠odo de An√°lise:** {period_text}  
**üîç Filtros Aplicados:** {len([f for f in filters['dimensions'].values() if f])} filtros dimensionais ativos  
**üìã Vers√£o do Sistema:** {config.VERSION}

---

## üìà RESUMO EXECUTIVO

### Indicadores Principais de Performance

| **M√©trica** | **Valor** | **Status** | **Benchmark** |
|-------------|-----------|------------|---------------|
| **üè• Atendimentos Totais** | {format_number(production_metrics.get('total_atendimentos', 0))} | {("üü¢" if production_metrics.get('crescimento_atendimentos', 0) > 0 else "üî¥")} | - |
| **üìã Laudos Emitidos** | {format_number(production_metrics.get('total_laudos', 0))} | {("üü¢" if production_metrics.get('crescimento_laudos', 0) > 0 else "üî¥")} | - |
| **üéØ Taxa de Convers√£o** | {format_number(production_metrics.get('taxa_conversao', 0), 1)}% | {efficiency_metrics.get('conversion_status', 'poor').replace('excellent', 'üü¢ Excelente').replace('good', 'üü° Boa').replace('fair', 'üü† Regular').replace('poor', 'üî¥ Ruim')} | {config.BENCHMARKS['taxa_conversao_boa']}% |
| **‚ö° Produtividade Mensal** | {format_number(production_metrics.get('media_mensal_laudos', 0))} laudos | - | - |
| **‚è∞ Backlog Estimado** | {format_number(pendency_metrics.get('backlog_meses', 0), 1)} meses | {efficiency_metrics.get('backlog_status', 'poor').replace('excellent', 'üü¢ Excelente').replace('good', 'üü° Boa').replace('poor', 'üî¥ Cr√≠tica')} | < {config.BENCHMARKS['backlog_atencao']} meses |

### Score de Efici√™ncia Global
**{format_number(efficiency_metrics.get('efficiency_score', 0), 1)}/100** - {
    "üü¢ Excelente" if efficiency_metrics.get('efficiency_score', 0) > 80 else
    "üü° Boa" if efficiency_metrics.get('efficiency_score', 0) > 60 else
    "üü† Regular" if efficiency_metrics.get('efficiency_score', 0) > 40 else
    "üî¥ Necessita Melhoria"
}

---

## ‚è∞ SITUA√á√ÉO DE PEND√äNCIAS

### Backlog Atual Detalhado

| **Tipo** | **Total** | **Cr√≠ticos (>90d)** | **% Cr√≠ticos** | **Aging M√©dio** |
|----------|-----------|---------------------|-----------------|-----------------|
| **üìã Laudos** | {format_number(pendency_metrics.get('laudos_pendentes', {}).get('total', 0))} | {format_number(pendency_metrics.get('laudos_pendentes', {}).get('criticos', 0))} | {format_number((pendency_metrics.get('laudos_pendentes', {}).get('criticos', 0) / max(pendency_metrics.get('laudos_pendentes', {}).get('total', 1), 1)) * 100, 1)}% | {format_number(pendency_metrics.get('laudos_pendentes', {}).get('media_dias', 0))} dias |
| **üî¨ Exames** | {format_number(pendency_metrics.get('exames_pendentes', {}).get('total', 0))} | {format_number(pendency_metrics.get('exames_pendentes', {}).get('criticos', 0))} | {format_number((pendency_metrics.get('exames_pendentes', {}).get('criticos', 0) / max(pendency_metrics.get('exames_pendentes', {}).get('total', 1), 1)) * 100, 1)}% | {format_number(pendency_metrics.get('exames_pendentes', {}).get('media_dias', 0))} dias |

### M√©tricas de Aging Avan√ßadas
- **P90 Laudos:** {format_number(pendency_metrics.get('laudos_pendentes', {}).get('p90_dias', 0))} dias
- **P90 Exames:** {format_number(pendency_metrics.get('exames_pendentes', {}).get('p90_dias', 0))} dias
- **M√°ximo Aging:** {format_number(max(pendency_metrics.get('laudos_pendentes', {}).get('max_dias', 0), pendency_metrics.get('exames_pendentes', {}).get('max_dias', 0)))} dias

---

## üìä AN√ÅLISE DE PERFORMANCE

### Tend√™ncias e Varia√ß√µes Identificadas
{chr(10).join([f"‚Ä¢ {insight}" for insight in insights]) if insights else "‚Ä¢ Sem tend√™ncias significativas identificadas no per√≠odo analisado"}

### Indicadores de Crescimento
- **üìà Crescimento Atendimentos:** {format_number(production_metrics.get('crescimento_atendimentos', 0), 1)}% (√∫ltimos 3 meses)
- **üìà Crescimento Laudos:** {format_number(production_metrics.get('crescimento_laudos', 0), 1)}% (√∫ltimos 3 meses)
- **üìä Volatilidade Atendimentos:** {format_number(production_metrics.get('volatilidade_atendimentos', 0), 1)}%
- **üìä Volatilidade Laudos:** {format_number(production_metrics.get('volatilidade_laudos', 0), 1)}%

### An√°lise de Correla√ß√£o
- **Correla√ß√£o Atend. vs Laudos:** {
    "Alta (>0.8)" if production_metrics.get('correlacao_atend_laudos', 0) > 0.8 else
    "Moderada (0.5-0.8)" if production_metrics.get('correlacao_atend_laudos', 0) > 0.5 else
    "Baixa (<0.5)"
}

---

## üö® ALERTAS E RECOMENDA√á√ïES ESTRAT√âGICAS

### Recomenda√ß√µes Priorit√°rias (por ordem de urg√™ncia)
{chr(10).join([f"{i+1}. {rec}" for i, rec in enumerate(recommendations)]) if recommendations else "‚úÖ **Situa√ß√£o Operacional Est√°vel**: Todos os indicadores dentro dos par√¢metros aceit√°veis"}

### Plano de A√ß√£o Sugerido

#### üî• **A√ß√µes Imediatas (0-30 dias)**
- Revisar casos com aging superior a {config.BENCHMARKS['aging_critico']} dias
- Implementar reuni√µes di√°rias de acompanhamento de pend√™ncias cr√≠ticas
- Estabelecer metas semanais de redu√ß√£o de backlog por unidade

#### üìã **A√ß√µes de M√©dio Prazo (30-90 dias)**
- Otimizar processos de convers√£o de atendimentos em laudos
- Implementar dashboard de monitoramento em tempo real
- Treinar equipes em gest√£o de prioridades baseada em aging

#### üéØ **A√ß√µes Estrat√©gicas (90-180 dias)**
- Desenvolver sistema de alertas autom√°ticos por aging
- Implementar an√°lise preditiva para identifica√ß√£o de gargalos
- Estabelecer programa de melhoria cont√≠nua baseado em dados

---

## üìä CONTEXTO DOS DADOS

### Datasets Processados e Qualidade
{chr(10).join([f"‚Ä¢ **{name.replace('_', ' ').title()}**: {len(df):,} registros".replace(",", ".") + 
               f" (Per√≠odo: {df['anom√™s'].min() if 'anom√™s' in df.columns and not df['anom√™s'].isna().all() else 'N/A'} a " +
               f"{df['anom√™s'].max() if 'anom√™s' in df.columns and not df['anom√™s'].isna().all() else 'N/A'})" 
               for name, df in dataframes.items() if df is not None and not df.empty])}

### Cobertura Temporal
- **Dados Mais Antigos:** {min([df['anom√™s'].min() for df in dataframes.values() if df is not None and 'anom√™s' in df.columns and not df['anom√™s'].isna().all()], default='N/A')}
- **Dados Mais Recentes:** {max([df['anom√™s'].max() for df in dataframes.values() if df is not None and 'anom√™s' in df.columns and not df['anom√™s'].isna().all()], default='N/A')}
- **Total de Meses Analisados:** {len(set().union(*[df['anom√™s'].dropna().unique() for df in dataframes.values() if df is not None and 'anom√™s' in df.columns]))}

### Filtros Aplicados
{chr(10).join([f"‚Ä¢ **{dim.title()}**: {', '.join(values) if values else 'Todos'}" for dim, values in filters['dimensions'].items()])}

---

## üìã METODOLOGIA E DEFINI√á√ïES

### C√°lculos de KPIs
- **Taxa de Convers√£o**: (Total de Laudos √∑ Total de Atendimentos) √ó 100
- **Taxa de Crescimento**: Varia√ß√£o percentual entre primeiro e √∫ltimo trimestre do per√≠odo
- **Backlog Estimado**: Total de Pend√™ncias √∑ Produtividade Mensal M√©dia
- **Aging**: Dias corridos desde a data de solicita√ß√£o at√© hoje
- **Score de Efici√™ncia**: M√©dia ponderada de volume (40%), convers√£o (60%)

### Crit√©rios de Classifica√ß√£o
- **üü¢ Excelente**: Taxa convers√£o ‚â• {config.BENCHMARKS['taxa_conversao_excelente']}%, Backlog ‚â§ {config.BENCHMARKS['backlog_atencao']} meses
- **üü° Boa**: Taxa convers√£o ‚â• {config.BENCHMARKS['taxa_conversao_boa']}%, Backlog ‚â§ {config.BENCHMARKS['backlog_critico']} meses
- **üü† Regular**: Taxa convers√£o ‚â• {config.BENCHMARKS['taxa_conversao_minima']}%, Backlog > {config.BENCHMARKS['backlog_critico']} meses
- **üî¥ Cr√≠tica**: Taxa convers√£o < {config.BENCHMARKS['taxa_conversao_minima']}%, Aging cr√≠tico > {config.BENCHMARKS['aging_critico']} dias

### Benchmarks Utilizados
- **Taxa de Convers√£o Excelente**: {config.BENCHMARKS['taxa_conversao_excelente']}%
- **Taxa de Convers√£o Boa**: {config.BENCHMARKS['taxa_conversao_boa']}%
- **Taxa de Convers√£o M√≠nima**: {config.BENCHMARKS['taxa_conversao_minima']}%
- **Backlog Cr√≠tico**: {config.BENCHMARKS['backlog_critico']} meses
- **Aging Cr√≠tico**: {config.BENCHMARKS['aging_critico']} dias

---

## üìû SUPORTE E CONTATO

**Sistema**: Dashboard Executivo {config.COMPANY} v{config.VERSION}  
**Suporte T√©cnico**: equipe-ti@pci.sc.gov.br  
**Documenta√ß√£o**: Dispon√≠vel no portal interno  
**Pr√≥xima Atualiza√ß√£o**: Autom√°tica a cada 24 horas

---

*Relat√≥rio gerado automaticamente pelo Sistema de Monitoramento Executivo*  
*Desenvolvido para otimiza√ß√£o operacional e tomada de decis√£o baseada em dados*  
*¬© {datetime.now().year} {config.COMPANY} - Todos os direitos reservados*
"""
        
        return report.strip()
    
    # Interface de gera√ß√£o
    col_gen1, col_gen2 = st.columns([0.7, 0.3])
    
    with col_gen1:
        if st.button("üìä Gerar Relat√≥rio Completo", type="primary", use_container_width=True):
            with st.spinner("Gerando relat√≥rio executivo..."):
                if report_type == "Relat√≥rio Executivo Completo":
                    report_content = generate_comprehensive_report()
                else:
                    # Outros tipos de relat√≥rio (implementa√ß√£o futura)
                    report_content = f"""# {report_type}

*Este tipo de relat√≥rio est√° em desenvolvimento e ser√° disponibilizado em vers√µes futuras.*

**Funcionalidades planejadas:**
- An√°lises especializadas por √°rea
- Relat√≥rios personaliz√°veis
- Exporta√ß√£o autom√°tica
- Integra√ß√£o com sistemas externos

**Vers√£o atual:** {config.VERSION}
**Previs√£o de implementa√ß√£o:** Pr√≥xima atualiza√ß√£o
"""
                
                # Exibir relat√≥rio
                st.markdown("### üìÑ Pr√©-visualiza√ß√£o do Relat√≥rio")
                st.markdown(report_content)
                
                # Preparar download
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename_base = f"{report_type.lower().replace(' ', '_')}_{timestamp}"
                
                if report_format == "Markdown":
                    st.download_button(
                        label="üì• Download Relat√≥rio (Markdown)",
                        data=report_content.encode('utf-8'),
                        file_name=f"{filename_base}.md",
                        mime="text/markdown",
                        use_container_width=True
                    )
                
                elif report_format == "HTML":
                    html_content = f"""
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{report_type} - {config.COMPANY}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 40px;
            color: #333;
            background: #f8fafc;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}
        h1 {{ color: {config.COLORS['primary']}; border-bottom: 3px solid {config.COLORS['secondary']}; padding-bottom: 15px; }}
        h2 {{ color: {config.COLORS['primary']}; margin-top: 35px; }}
        h3 {{ color: #7c3aed; }}
        table {{ 
            border-collapse: collapse; 
            width: 100%; 
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        th, td {{ 
            border: 1px solid #e5e7eb; 
            padding: 12px; 
            text-align: left; 
        }}
        th {{ 
            background: {config.COLORS['light']}; 
            font-weight: 600;
            color: {config.COLORS['primary']};
        }}
        .metric {{ 
            background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%); 
            padding: 15px; 
            margin: 10px 0; 
            border-radius: 8px;
            border-left: 4px solid {config.COLORS['secondary']};
        }}
        .alert {{ 
            background: #fef3c7; 
            padding: 15px; 
            margin: 15px 0; 
            border-left: 4px solid {config.COLORS['warning']}; 
            border-radius: 8px;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e5e7eb;
            text-align: center;
            color: #6b7280;
            font-size: 0.9em;
        }}
        ul {{ margin: 10px 0; }}
        li {{ margin: 5px 0; }}
    </style>
</head>
<body>
    <div class="container">
        {report_content.replace(chr(10), '<br>').replace('**', '<strong>').replace('**', '</strong>')}
        <div class="footer">
            <p>Relat√≥rio gerado em {datetime.now().strftime('%d/%m/%Y √†s %H:%M:%S')}</p>
            <p>Sistema Dashboard Executivo {config.COMPANY} v{config.VERSION}</p>
        </div>
    </div>
</body>
</html>
"""
                    st.download_button(
                        label="üì• Download Relat√≥rio (HTML)",
                        data=html_content.encode('utf-8'),
                        file_name=f"{filename_base}.html",
                        mime="text/html",
                        use_container_width=True
                    )
                
                elif report_format == "JSON":
                    json_data = {
                        "relatorio": {
                            "titulo": report_type,
                            "timestamp": datetime.now().isoformat(),
                            "periodo": period_text if 'period_text' in locals() else "Todo o per√≠odo",
                            "versao": config.VERSION
                        },
                        "metricas": {
                            "producao": production_metrics,
                            "pendencias": pendency_metrics,
                            "eficiencia": efficiency_metrics
                        },
                        "datasets": {
                            name: {
                                "registros": len(df),
                                "colunas": list(df.columns),
                                "periodo_min": df['anom√™s'].min() if 'anom√™s' in df.columns else None,
                                "periodo_max": df['anom√™s'].max() if 'anom√™s' in df.columns else None
                            }
                            for name, df in dataframes.items() if df is not None and not df.empty
                        },
                        "filtros_aplicados": filters
                    }
                    
                    import json
                    st.download_button(
                        label="üì• Download Dados (JSON)",
                        data=json.dumps(json_data, indent=2, ensure_ascii=False, default=str),
                        file_name=f"{filename_base}.json",
                        mime="application/json",
                        use_container_width=True
                    )
    
    with col_gen2:
        st.markdown("#### üìä Estat√≠sticas do Relat√≥rio")
        
        # Resumo dos dados para relat√≥rio
        total_registros = sum(len(df) for df in dataframes.values() if df is not None and not df.empty)
        datasets_carregados = len([df for df in dataframes.values() if df is not None and not df.empty])
        
        st.metric("üìÅ Datasets", datasets_carregados)
        st.metric("üìä Total Registros", f"{total_registros:,}".replace(",", "."))
        st.metric("üîç Filtros Ativos", len([f for f in filters['dimensions'].values() if f]))
        
        if production_metrics:
            st.metric("‚ö° Score Efici√™ncia", f"{efficiency_metrics.get('efficiency_score', 0):.1f}/100")

# ============ RESUMO LATERAL E RODAP√â ============
with st.sidebar:
    st.markdown("---")
    st.markdown("### üìä Resumo da Sess√£o")
    
    # Status dos datasets
    st.markdown("**üìÅ Datasets Carregados:**")
    for name, df in dataframes.items():
        if df is not None and not df.empty:
            filtered_df = filtered_dataframes.get(name, df)
            status_icon = "üü¢" if not filtered_df.empty else "üü°"
            count_text = f"{len(filtered_df):,}".replace(",", ".")
            st.write(f"{status_icon} {name.replace('_', ' ')}: {count_text}")
    
    # Filtros aplicados
    active_filters = sum(1 for filters_list in filters['dimensions'].values() if filters_list)
    st.markdown(f"**üîç Filtros Ativos:** {active_filters}")
    
    # Per√≠odo de an√°lise
    if start_date and end_date:
        period_text = f"{start_date.strftime('%d/%m')} a {end_date.strftime('%d/%m/%Y')}"
    else:
        period_text = "Todo o per√≠odo"
    st.markdown(f"**üìÖ Per√≠odo:** {period_text}")
    
    # Status geral baseado em alertas
    critical_alerts = len([a for a in alerts if a.get('type') == 'danger'])
    warning_alerts = len([a for a in alerts if a.get('type') == 'warning'])
    
    if critical_alerts > 0:
        st.markdown(f"**üö® Status:** {critical_alerts} alertas cr√≠ticos")
    elif warning_alerts > 0:
        st.markdown(f"**üü° Status:** {warning_alerts} alertas de aten√ß√£o")
    else:
        st.markdown("**‚úÖ Status:** Opera√ß√£o normal")
    
    # Link para suporte
    st.markdown("---")
    st.markdown("**üõ†Ô∏è Suporte T√©cnico**")
    st.markdown("üìß equipe-ti@pci.sc.gov.br")
    
    if auto_refresh:
        st.markdown("üîÑ **Auto-refresh ativo**")
        time.sleep(300)  # 5 minutos
        st.rerun()

# ============ RODAP√â FINAL ============
st.markdown("---")
st.markdown(f"""
<div style='text-align: center; padding: 40px; background: linear-gradient(135deg, {config.COLORS['primary']} 0%, #374151 100%); 
           border-radius: 20px; margin-top: 40px; color: white;'>
    <h2 style='color: white; margin-bottom: 20px;'>üè• Sistema Dashboard Executivo {config.COMPANY}</h2>
    <div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 30px 0;'>
        <div style='background: rgba(255,255,255,0.1); padding: 20px; border-radius: 12px;'>
            <h4 style='color: white; margin: 0 0 10px 0;'>üìä An√°lise Avan√ßada</h4>
            <p style='color: rgba(255,255,255,0.9); margin: 0; font-size: 0.9em;'>
                Monitoramento em tempo real ‚Ä¢ Indicadores de performance ‚Ä¢ Gest√£o de pend√™ncias
            </p>
        </div>
        <div style='background: rgba(255,255,255,0.1); padding: 20px; border-radius: 12px;'>
            <h4 style='color: white; margin: 0 0 10px 0;'>üéØ Intelig√™ncia Operacional</h4>
            <p style='color: rgba(255,255,255,0.9); margin: 0; font-size: 0.9em;'>
                Alertas inteligentes ‚Ä¢ Forecasting ‚Ä¢ An√°lise de tend√™ncias
            </p>
        </div>
        <div style='background: rgba(255,255,255,0.1); padding: 20px; border-radius: 12px;'>
            <h4 style='color: white; margin: 0 0 10px 0;'>üìà Otimiza√ß√£o de Processos</h4>
            <p style='color: rgba(255,255,255,0.9); margin: 0; font-size: 0.9em;'>
                Relat√≥rios executivos ‚Ä¢ Rankings de performance ‚Ä¢ Insights acion√°veis
            </p>
        </div>
    </div>
    <div style='background: rgba(255,255,255,0.1); padding: 20px; border-radius: 12px; margin-top: 20px;'>
        <p style='margin: 8px 0; color: rgba(255,255,255,0.9);'><strong>üìß Suporte:</strong> equipe-ti@pci.sc.gov.br</p>
        <p style='margin: 8px 0; color: rgba(255,255,255,0.9);'><strong>üîß Vers√£o:</strong> {config.VERSION} - Sistema Profissional de Monitoramento</p>
        <p style='margin: 8px 0; color: rgba(255,255,255,0.8); font-size: 0.85em;'>
            <em>√öltima atualiza√ß√£o: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}</em>
        </p>
    </div>
    <p style='margin-top: 30px; font-size: 0.9em; color: rgba(255,255,255,0.7);'>
        Sistema desenvolvido para excel√™ncia operacional e tomada de decis√£o estrat√©gica baseada em dados
    </p>
</div>
""", unsafe_allow_html=True)# ============ SISTEMA DE ABAS AVAN√áADO ============
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìä **Vis√£o Executiva**",
    "üìà **An√°lise Temporal**", 
    "üèÜ **Performance & Rankings**",
    "‚è∞ **Gest√£o de Pend√™ncias**",
    "üìä **Analytics Avan√ßado**",
    "üìë **Relat√≥rios & Exporta√ß√£o**"
])

# ============ ABA 1: VIS√ÉO EXECUTIVA ============
with tab1:
    st.markdown('<h3 class="section-header">üìä Panorama Executivo Consolidado</h3>', unsafe_allow_html=True)
    
    # Gr√°fico principal - Evolu√ß√£o temporal
    df_atend = filtered_dataframes.get("Atendimentos_todos_Mensal")
    df_laudos = filtered_dataframes.get("Laudos_todos_Mensal")
    
    if df_atend is not None and df_laudos is not None and not df_atend.empty and not df_laudos.empty:
        
        # Prepara√ß√£o dos dados
        atend_monthly = df_atend.groupby("anom√™s_dt")["quantidade"].sum().reset_index()
        laudos_monthly = df_laudos.groupby("anom√™s_dt")["quantidade"].sum().reset_index()
        
        # Gr√°fico de evolu√ß√£o principal
        col_chart1, col_chart2 = st.columns([0.75, 0.25])
        
        with col_chart1:
            st.markdown("#### üìà Evolu√ß√£o Temporal: Atendimentos vs Laudos")
            
            fig_evolution = VisualizationEngine.create_modern_line_chart(
                pd.merge(atend_monthly, laudos_monthly, on="anom√™s_dt", suffixes=("_atend", "_laudos")),
                "anom√™s_dt",
                ["quantidade_atend", "quantidade_laudos"],
                "Evolu√ß√£o Mensal de Atendimentos e Laudos"
            )
            
            # Adicionar m√©dias m√≥veis se solicitado
            if show_benchmarks and len(atend_monthly) > 3:
                merged_data = pd.merge(atend_monthly, laudos_monthly, on="anom√™s_dt", suffixes=("_atend", "_laudos"))
                merged_data['ma3_atend'] = merged_data['quantidade_atend'].rolling(3).mean()
                merged_data['ma3_laudos'] = merged_data['quantidade_laudos'].rolling(3).mean()
                
                fig_evolution.add_trace(go.Scatter(
                    x=merged_data["anom√™s_dt"],
                    y=merged_data["ma3_atend"],
                    mode='lines',
                    name='Tend√™ncia Atendimentos',
                    line=dict(color=config.COLORS['secondary'], width=2, dash='dash'),
                    opacity=0.7
                ))
                
                fig_evolution.add_trace(go.Scatter(
                    x=merged_data["anom√™s_dt"],
                    y=merged_data["ma3_laudos"],
                    mode='lines',
                    name='Tend√™ncia Laudos',
                    line=dict(color=config.COLORS['success'], width=2, dash='dash'),
                    opacity=0.7
                ))
            
            fig_evolution.update_layout(height=chart_height)
            st.plotly_chart(fig_evolution, use_container_width=True)
        
        with col_chart2:
            st.markdown("#### üéØ Taxa de Convers√£o")
            
            # C√°lculo da taxa de convers√£o mensal
            merged_monthly = pd.merge(
                atend_monthly.rename(columns={"quantidade": "Atendimentos"}),
                laudos_monthly.rename(columns={"quantidade": "Laudos"}),
                on="anom√™s_dt",
                how="inner"
            )
            
            if not merged_monthly.empty:
                merged_monthly["Taxa_Conversao"] = (merged_monthly["Laudos"] / merged_monthly["Atendimentos"]) * 100
                
                fig_conversion = go.Figure()
                
                # Linha principal
                fig_conversion.add_trace(go.Scatter(
                    x=merged_monthly["anom√™s_dt"],
                    y=merged_monthly["Taxa_Conversao"],
                    mode='lines+markers',
                    line=dict(color=config.COLORS['warning'], width=3),
                    marker=dict(size=8, symbol='circle'),
                    name='Taxa de Convers√£o',
                    fill='tonexty'
                ))
                
                # Benchmarks
                if show_benchmarks:
                    fig_conversion.add_hline(
                        y=config.BENCHMARKS['taxa_conversao_excelente'],
                        line_dash="solid",
                        line_color=config.COLORS['success'],
                        annotation_text=f"Excelente: {config.BENCHMARKS['taxa_conversao_excelente']}%",
                        annotation_position="top right"
                    )
                    
                    fig_conversion.add_hline(
                        y=config.BENCHMARKS['taxa_conversao_boa'],
                        line_dash="dash",
                        line_color=config.COLORS['warning'],
                        annotation_text=f"Meta: {config.BENCHMARKS['taxa_conversao_boa']}%",
                        annotation_position="bottom right"
                    )
                    
                    fig_conversion.add_hline(
                        y=config.BENCHMARKS['taxa_conversao_minima'],
                        line_dash="dot",
                        line_color=config.COLORS['danger'],
                        annotation_text=f"M√≠nimo: {config.BENCHMARKS['taxa_conversao_minima']}%"
                    )
                
                fig_conversion.update_layout(
                    height=chart_height,
                    xaxis_title="Per√≠odo",
                    yaxis_title="Taxa (%)",
                    yaxis=dict(range=[0, 100]),
                    showlegend=False,
                    plot_bgcolor='rgba(0,0,0,0)',
                    paper_bgcolor='rgba(0,0,0,0)'
                )
                
                st.plotly_chart(fig_conversion, use_container_width=True)
    
    # An√°lises por dimens√£o
    st.markdown("#### üè¢ An√°lise por Dimens√µes")
    
    col_dim1, col_dim2 = st.columns(2)
    
    with col_dim1:
        st.markdown("**Performance por Unidade (Top 15)**")
        if df_laudos is not None and "unidade" in df_laudos.columns:
            unidade_summary = (
                df_laudos.groupby("unidade")["quantidade"]
                .sum()
                .sort_values(ascending=True)
                .tail(15)
                .reset_index()
            )
            
            fig_unidades = px.bar(
                unidade_summary,
                x="quantidade",
                y="unidade",
                orientation="h",
                color="quantidade",
                color_continuous_scale="Blues",
                title="Laudos Emitidos por Unidade"
            )
            
            fig_unidades.update_layout(
                height=500,
                showlegend=False,
                yaxis={'categoryorder': 'total ascending'},
                plot_bgcolor='rgba(0,0,0,0)',
                xaxis_title="Quantidade de Laudos"
            )
            
            st.plotly_chart(fig_unidades, use_container_width=True)
    
    with col_dim2:
        st.markdown("**An√°lise Pareto - Tipos de Per√≠cia**")
        df_laudos_esp = filtered_dataframes.get("Laudos_especifico_Mensal")
        if df_laudos_esp is not None and "tipo" in df_laudos_esp.columns:
            tipo_summary = (
                df_laudos_esp.groupby("tipo")["quantidade"]
                .sum()
                .sort_values(ascending=False)
                .head(10)
                .reset_index()
            )
            
            tipo_summary["pct"] = 100 * tipo_summary["quantidade"] / tipo_summary["quantidade"].sum()
            tipo_summary["pct_acum"] = tipo_summary["pct"].cumsum()
            
            fig_pareto = make_subplots(specs=[[{"secondary_y": True}]])
            
            fig_pareto.add_trace(
                go.Bar(
                    x=tipo_summary["tipo"],
                    y=tipo_summary["quantidade"],
                    name="Quantidade",
                    marker_color=config.COLORS['secondary'],
                    opacity=0.8
                )
            )
            
            fig_pareto.add_trace(
                go.Scatter(
                    x=tipo_summary["tipo"],
                    y=tipo_summary["pct_acum"],
                    mode="lines+markers",
                    name="% Acumulado",
                    line=dict(color=config.COLORS['danger'], width=3),
                    marker=dict(size=8)
                ),
                secondary_y=True,
            )
            
            if show_benchmarks:
                fig_pareto.add_hline(
                    y=80,
                    line_dash="dash",
                    line_color=config.COLORS['danger'],
                    secondary_y=True,
                    annotation_text="Princ√≠pio 80/20"
                )
            
            fig_pareto.update_layout(
                title="An√°lise Pareto - Tipos de Per√≠cia",
                height=500,
                hovermode="x unified",
                plot_bgcolor='rgba(0,0,0,0)'
            )
            fig_pareto.update_yaxes(title_text="Quantidade", secondary_y=False)
            fig_pareto.update_yaxes(title_text="% Acumulado", range=[0, 100], secondary_y=True)
            fig_pareto.update_xaxes(tickangle=-45)
            
            st.plotly_chart(fig_pareto, use_container_width=True)

# ============ ABA 2: AN√ÅLISE TEMPORAL ============
with tab2:
    st.markdown('<h3 class="section-header">üìà An√°lise Temporal Avan√ßada</h3>', unsafe_allow_html=True)
    
    def create_advanced_time_analysis(df: pd.DataFrame, title: str, color: str):
        """Cria an√°lise temporal avan√ßada com decomposi√ß√£o"""
        if df is None or df.empty or "anom√™s_dt" not in df.columns:
            st.info(f"Dados insuficientes para {title}")
            return
        
        monthly_data = df.groupby("anom√™s_dt")["quantidade"].sum().sort_index()
        if len(monthly_data) < 3:
            st.info(f"Per√≠odo insuficiente para an√°lise: {title}")
            return
        
        # Prepara√ß√£o dos dados
        dates = monthly_data.index
        values = monthly_data.values
        
        # C√°lculos estat√≠sticos
        ma3 = monthly_data.rolling(window=3, center=True).mean()
        ma6 = monthly_data.rolling(window=6, center=True).mean()
        pct_change = monthly_data.pct_change() * 100
        
        # Detec√ß√£o de tend√™ncia
        x_numeric = np.arange(len(monthly_data))
        slope = np.polyfit(x_numeric, values, 1)[0]
        intercept = values.mean() - slope * np.mean(x_numeric)
        trend_line = slope * x_numeric + intercept
        
        # Detec√ß√£o de sazonalidade
        seasonal_pattern = None
        if len(monthly_data) >= 12:
            seasonal_pattern = monthly_data.groupby(monthly_data.index.month).mean()
        
        # Cria√ß√£o do gr√°fico
        fig = make_subplots(
            rows=4, cols=1,
            subplot_titles=(
                f"{title} - Evolu√ß√£o Temporal",
                "Varia√ß√£o Percentual Mensal",
                "M√©dias M√≥veis e Tend√™ncia",
                "Padr√£o Sazonal" if seasonal_pattern is not None else "Distribui√ß√£o Mensal"
            ),
            vertical_spacing=0.06,
            row_heights=[0.4, 0.2, 0.2, 0.2]
        )
        
        # S√©rie principal com √°rea
        fig.add_trace(
            go.Scatter(
                x=dates, y=values,
                mode="lines+markers",
                name="Valores Observados",
                line=dict(color=color, width=3),
                marker=dict(size=6),
                fill='tonexty',
                fillcolor=f'rgba({int(color[1:3], 16)}, {int(color[3:5], 16)}, {int(color[5:7], 16)}, 0.1)'
            ),
            row=1, col=1
        )
        
        # Varia√ß√£o percentual com cores condicionais
        colors = [config.COLORS['danger'] if x < 0 else config.COLORS['success'] for x in pct_change.fillna(0)]
        fig.add_trace(
            go.Bar(
                x=dates, y=pct_change,
                name="Varia√ß√£o %",
                marker_color=colors,
                showlegend=False
            ),
            row=2, col=1
        )
        
        # M√©dias m√≥veis
        fig.add_trace(
            go.Scatter(
                x=dates, y=ma3,
                mode="lines",
                name="M√©dia M√≥vel 3m",
                line=dict(color=config.COLORS['warning'], width=2, dash="dash")
            ),
            row=3, col=1
        )
        
        fig.add_trace(
            go.Scatter(
                x=dates, y=ma6,
                mode="lines",
                name="M√©dia M√≥vel 6m",
                line=dict(color=config.COLORS['info'], width=2, dash="dot")
            ),
            row=3, col=1
        )
        
        # Linha de tend√™ncia
        fig.add_trace(
            go.Scatter(
                x=dates, y=trend_line,
                mode="lines",
                name="Tend√™ncia Linear",
                line=dict(color=config.COLORS['danger'], width=3, dash="solid"),
                opacity=0.8
            ),
            row=3, col=1
        )
        
        # Padr√£o sazonal ou distribui√ß√£o
        if seasonal_pattern is not None:
            months = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun',
                     'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']
            fig.add_trace(
                go.Bar(
                    x=months[:len(seasonal_pattern)],
                    y=seasonal_pattern.values,
                    name="Padr√£o Sazonal",
                    marker_color=config.COLORS['info'],
                    showlegend=False
                ),
                row=4, col=1
            )
        else:
            # Distribui√ß√£o por m√™s do ano
            month_dist = monthly_data.groupby(monthly_data.index.month).mean()
            months = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun',
                     'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']
            fig.add_trace(
                go.Bar(
                    x=months[:len(month_dist)],
                    y=month_dist.values,
                    name="Distribui√ß√£o Mensal",
                    marker_color=config.COLORS['secondary'],
                    showlegend=False
                ),
                row=4, col=1
            )
        
        # Layout
        fig.update_layout(
            height=800,
            hovermode="x unified",
            showlegend=True,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        # Configura√ß√£o dos eixos
        fig.update_xaxes(title_text="Per√≠odo", row=4, col=1)
        fig.update_yaxes(title_text="Quantidade", row=1, col=1)
        fig.update_yaxes(title_text="Varia√ß√£o (%)", row=2, col=1)
        fig.update_yaxes(title_text="Valores", row=3, col=1)
        fig.update_yaxes(title_text="M√©dia", row=4, col=1)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # M√©tricas de an√°lise temporal
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            trend_direction = "üìà Crescente" if slope > 0 else "üìâ Decrescente" if slope < 0 else "‚û°Ô∏è Est√°vel"
            st.metric("Tend√™ncia", trend_direction)
        
        with col2:
            correlation = np.corrcoef(x_numeric, values)[0, 1]
            st.metric("Correla√ß√£o Temporal", f"{correlation:.3f}")
        
        with col3:
            volatility = pct_change.std()
            st.metric("Volatilidade", f"{volatility:.1f}%")
        
        with col4:
            last_change = pct_change.iloc[-1] if not pct_change.empty else 0
            change_icon = "üìà" if last_change > 0 else "üìâ" if last_change < 0 else "‚û°Ô∏è"
            st.metric("√öltima Varia√ß√£o", f"{change_icon} {last_change:.1f}%")
        
        with col5:
            avg_growth = pct_change.mean()
            st.metric("Crescimento M√©dio", f"{avg_growth:.1f}%")
    
    # An√°lises por dataset
    analysis_col1, analysis_col2 = st.columns(2)
    
    with analysis_col1:
        create_advanced_time_analysis(
            filtered_dataframes.get("Atendimentos_todos_Mensal"),
            "Atendimentos",
            config.COLORS['secondary']
        )
    
    with analysis_col2:
        create_advanced_time_analysis(
            filtered_dataframes.get("Laudos_todos_Mensal"),
            "Laudos",
            config.COLORS['success']
        )
    
    # An√°lise de correla√ß√£o cruzada
    df_atend = filtered_dataframes.get("Atendimentos_todos_Mensal")
    df_laudos = filtered_dataframes.get("Laudos_todos_Mensal")
    
    if df_atend is not None and df_laudos is not None and not df_atend.empty and not df_laudos.empty:
        st.markdown("#### üîó An√°lise de Correla√ß√£o Cruzada")
        
        atend_monthly = df_atend.groupby("anom√™s_dt")["quantidade"].sum()
        laudos_monthly = df_laudos.groupby("anom√™s_dt")["quantidade"].sum()
        common_periods = atend_monthly.index.intersection(laudos_monthly.index)
        
        if len(common_periods) > 3:
            correlation_data = pd.DataFrame({
                "Atendimentos": atend_monthly.loc[common_periods],
                "Laudos": laudos_monthly.loc[common_periods],
                "Periodo": common_periods
            }).reset_index(drop=True)
            
            correlation_coef = correlation_data["Atendimentos"].corr(correlation_data["Laudos"])
            
            # Gr√°fico de dispers√£o
            fig_correlation = px.scatter(
                correlation_data,
                x="Atendimentos",
                y="Laudos",
                trendline="ols",
                title=f"Correla√ß√£o: Atendimentos vs Laudos (r = {correlation_coef:.3f})",
                hover_data=["Periodo"],
                color_discrete_sequence=[config.COLORS['secondary']]
            )
            
            fig_correlation.update_layout(
                height=400,
                plot_bgcolor='rgba(0,0,0,0)'
            )
            
            # M√©tricas de correla√ß√£o
            col_corr1, col_corr2, col_corr3 = st.columns([0.6, 0.2, 0.2])
            
            with col_corr1:
                st.plotly_chart(fig_correlation, use_container_width=True)
            
            with col_corr2:
                # Interpreta√ß√£o da correla√ß√£o
                if correlation_coef > 0.8:
                    corr_status = "üü¢ Forte"
                    corr_desc = "Excelente alinhamento"
                elif correlation_coef > 0.6:
                    corr_status = "üü° Moderada"
                    corr_desc = "Bom alinhamento"
                elif correlation_coef > 0.3:
                    corr_status = "üü† Fraca"
                    corr_desc = "Algum desalinhamento"
                else:
                    corr_status = "üî¥ Muito Fraca"
                    corr_desc = "Pouco alinhamento"
                
                st.metric("Status da Correla√ß√£o", corr_status)
                st.caption(corr_desc)
            
            with col_corr3:
                # Estat√≠sticas adicionais
                r_squared = correlation_coef ** 2
                st.metric("R¬≤", f"{r_squared:.3f}")
                st.caption("Vari√¢ncia explicada")

# ============ ABA 3: PERFORMANCE & RANKINGS ============
with tab3:
    st.markdown('<h3 class="section-header">üèÜ Performance & Rankings Detalhados</h3>', unsafe_allow_html=True)
    
    def create_comprehensive_ranking(df: pd.DataFrame, dimension: str, title: str, top_n: int = 20):
        """Cria ranking abrangente com m√∫ltiplas m√©tricas"""
        if df is None or df.empty or dimension not in df.columns:
            st.info(f"Dados insuficientes para {title}")
            return
        
        # Agrega√ß√£o com estat√≠sticas descritivas
        ranking_data = df.groupby(dimension).agg({
            "quantidade": ["sum", "count", "mean", "std", "min", "max"]
        }).round(2)
        
        ranking_data.columns = ["Total", "Registros", "M√©dia", "Desvio", "M√≠nimo", "M√°ximo"]
        ranking_data = ranking_data.fillna(0)
        
        # M√©tricas derivadas
        ranking_data["Coef_Variacao"] = (ranking_data["Desvio"] / ranking_data["M√©dia"]).replace([np.inf, -np.inf], 0)
        ranking_data["Percentual"] = (ranking_data["Total"] / ranking_data["Total"].sum()) * 100
        ranking_data["Percentual_Acum"] = ranking_data.sort_values("Total", ascending=False)["Percentual"].cumsum()
        
        # Score de performance (normalizado)
        max_total = ranking_data["Total"].max()
        max_media = ranking_data["M√©dia"].max()
        ranking_data["Score_Performance"] = (
            (ranking_data["Total"] / max_total) * 0.6 +
            (ranking_data["M√©dia"] / max_media) * 0.3 +
            (1 - ranking_data["Coef_Variacao"].clip(0, 1)) * 0.1
        ) * 100
        
        # Top N para visualiza√ß√£o
        top_ranking = ranking_data.sort_values("Total", ascending=False).head(top_n).reset_index()
        
        if top_ranking.empty:
            st.info(f"Sem dados para {title}")
            return
        
        # Visualiza√ß√£o em colunas
        viz_col1, viz_col2 = st.columns([0.6, 0.4])
        
        with viz_col1:
            # Gr√°fico de barras horizontal
            fig_ranking = go.Figure()
            
            fig_ranking.add_trace(go.Bar(
                y=top_ranking[dimension],
                x=top_ranking["Total"],
                orientation="h",
                marker=dict(
                    color=top_ranking["Score_Performance"],
                    colorscale="Viridis",
                    showscale=True,
                    colorbar=dict(title="Score Performance")
                ),
                text=[f"{val:,.0f}".replace(",", ".") for val in top_ranking["Total"]],
                textposition="outside",
                hovertemplate=(
                    "<b>%{y}</b><br>"
                    "Total: %{x:,.0f}<br>"
                    "M√©dia: %{customdata[0]:.1f}<br>"
                    "Score: %{marker.color:.1f}"
                    "<extra></extra>"
                ),
                customdata=top_ranking[["M√©dia"]].values
            ))
            
            fig_ranking.update_layout(
                title=f"{title} - Top {min(top_n, len(top_ranking))}",
                height=max(400, len(top_ranking) * 25),
                yaxis={'categoryorder': 'total ascending'},
                xaxis_title="Quantidade Total",
                plot_bgcolor='rgba(0,0,0,0)',
                margin=dict(l=0, r=0, t=40, b=0)
            )
            
            st.plotly_chart(fig_ranking, use_container_width=True)
        
        with viz_col2:
            # Gr√°fico de pizza para distribui√ß√£o
            top_10_for_pie = top_ranking.head(10)
            
            fig_pie = px.pie(
                values=top_10_for_pie["Percentual"],
                names=top_10_for_pie[dimension],
                title=f"Distribui√ß√£o - Top 10",
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            
            fig_pie.update_layout(
                height=400,
                showlegend=True,
                legend=dict(orientation="v", yanchor="middle", y=0.5)
            )
            
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # Tabela detalhada expans√≠vel
        with st.expander(f"üìä Dados Detalhados - {title}", expanded=False):
            # Formata√ß√£o para exibi√ß√£o
            display_df = top_ranking.copy()
            display_df["Total"] = display_df["Total"].apply(lambda x: f"{x:,.0f}".replace(",", "."))
            display_df["M√©dia"] = display_df["M√©dia"].apply(lambda x: f"{x:.1f}")
            display_df["Percentual"] = display_df["Percentual"].apply(lambda x: f"{x:.1f}%")
            display_df["Score_Performance"] = display_df["Score_Performance"].apply(lambda x: f"{x:.1f}")
            display_df["Coef_Variacao"] = display_df["Coef_Variacao"].apply(lambda x: f"{x:.2f}")
            
            # Colunas para exibi√ß√£o
            cols_to_show = [dimension, "Total", "Registros", "M√©dia", "Percentual", "Score_Performance"]
            st.dataframe(
                display_df[cols_to_show],
                use_container_width=True,
                hide_index=True
            )
    
    # Tabs de rankings
    rank_tab1, rank_tab2, rank_tab3, rank_tab4 = st.tabs([
        "üè¢ Por Diretoria",
        "üè™ Por Unidade",
        "üî¨ Por Tipo",
        "üìä Matriz de Efici√™ncia"
    ])
    
    with rank_tab1:
        col1, col2 = st.columns(2)
        with col1:
            create_comprehensive_ranking(
                filtered_dataframes.get("Atendimentos_todos_Mensal"),
                "diretoria",
                "Atendimentos por Diretoria"
            )
        with col2:
            create_comprehensive_ranking(
                filtered_dataframes.get("Laudos_todos_Mensal"),
                "diretoria",
                "Laudos por Diretoria"
            )
    
    with rank_tab2:
        col1, col2 = st.columns(2)
        with col1:
            create_comprehensive_ranking(
                filtered_dataframes.get("Atendimentos_todos_Mensal"),
                "unidade",
                "Atendimentos por Unidade",
                25
            )
        with col2:
            create_comprehensive_ranking(
                filtered_dataframes.get("Laudos_todos_Mensal"),
                "unidade",
                "Laudos por Unidade",
                25
            )
    
    with rank_tab3:
        col1, col2 = st.columns(2)
        with col1:
            create_comprehensive_ranking(
                filtered_dataframes.get("Atendimentos_especifico_Mensal"),
                "tipo",
                "Atendimentos por Tipo",
                20
            )
        with col2:
            create_comprehensive_ranking(
                filtered_dataframes.get("Laudos_especifico_Mensal"),
                "tipo",
                "Laudos por Tipo",
                20
            )
    
    with rank_tab4:
        st.markdown("#### üìä Matriz de Efici√™ncia Operacional")
        
        df_atend = filtered_dataframes.get("Atendimentos_todos_Mensal")
        df_laudos = filtered_dataframes.get("Laudos_todos_Mensal")
        
        if (df_atend is not None and df_laudos is not None and 
            not df_atend.empty and not df_laudos.empty and
            "unidade" in df_atend.columns and "unidade" in df_laudos.columns):
            
            # An√°lise por unidade
            atend_unidade = df_atend.groupby("unidade")["quantidade"].sum()
            laudos_unidade = df_laudos.groupby("unidade")["quantidade"].sum()
            
            efficiency_data = pd.DataFrame({
                "Atendimentos": atend_unidade,
                "Laudos": laudos_unidade
            }).fillna(0)
            
            # M√©tricas calculadas
            efficiency_data["Taxa_Conversao"] = (
                efficiency_data["Laudos"] / efficiency_data["Atendimentos"] * 100
            ).replace([np.inf, -np.inf], 0)
            
            efficiency_data["Volume_Score"] = (
                (efficiency_data["Atendimentos"] / efficiency_data["Atendimentos"].max()) * 50 +
                (efficiency_data["Laudos"] / efficiency_data["Laudos"].max()) * 50
            )
            
            efficiency_data["Eficiencia_Global"] = (
                efficiency_data["Taxa_Conversao"] * 0.6 +
                efficiency_data["Volume_Score"] * 0.4
            )
            
            # Classifica√ß√£o em quadrantes
            mediana_atend = efficiency_data["Atendimentos"].median()
            mediana_laudos = efficiency_data["Laudos"].median()
            
            def classify_quadrant(row):
                if row["Atendimentos"] >= mediana_atend and row["Laudos"] >= mediana_laudos:
                    return "‚≠ê Alto Volume/Alta Produ√ß√£o"
                elif row["Atendimentos"] >= mediana_atend and row["Laudos"] < mediana_laudos:
                    return "üîÑ Alto Volume/Baixa Convers√£o"
                elif row["Atendimentos"] < mediana_atend and row["Laudos"] >= mediana_laudos:
                    return "üéØ Baixo Volume/Alta Efici√™ncia"
                else:
                    return "üìà Oportunidade de Melhoria"
            
            efficiency_data["Quadrante"] = efficiency_data.apply(classify_quadrant, axis=1)
            
            # Visualiza√ß√£o da matriz
            col_matrix1, col_matrix2 = st.columns([0.7, 0.3])
            
            with col_matrix1:
                fig_efficiency = px.scatter(
                    efficiency_data.reset_index(),
                    x="Atendimentos",
                    y="Laudos",
                    size="Taxa_Conversao",
                    color="Quadrante",
                    hover_name="unidade",
                    title="Matriz de Efici√™ncia: Volume vs Produ√ß√£o",
                    size_max=25,
                    color_discrete_map={
                        "‚≠ê Alto Volume/Alta Produ√ß√£o": config.COLORS['success'],
                        "üîÑ Alto Volume/Baixa Convers√£o": config.COLORS['warning'],
                        "üéØ Baixo Volume/Alta Efici√™ncia": config.COLORS['info'],
                        "üìà Oportunidade de Melhoria": config.COLORS['danger']
                    }
                )
                
                # Linhas de refer√™ncia
                fig_efficiency.add_vline(
                    x=mediana_atend,
                    line_dash="dash",
                    line_color="gray",
                    annotation_text="Mediana Atendimentos"
                )
                fig_efficiency.add_hline(
                    y=mediana_laudos,
                    line_dash="dash",
                    line_color="gray",
                    annotation_text="Mediana Laudos"
                )
                
                fig_efficiency.update_layout(
                    height=500,
                    plot_bgcolor='rgba(0,0,0,0)'
                )
                
                st.plotly_chart(fig_efficiency, use_container_width=True)
            
            with col_matrix2:
                # Top performers
                st.markdown("**üèÜ Top 10 Mais Eficientes**")
                top_efficient = efficiency_data.sort_values("Eficiencia_Global", ascending=False).head(10)
                
                for idx, (unidade, row) in enumerate(top_efficient.iterrows(), 1):
                    quadrante_icon = row["Quadrante"].split()[0]
                    st.write(f"{idx}. {quadrante_icon} **{unidade}**")
                    st.write(f"   Taxa: {row['Taxa_Conversao']:.1f}% | Score: {row['Eficiencia_Global']:.1f}")
                    st.write("---")

# ============ ABA 4: GEST√ÉO DE PEND√äNCIAS ============
with tab4:
    st.markdown('<h3 class="section-header">‚è∞ Gest√£o Avan√ßada de Pend√™ncias</h3>', unsafe_allow_html=True)
    
    def analyze_aging_advanced(df: pd.DataFrame, title: str, date_column: str = "data_base"):
        """An√°lise avan√ßada de aging com m√∫ltiplas dimens√µes"""
        if df is None or df.empty:
            st.info(f"Sem dados de {title}")
            return None
        
        # Buscar coluna de data dispon√≠vel
        date_cols = [col for col in df.columns if "data" in col.lower()]
        if date_column not in df.columns and date_cols:
            date_column = date_cols[0]
        
        if date_column not in df.columns:
            st.warning(f"Coluna de data n√£o encontrada para {title}")
            return None
        
        # Processamento de aging
        dates = pd.to_datetime(df[date_column], errors="coerce")
        import io
import os
import re
import warnings
from datetime import datetime, timedelta
from typing import Dict, Optional, Tuple, List, Union, Any
from dataclasses import dataclass

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Configura√ß√µes de warnings e performance
warnings.filterwarnings('ignore')
pd.options.mode.chained_assignment = None

# ============ CONFIGURA√á√ÉO INICIAL ============
st.set_page_config(
    page_title="PCI/SC ‚Äì Dashboard Executivo",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üè•",
    menu_items={
        'Get Help': 'mailto:equipe-ti@pci.sc.gov.br',
        'Report a bug': 'mailto:equipe-ti@pci.sc.gov.br',
        'About': "Dashboard Executivo PCI/SC v4.0 - Sistema Avan√ßado de Monitoramento"
    }
)

# ============ CONFIGURA√á√ïES GLOBAIS ============
@dataclass
class DashboardConfig:
    """Configura√ß√µes centralizadas do dashboard"""
    VERSION = "4.0.0"
    COMPANY = "PCI/SC"
    CACHE_TTL = 3600
    DEFAULT_CHART_HEIGHT = 450
    MAX_UPLOAD_SIZE = 100  # MB
    
    # Cores do tema
    COLORS = {
        'primary': '#1f2937',
        'secondary': '#3b82f6',
        'success': '#10b981',
        'warning': '#f59e0b',
        'danger': '#ef4444',
        'info': '#06b6d4',
        'light': '#f8fafc',
        'dark': '#111827'
    }
    
    # Metas e benchmarks
    BENCHMARKS = {
        'taxa_conversao_excelente': 80,
        'taxa_conversao_boa': 70,
        'taxa_conversao_minima': 50,
        'backlog_critico': 6,  # meses
        'backlog_atencao': 3,  # meses
        'aging_critico': 90,   # dias
        'aging_atencao': 60    # dias
    }

config = DashboardConfig()

# === ESTILOS CSS MODERNOS ===
MODERN_CSS = f"""
<style>
/* Reset e base */
.main {{
    padding-top: 1rem;
}}

/* Design System - Cards */
.metric-card {{
    background: linear-gradient(135deg, #ffffff 0%, {config.COLORS['light']} 100%);
    border: 1px solid #e5e7eb;
    border-radius: 16px;
    padding: 24px;
    height: 100%;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
    transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
    position: relative;
    overflow: hidden;
}}

.metric-card::before {{
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 4px;
    background: linear-gradient(90deg, {config.COLORS['secondary']}, {config.COLORS['success']});
}}

.metric-card:hover {{
    transform: translateY(-4px);
    box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
}}

.metric-title {{
    font-size: 0.875rem;
    color: #6b7280;
    font-weight: 600;
    margin: 0 0 8px 0;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    display: flex;
    align-items: center;
    gap: 6px;
}}

.metric-value {{
    font-size: 2.25rem;
    font-weight: 800;
    color: {config.COLORS['primary']};
    margin: 8px 0 4px 0;
    line-height: 1;
    font-family: 'Inter', system-ui, -apple-system, sans-serif;
}}

.metric-delta {{
    font-size: 0.875rem;
    font-weight: 600;
    margin-top: 8px;
    display: flex;
    align-items: center;
    gap: 4px;
}}

.metric-delta.positive {{ color: {config.COLORS['success']}; }}
.metric-delta.negative {{ color: {config.COLORS['danger']}; }}
.metric-delta.neutral {{ color: #6b7280; }}

/* Alertas modernos */
.alert {{
    padding: 16px 20px;
    border-radius: 12px;
    margin: 16px 0;
    border-left: 4px solid;
    backdrop-filter: blur(10px);
    position: relative;
    overflow: hidden;
}}

.alert::before {{
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: linear-gradient(135deg, rgba(255,255,255,0.1) 0%, rgba(255,255,255,0.05) 100%);
    pointer-events: none;
}}

.alert-success {{
    background: linear-gradient(135deg, rgba(16, 185, 129, 0.1) 0%, rgba(5, 150, 105, 0.05) 100%);
    border-left-color: {config.COLORS['success']};
    color: #065f46;
}}

.alert-warning {{
    background: linear-gradient(135deg, rgba(245, 158, 11, 0.1) 0%, rgba(217, 119, 6, 0.05) 100%);
    border-left-color: {config.COLORS['warning']};
    color: #92400e;
}}

.alert-danger {{
    background: linear-gradient(135deg, rgba(239, 68, 68, 0.1) 0%, rgba(220, 38, 38, 0.05) 100%);
    border-left-color: {config.COLORS['danger']};
    color: #991b1b;
}}

.alert-info {{
    background: linear-gradient(135deg, rgba(6, 182, 212, 0.1) 0%, rgba(8, 145, 178, 0.05) 100%);
    border-left-color: {config.COLORS['info']};
    color: #0c4a6e;
}}

/* T√≠tulos de se√ß√£o */
.section-header {{
    margin: 32px 0 20px 0;
    padding: 0 0 12px 0;
    border-bottom: 2px solid #e5e7eb;
    color: {config.COLORS['primary']};
    font-weight: 700;
    font-size: 1.5rem;
    display: flex;
    align-items: center;
    gap: 12px;
}}

/* Header principal */
.main-header {{
    background: linear-gradient(135deg, {config.COLORS['primary']} 0%, #374151 100%);
    color: white;
    padding: 32px;
    border-radius: 20px;
    margin-bottom: 32px;
    box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
}}

.main-header h1 {{
    font-size: 2.5rem;
    font-weight: 800;
    margin: 0 0 8px 0;
}}

.main-header p {{
    font-size: 1.125rem;
    opacity: 0.9;
    margin: 0;
}}

/* Status badges */
.status-badge {{
    display: inline-flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    border-radius: 20px;
    font-size: 0.875rem;
    font-weight: 600;
    backdrop-filter: blur(10px);
}}

.status-excellent {{ background: rgba(16, 185, 129, 0.2); color: {config.COLORS['success']}; }}
.status-good {{ background: rgba(245, 158, 11, 0.2); color: {config.COLORS['warning']}; }}
.status-poor {{ background: rgba(239, 68, 68, 0.2); color: {config.COLORS['danger']}; }}

/* Gr√°ficos melhorados */
.chart-container {{
    background: white;
    border-radius: 16px;
    padding: 24px;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    margin: 16px 0;
}}

/* Anima√ß√µes */
@keyframes slideIn {{
    from {{ opacity: 0; transform: translateY(20px); }}
    to {{ opacity: 1; transform: translateY(0); }}
}}

.animate-slide-in {{
    animation: slideIn 0.6s ease-out;
}}

/* Responsividade */
@media (max-width: 768px) {{
    .metric-card {{
        padding: 16px;
    }}
    
    .metric-value {{
        font-size: 1.875rem;
    }}
    
    .main-header {{
        padding: 24px;
    }}
    
    .main-header h1 {{
        font-size: 2rem;
    }}
}}

/* Loading states */
.loading-skeleton {{
    background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
    background-size: 200% 100%;
    animation: loading 1.5s infinite;
}}

@keyframes loading {{
    0% {{ background-position: 200% 0; }}
    100% {{ background-position: -200% 0; }}
}}

/* Scroll personalizado */
::-webkit-scrollbar {{
    width: 8px;
    height: 8px;
}}

::-webkit-scrollbar-track {{
    background: #f1f5f9;
    border-radius: 4px;
}}

::-webkit-scrollbar-thumb {{
    background: #cbd5e1;
    border-radius: 4px;
}}

::-webkit-scrollbar-thumb:hover {{
    background: #94a3b8;
}}
</style>
"""

st.markdown(MODERN_CSS, unsafe_allow_html=True)

# ============ UTILIT√ÅRIOS AVAN√áADOS ============
class DataProcessor:
    """Classe para processamento avan√ßado de dados"""
    
    @staticmethod
    @st.cache_data(ttl=config.CACHE_TTL, show_spinner=False)
    def detect_encoding(file_content: bytes) -> str:
        """Detecta encoding do arquivo automaticamente"""
        try:
            import chardet
            result = chardet.detect(file_content)
            return result.get('encoding', 'utf-8')
        except ImportError:
            # Fallback sem chardet
            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            for encoding in encodings:
                try:
                    file_content.decode(encoding)
                    return encoding
                except UnicodeDecodeError:
                    continue
            return 'utf-8'
    
    @staticmethod
    @st.cache_data(ttl=config.CACHE_TTL, show_spinner=False)
    def smart_csv_reader(file_content: bytes, filename: str) -> Optional[pd.DataFrame]:
        """Leitor inteligente de CSV com detec√ß√£o autom√°tica"""
        encoding = DataProcessor.detect_encoding(file_content)
        separators = [';', ',', '\t', '|']
        
        for sep in separators:
            try:
                bio = io.BytesIO(file_content)
                df = pd.read_csv(
                    bio, 
                    sep=sep, 
                    encoding=encoding,
                    engine='python',
                    skip_blank_lines=True,
                    low_memory=False
                )
                
                # Valida√ß√£o de qualidade
                if df.shape[1] > 1 and len(df) > 0:
                    # Limpeza autom√°tica
                    df.columns = [col.strip().strip('"\'') for col in df.columns]
                    
                    # Convers√£o de tipos inteligente
                    for col in df.columns:
                        if df[col].dtype == 'object':
                            df[col] = df[col].astype(str).str.strip().str.strip('"\'')
                            
                            # Tentativa de convers√£o num√©rica
                            if col.lower() in ['id', 'quantidade', 'idatendimento', 'iddocumento']:
                                df[col] = pd.to_numeric(df[col], errors='coerce')
                    
                    return df
                    
            except Exception:
                continue
        
        st.error(f"‚ùå N√£o foi poss√≠vel processar {filename}")
        return None

class MetricsCalculator:
    """Calculadora avan√ßada de m√©tricas"""
    
    @staticmethod
    def calculate_growth_rate(series: pd.Series, periods: int = 3) -> Optional[float]:
        """Calcula taxa de crescimento com an√°lise de tend√™ncia"""
        if len(series) < periods * 2:
            return None
        
        series = series.dropna().sort_index()
        if len(series) < periods * 2:
            return None
        
        # Divide em dois per√≠odos
        mid_point = len(series) // 2
        first_half = series.iloc[:mid_point].mean()
        second_half = series.iloc[mid_point:].mean()
        
        if first_half > 0:
            return ((second_half - first_half) / first_half) * 100
        return None
    
    @staticmethod
    def calculate_volatility(series: pd.Series) -> Optional[float]:
        """Calcula volatilidade da s√©rie"""
        if len(series) < 3:
            return None
        
        pct_change = series.pct_change().dropna()
        return pct_change.std() * 100 if len(pct_change) > 0 else None
    
    @staticmethod
    def calculate_efficiency_score(atendimentos: float, laudos: float, taxa_conversao: float) -> float:
        """Calcula score de efici√™ncia ponderado"""
        if atendimentos == 0:
            return 0
        
        # Pondera√ß√£o: 50% taxa convers√£o, 30% volume laudos, 20% volume atendimentos
        volume_score = min(laudos / 100, 1) * 30  # Normalizado para max 100 laudos
        conversion_score = min(taxa_conversao / 100, 1) * 50
        activity_score = min(atendimentos / 200, 1) * 20  # Normalizado para max 200 atendimentos
        
        return volume_score + conversion_score + activity_score

class VisualizationEngine:
    """Motor de visualiza√ß√µes avan√ßadas"""
    
    @staticmethod
    def create_modern_line_chart(df: pd.DataFrame, x_col: str, y_cols: List[str], 
                                title: str, colors: List[str] = None) -> go.Figure:
        """Cria gr√°fico de linha moderno"""
        fig = go.Figure()
        
        default_colors = [config.COLORS['secondary'], config.COLORS['success'], 
                         config.COLORS['warning'], config.COLORS['danger']]
        colors = colors or default_colors
        
        for i, y_col in enumerate(y_cols):
            if y_col in df.columns:
                fig.add_trace(go.Scatter(
                    x=df[x_col],
                    y=df[y_col],
                    mode='lines+markers',
                    name=y_col.replace('_', ' ').title(),
                    line=dict(color=colors[i % len(colors)], width=3),
                    marker=dict(size=6, symbol='circle'),
                    hovertemplate=f'<b>%{{fullData.name}}</b><br>%{{x}}<br>%{{y:,.0f}}<extra></extra>'
                ))
        
        fig.update_layout(
            title=dict(text=title, font=dict(size=18, weight='bold')),
            height=config.DEFAULT_CHART_HEIGHT,
            hovermode='x unified',
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font=dict(family="Inter, system-ui, sans-serif"),
            margin=dict(l=0, r=0, t=60, b=0)
        )
        
        fig.update_xaxes(
            showgrid=True,
            gridwidth=1,
            gridcolor='rgba(0,0,0,0.1)',
            showline=True,
            linewidth=1,
            linecolor='rgba(0,0,0,0.2)'
        )
        
        fig.update_yaxes(
            showgrid=True,
            gridwidth=1,
            gridcolor='rgba(0,0,0,0.1)',
            showline=True,
            linewidth=1,
            linecolor='rgba(0,0,0,0.2)'
        )
        
        return fig

def format_number(value: Union[float, int], decimal_places: int = 0, 
                 suffix: str = "") -> str:
    """Formata√ß√£o avan√ßada de n√∫meros"""
    if pd.isna(value) or value is None:
        return "‚Äî"
    
    try:
        if abs(value) >= 1_000_000:
            formatted = f"{value/1_000_000:.1f}M"
        elif abs(value) >= 1_000:
            formatted = f"{value/1_000:.1f}K"
        else:
            if decimal_places == 0:
                formatted = f"{int(round(value)):,}".replace(",", ".")
            else:
                formatted = f"{value:,.{decimal_places}f}".replace(",", "X").replace(".", ",").replace("X", ".")
        
        return f"{formatted}{suffix}"
    except (ValueError, TypeError):
        return "‚Äî"

def create_metric_card(title: str, value: str, delta: Optional[str] = None, 
                      icon: str = "üìä", delta_type: str = "neutral") -> str:
    """Cria card de m√©trica moderno"""
    delta_class = f"metric-delta {delta_type}" if delta else ""
    delta_html = f'<div class="{delta_class}">{delta}</div>' if delta else ""
    
    return f"""
    <div class="metric-card animate-slide-in">
        <div class="metric-title">{icon} {title}</div>
        <div class="metric-value">{value}</div>
        {delta_html}
    </div>
    """

# ============ HEADER PRINCIPAL ============
def render_main_header():
    """Renderiza header principal"""
    current_time = datetime.now().strftime("%d/%m/%Y %H:%M")
    
    st.markdown(f"""
    <div class="main-header">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <h1>üè• Dashboard Executivo {config.COMPANY}</h1>
                <p>Sistema Avan√ßado de Monitoramento e An√°lise Operacional</p>
            </div>
            <div style="text-align: right;">
                <div class="status-badge status-excellent">
                    <span>üöÄ</span> v{config.VERSION}
                </div>
                <div style="margin-top: 8px; opacity: 0.8; font-size: 0.9rem;">
                    Atualizado: {current_time}
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

render_main_header()

# ============ CONFIGURA√á√ÉO DE DADOS ============
ENHANCED_COLUMN_MAPPINGS = {
    "detalhes_laudospendentes": {
        "date_columns": ["data_solicitacao"],
        "id_column": "caso_sirsaelp",
        "dimensions": {
            "unidade": "unidade",
            "superintendencia": "superintendencia",
            "diretoria": "diretoria",
            "tipo": "tipopericia",
            "perito": "perito",
            "competencia": "competencia"
        }
    },
    "detalhes_examespendentes": {
        "date_columns": ["data_solicitacao"],
        "id_column": "caso_sirsaelp",
        "dimensions": {
            "unidade": "unidade",
            "superintendencia": "superintendencia",
            "diretoria": "diretoria",
            "tipo": "tipopericia",
            "competencia": "competencia"
        }
    },
    "Atendimentos_todos_Mensal": {
        "date_columns": ["data_interesse"],
        "id_column": "idatendimento",
        "quantity_column": "idatendimento",
        "aggregation_level": "monthly"
    },
    "Laudos_todos_Mensal": {
        "date_columns": ["data_interesse"],
        "id_column": "iddocumento",
        "quantity_column": "iddocumento",
        "aggregation_level": "monthly"
    },
    "Atendimentos_especifico_Mensal": {
        "date_columns": ["data_interesse"],
        "id_column": "idatendimento",
        "quantity_column": "idatendimento",
        "dimensions": {"tipo": "txcompetencia"},
        "aggregation_level": "monthly"
    },
    "Laudos_especifico_Mensal": {
        "date_columns": ["data_interesse"],
        "id_column": "iddocumento",
        "quantity_column": "iddocumento",
        "dimensions": {"tipo": "txcompetencia"},
        "aggregation_level": "monthly"
    },
    "Atendimentos_diario": {
        "date_columns": ["data_interesse"],
        "id_column": "idatendimento",
        "quantity_column": "idatendimento",
        "aggregation_level": "daily"
    },
    "Laudos_diario": {
        "date_columns": ["data_interesse"],
        "id_column": "iddocumento",
        "quantity_column": "iddocumento",
        "aggregation_level": "daily"
    }
}

@st.cache_data(ttl=config.CACHE_TTL, show_spinner=False)
def standardize_dataframe(name: str, df: pd.DataFrame) -> pd.DataFrame:
    """Padroniza√ß√£o inteligente de DataFrames"""
    if df is None or df.empty:
        return pd.DataFrame()
    
    result = df.copy()
    mapping = ENHANCED_COLUMN_MAPPINGS.get(name, {})
    
    # Normaliza√ß√£o de colunas
    result.columns = [col.lower().strip().replace(' ', '_') for col in result.columns]
    
    # Processamento de quantidade
    quantity_col = mapping.get("quantity_column")
    if quantity_col and quantity_col in result.columns:
        result["quantidade"] = pd.to_numeric(result[quantity_col], errors="coerce").fillna(1)
    else:
        result["quantidade"] = 1
    
    # Processamento de dimens√µes
    dimensions = mapping.get("dimensions", {})
    for target_col, source_col in dimensions.items():
        if source_col in result.columns:
            result[target_col] = (result[source_col]
                                 .astype(str)
                                 .str.strip()
                                 .str.title()
                                 .replace({"Nan": None, "": None}))
    
    # Processamento de datas avan√ßado
    date_columns = mapping.get("date_columns", [])
    for date_col in date_columns:
        if date_col in result.columns:
            processed_date = pd.to_datetime(result[date_col], 
                                          errors="coerce", 
                                          dayfirst=True,
                                          infer_datetime_format=True)
            if processed_date.notna().any():
                result["data_base"] = processed_date
                result["anom√™s_dt"] = processed_date.dt.to_period("M").dt.to_timestamp()
                result["anom√™s"] = result["anom√™s_dt"].dt.strftime("%Y-%m")
                result["ano"] = result["anom√™s_dt"].dt.year
                result["mes"] = result["anom√™s_dt"].dt.month
                result["dia"] = processed_date.dt.normalize()
                result["dia_semana"] = processed_date.dt.day_name()
                break
    
    # ID √∫nico
    id_col = mapping.get("id_column")
    if id_col and id_col in result.columns:
        result["id"] = result[id_col].astype(str)
    
    return result

# ============ SIDEBAR AVAN√áADA ============
with st.sidebar:
    st.markdown("""
    <div style="background: linear-gradient(135deg, #1f2937 0%, #374151 100%); 
                color: white; padding: 20px; border-radius: 16px; margin-bottom: 20px;">
        <h3 style="margin: 0; color: white;">üéõÔ∏è Controle Central</h3>
        <p style="margin: 8px 0 0 0; opacity: 0.9;">Configura√ß√µes e filtros avan√ßados</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Upload de arquivos com interface melhorada
    st.subheader("üìÅ Gest√£o de Dados")
    
    with st.expander("üì§ Upload de Arquivos", expanded=True):
        uploaded_files = st.file_uploader(
            "Selecione os arquivos CSV",
            type=['csv'],
            accept_multiple_files=True,
            help="Arraste e solte arquivos CSV ou clique para selecionar"
        )
    
    # Configura√ß√µes de exibi√ß√£o
    st.subheader("‚öôÔ∏è Configura√ß√µes")
    
    chart_height = st.slider(
        "üìè Altura dos Gr√°ficos",
        min_value=300,
        max_value=700,
        value=config.DEFAULT_CHART_HEIGHT,
        step=50,
        help="Ajuste a altura dos gr√°ficos para melhor visualiza√ß√£o"
    )
    
    show_benchmarks = st.toggle(
        "üìä Exibir Metas e Benchmarks",
        value=True,
        help="Mostra linhas de refer√™ncia nos gr√°ficos"
    )
    
    auto_refresh = st.toggle(
        "üîÑ Atualiza√ß√£o Autom√°tica",
        value=False,
        help="Atualiza dados automaticamente a cada 5 minutos"
    )
    
    if auto_refresh:
        st.rerun()

# ============ PROCESSAMENTO DE DADOS ============
@st.cache_data(ttl=config.CACHE_TTL, show_spinner="Processando dados...")
def load_and_process_data(files: List) -> Dict[str, pd.DataFrame]:
    """Carrega e processa todos os dados"""
    dataframes = {}
    
    if not files:
        # Tentar carregar da pasta data/
        if os.path.exists("data"):
            for filename in os.listdir("data"):
                if filename.endswith('.csv'):
                    filepath = os.path.join("data", filename)
                    with open(filepath, 'rb') as f:
                        content = f.read()
                    
                    df = DataProcessor.smart_csv_reader(content, filename)
                    if df is not None:
                        # Detectar tipo de dataset pelo nome
                        base_name = os.path.splitext(filename)[0].lower()
                        dataset_name = detect_dataset_type(base_name)
                        dataframes[dataset_name] = standardize_dataframe(dataset_name, df)
        return dataframes
    
    # Processar uploads
    for uploaded_file in files:
        if uploaded_file is not None:
            content = uploaded_file.read()
            df = DataProcessor.smart_csv_reader(content, uploaded_file.name)
            
            if df is not None:
                base_name = os.path.splitext(uploaded_file.name)[0].lower()
                dataset_name = detect_dataset_type(base_name)
                dataframes[dataset_name] = standardize_dataframe(dataset_name, df)
    
    return dataframes

def detect_dataset_type(filename: str) -> str:
    """Detecta o tipo de dataset pelo nome do arquivo"""
    filename = filename.lower().replace(' ', '_').replace('-', '_')
    
    patterns = {
        'atendimentos_todos': 'Atendimentos_todos_Mensal',
        'laudos_todos': 'Laudos_todos_Mensal',
        'atendimentos_especifico': 'Atendimentos_especifico_Mensal',
        'laudos_especifico': 'Laudos_especifico_Mensal',
        'atendimentos_diario': 'Atendimentos_diario',
        'laudos_diario': 'Laudos_diario',
        'laudospendentes': 'detalhes_laudospendentes',
        'examespendentes': 'detalhes_examespendentes'
    }
    
    for pattern, dataset_type in patterns.items():
        if pattern in filename:
            return dataset_type
    
    return filename

# Carregar dados
with st.spinner("üîÑ Carregando e processando dados..."):
    dataframes = load_and_process_data(uploaded_files if 'uploaded_files' in locals() else [])

# Valida√ß√£o e feedback
if not dataframes:
    st.warning("‚ö†Ô∏è Nenhum arquivo de dados foi carregado")
    st.info("""
    üìù **Para come√ßar:**
    - Fa√ßa upload dos arquivos CSV usando a sidebar
    - Ou coloque os arquivos na pasta `data/` do projeto
    
    **Arquivos esperados:** Atendimentos, Laudos, Pend√™ncias
    """)
    st.stop()

# Resumo dos dados carregados
with st.sidebar:
    st.success(f"‚úÖ {len(dataframes)} datasets carregados")
    for name, df in dataframes.items():
        if not df.empty:
            st.write(f"üìä {name.replace('_', ' ')}: {len(df):,} registros")

# ============ FILTROS INTELIGENTES ============
class FilterEngine:
    """Sistema avan√ßado de filtros"""
    
    @staticmethod
    def extract_unique_values(dataframes: Dict[str, pd.DataFrame], column: str) -> List[str]:
        """Extrai valores √∫nicos de uma coluna em todos os dataframes"""
        values = set()
        for df in dataframes.values():
            if df is not None and column in df.columns:
                unique_vals = df[column].dropna().astype(str).unique()
                values.update(v for v in unique_vals if v and v.lower() not in ["nan", "none", ""])
        return sorted(list(values))
    
    @staticmethod
    def get_date_range(dataframes: Dict[str, pd.DataFrame]) -> Tuple[Optional[datetime], Optional[datetime]]:
        """Obt√©m o range de datas dispon√≠vel"""
        min_date, max_date = None, None
        
        for df in dataframes.values():
            if df is not None and 'data_base' in df.columns:
                df_min = df['data_base'].min()
                df_max = df['data_base'].max()
                
                if pd.notna(df_min):
                    min_date = df_min if min_date is None else min(min_date, df_min)
                if pd.notna(df_max):
                    max_date = df_max if max_date is None else max(max_date, df_max)
        
        return min_date, max_date

filter_engine = FilterEngine()

# Configura√ß√£o de filtros na sidebar
with st.sidebar:
    st.markdown("### üîç Filtros Avan√ßados")
    
    # Filtros dimensionais com interface melhorada
    col1, col2 = st.columns(2)
    
    with col1:
        diretorias = st.multiselect(
            "üè¢ Diretoria",
            filter_engine.extract_unique_values(dataframes, "diretoria"),
            help="Filtrar por diretoria espec√≠fica"
        )
        
        unidades = st.multiselect(
            "üè™ Unidade",
            filter_engine.extract_unique_values(dataframes, "unidade"),
            help="Filtrar por unidade operacional"
        )
    
    with col2:
        superintendencias = st.multiselect(
            "üèõÔ∏è Superintend√™ncia",
            filter_engine.extract_unique_values(dataframes, "superintendencia"),
            help="Filtrar por superintend√™ncia"
        )
        
        tipos = st.multiselect(
            "üî¨ Tipo",
            filter_engine.extract_unique_values(dataframes, "tipo"),
            help="Filtrar por tipo de per√≠cia"
        )
    
    # Filtro temporal avan√ßado
    st.markdown("#### üìÖ Per√≠odo de An√°lise")
    
    min_date, max_date = filter_engine.get_date_range(dataframes)
    
    if min_date and max_date:
        period_type = st.radio(
            "Tipo de per√≠odo:",
            ["Predefinido", "Personalizado"],
            horizontal=True
        )
        
        if period_type == "Predefinido":
            period_options = {
                "Todo o per√≠odo": None,
                "√öltimo ano": 365,
                "√öltimos 6 meses": 180,
                "√öltimos 3 meses": 90,
                "√öltimo m√™s": 30
            }
            
            selected_period = st.selectbox(
                "Per√≠odo:",
                list(period_options.keys())
            )
            
            if period_options[selected_period]:
                start_date = max_date - timedelta(days=period_options[selected_period])
                end_date = max_date
            else:
                start_date, end_date = min_date, max_date
        else:
            date_range = st.date_input(
                "Selecione o per√≠odo:",
                value=(min_date.date(), max_date.date()),
                min_value=min_date.date(),
                max_value=max_date.date()
            )
            
            if isinstance(date_range, tuple) and len(date_range) == 2:
                start_date = pd.Timestamp(date_range[0])
                end_date = pd.Timestamp(date_range[1])
            else:
                start_date, end_date = min_date, max_date
    else:
        start_date = end_date = None

# Aplicar filtros
@st.cache_data(ttl=config.CACHE_TTL)
def apply_filters(dataframes: Dict[str, pd.DataFrame], filters: Dict) -> Dict[str, pd.DataFrame]:
    """Aplica filtros avan√ßados aos dataframes"""
    filtered_dfs = {}
    
    for name, df in dataframes.items():
        if df is None or df.empty:
            filtered_dfs[name] = df
            continue
        
        filtered = df.copy()
        
        # Filtros dimensionais
        for filter_name, values in filters.get('dimensions', {}).items():
            if values and filter_name in filtered.columns:
                filtered = filtered[filtered[filter_name].isin(values)]
        
        # Filtro temporal
        if 'data_base' in filtered.columns and filters.get('start_date') and filters.get('end_date'):
            filtered = filtered[
                (filtered['data_base'] >= filters['start_date']) &
                (filtered['data_base'] <= filters['end_date'])
            ]
        
        filtered_dfs[name] = filtered
    
    return filtered_dfs

# Consolidar filtros
filters = {
    'dimensions': {
        'diretoria': diretorias,
        'superintendencia': superintendencias,
        'unidade': unidades,
        'tipo': tipos
    },
    'start_date': start_date,
    'end_date': end_date
}

# Aplicar filtros
filtered_dataframes = apply_filters(dataframes, filters)

# ============ C√ÅLCULO DE M√âTRICAS PRINCIPAIS ============
class KPIEngine:
    """Motor de c√°lculo de KPIs avan√ßados"""
    
    def __init__(self, dataframes: Dict[str, pd.DataFrame]):
        self.dfs = dataframes
        self.calc = MetricsCalculator()
    
    def get_production_metrics(self) -> Dict[str, Any]:
        """Calcula m√©tricas de produ√ß√£o"""
        df_atend = self.dfs.get("Atendimentos_todos_Mensal")
        df_laudos = self.dfs.get("Laudos_todos_Mensal")
        
        metrics = {}
        
        if df_atend is not None and not df_atend.empty:
            metrics['total_atendimentos'] = df_atend['quantidade'].sum()
            metrics['media_mensal_atendimentos'] = df_atend.groupby('anom√™s_dt')['quantidade'].sum().mean()
            
            # Tend√™ncia
            monthly_atend = df_atend.groupby('anom√™s_dt')['quantidade'].sum().sort_index()
            metrics['crescimento_atendimentos'] = self.calc.calculate_growth_rate(monthly_atend)
            metrics['volatilidade_atendimentos'] = self.calc.calculate_volatility(monthly_atend)
        
        if df_laudos is not None and not df_laudos.empty:
            metrics['total_laudos'] = df_laudos['quantidade'].sum()
            metrics['media_mensal_laudos'] = df_laudos.groupby('anom√™s_dt')['quantidade'].sum().mean()
            
            # Tend√™ncia
            monthly_laudos = df_laudos.groupby('anom√™s_dt')['quantidade'].sum().sort_index()
            metrics['crescimento_laudos'] = self.calc.calculate_growth_rate(monthly_laudos)
            metrics['volatilidade_laudos'] = self.calc.calculate_volatility(monthly_laudos)
        
        # Taxa de convers√£o
        if metrics.get('total_atendimentos', 0) > 0:
            metrics['taxa_conversao'] = (metrics.get('total_laudos', 0) / metrics['total_atendimentos']) * 100
        
        return metrics
    
    def get_pendency_metrics(self) -> Dict[str, Any]:
        """Calcula m√©tricas de pend√™ncias"""
        df_pend_laudos = self.dfs.get("detalhes_laudospendentes")
        df_pend_exames = self.dfs.get("detalhes_examespendentes")
        
        metrics = {}
        
        def calculate_aging_stats(df: pd.DataFrame) -> Dict:
            if df is None or df.empty or 'data_base' not in df.columns:
                return {}
            
            hoje = pd.Timestamp.now().normalize()
            aging_days = (hoje - df['data_base']).dt.days
            
            return {
                'total': len(df),
                'media_dias': aging_days.mean(),
                'mediana_dias': aging_days.median(),
                'max_dias': aging_days.max(),
                'p90_dias': aging_days.quantile(0.9),
                'criticos': (aging_days > config.BENCHMARKS['aging_critico']).sum(),
                'urgentes': (aging_days > config.BENCHMARKS['aging_atencao']).sum()
            }
        
        metrics['laudos_pendentes'] = calculate_aging_stats(df_pend_laudos)
        metrics['exames_pendentes'] = calculate_aging_stats(df_pend_exames)
        
        # Backlog estimado
        media_laudos = self.get_production_metrics().get('media_mensal_laudos', 0)
        total_pend_laudos = metrics['laudos_pendentes'].get('total', 0)
        
        if media_laudos > 0:
            metrics['backlog_meses'] = total_pend_laudos / media_laudos
        
        return metrics
    
    def get_efficiency_metrics(self) -> Dict[str, Any]:
        """Calcula m√©tricas de efici√™ncia"""
        production = self.get_production_metrics()
        pendency = self.get_pendency_metrics()
        
        metrics = {}
        
        # Score de efici√™ncia global
        atend = production.get('total_atendimentos', 0)
        laudos = production.get('total_laudos', 0)
        taxa_conv = production.get('taxa_conversao', 0)
        
        metrics['efficiency_score'] = self.calc.calculate_efficiency_score(atend, laudos, taxa_conv)
        
        # Status baseado em benchmarks
        if taxa_conv >= config.BENCHMARKS['taxa_conversao_excelente']:
            metrics['conversion_status'] = 'excellent'
        elif taxa_conv >= config.BENCHMARKS['taxa_conversao_boa']:
            metrics['conversion_status'] = 'good'
        elif taxa_conv >= config.BENCHMARKS['taxa_conversao_minima']:
            metrics['conversion_status'] = 'fair'
        else:
            metrics['conversion_status'] = 'poor'
        
        # Status do backlog
        backlog = pendency.get('backlog_meses', 0)
        if backlog <= config.BENCHMARKS['backlog_atencao']:
            metrics['backlog_status'] = 'excellent'
        elif backlog <= config.BENCHMARKS['backlog_critico']:
            metrics['backlog_status'] = 'good'
        else:
            metrics['backlog_status'] = 'poor'
        
        return metrics

# Calcular m√©tricas
kpi_engine = KPIEngine(filtered_dataframes)
production_metrics = kpi_engine.get_production_metrics()
pendency_metrics = kpi_engine.get_pendency_metrics()
efficiency_metrics = kpi_engine.get_efficiency_metrics()

# ============ DASHBOARD PRINCIPAL ============
st.markdown('<h2 class="section-header">üìä Indicadores Principais de Performance</h2>', unsafe_allow_html=True)

# Linha 1: M√©tricas de Produ√ß√£o
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_atend = production_metrics.get('total_atendimentos', 0)
    cresc_atend = production_metrics.get('crescimento_atendimentos')
    
    delta_text = None
    delta_type = "neutral"
    if cresc_atend is not None:
        delta_text = f"‚ÜóÔ∏è {format_number(cresc_atend, 1)}%" if cresc_atend > 0 else f"‚ÜòÔ∏è {format_number(abs(cresc_atend), 1)}%"
        delta_type = "positive" if cresc_atend > 0 else "negative"
    
    card_html = create_metric_card(
        "Atendimentos Totais",
        format_number(total_atend),
        delta_text,
        "üë•",
        delta_type
    )
    st.markdown(card_html, unsafe_allow_html=True)

with col2:
    total_laudos = production_metrics.get('total_laudos', 0)
    cresc_laudos = production_metrics.get('crescimento_laudos')
    
    delta_text = None
    delta_type = "neutral"
    if cresc_laudos is not None:
        delta_text = f"‚ÜóÔ∏è {format_number(cresc_laudos, 1)}%" if cresc_laudos > 0 else f"‚ÜòÔ∏è {format_number(abs(cresc_laudos), 1)}%"
        delta_type = "positive" if cresc_laudos > 0 else "negative"
    
    card_html = create_metric_card(
        "Laudos Emitidos",
        format_number(total_laudos),
        delta_text,
        "üìã",
        delta_type
    )
    st.markdown(card_html, unsafe_allow_html=True)

with col3:
    taxa_conv = production_metrics.get('taxa_conversao', 0)
    conv_status = efficiency_metrics.get('conversion_status', 'poor')
    
    status_icons = {
        'excellent': 'üü¢',
        'good': 'üü°',
        'fair': 'üü†',
        'poor': 'üî¥'
    }
    
    card_html = create_metric_card(
        "Taxa de Convers√£o",
        f"{status_icons[conv_status]} {format_number(taxa_conv, 1)}%",
        f"Meta: {config.BENCHMARKS['taxa_conversao_boa']}%",
        "üéØ",
        "positive" if conv_status in ['excellent', 'good'] else "negative"
    )
    st.markdown(card_html, unsafe_allow_html=True)

with col4:
    media_laudos = production_metrics.get('media_mensal_laudos', 0)
    efficiency_score = efficiency_metrics.get('efficiency_score', 0)
    
    card_html = create_metric_card(
        "Produtividade Mensal",
        f"{format_number(media_laudos)} laudos",
        f"Score: {format_number(efficiency_score, 1)}/100",
        "‚ö°",
        "positive" if efficiency_score > 70 else "neutral"
    )
    st.markdown(card_html, unsafe_allow_html=True)

# Linha 2: M√©tricas de Pend√™ncias
st.markdown('<h2 class="section-header">‚è∞ Gest√£o de Pend√™ncias e Backlog</h2>', unsafe_allow_html=True)

col5, col6, col7, col8 = st.columns(4)

with col5:
    total_pend_laudos = pendency_metrics['laudos_pendentes'].get('total', 0)
    criticos_laudos = pendency_metrics['laudos_pendentes'].get('criticos', 0)
    
    pct_criticos = (criticos_laudos / total_pend_laudos * 100) if total_pend_laudos > 0 else 0
    status_icon = "üî¥" if pct_criticos > 20 else "üü°" if pct_criticos > 10 else "üü¢"
    
    card_html = create_metric_card(
        "Laudos Pendentes",
        f"{status_icon} {format_number(total_pend_laudos)}",
        f"Cr√≠ticos: {format_number(criticos_laudos)} ({format_number(pct_criticos, 1)}%)",
        "üìã",
        "negative" if pct_criticos > 20 else "neutral"
    )
    st.markdown(card_html, unsafe_allow_html=True)

with col6:
    total_pend_exames = pendency_metrics['exames_pendentes'].get('total', 0)
    criticos_exames = pendency_metrics['exames_pendentes'].get('criticos', 0)
    
    pct_criticos_ex = (criticos_exames / total_pend_exames * 100) if total_pend_exames > 0 else 0
    status_icon = "üî¥" if pct_criticos_ex > 20 else "üü°" if pct_criticos_ex > 10 else "üü¢"
    
    card_html = create_metric_card(
        "Exames Pendentes",
        f"{status_icon} {format_number(total_pend_exames)}",
        f"Cr√≠ticos: {format_number(criticos_exames)} ({format_number(pct_criticos_ex, 1)}%)",
        "üî¨",
        "negative" if pct_criticos_ex > 20 else "neutral"
    )
    st.markdown(card_html, unsafe_allow_html=True)

with col7:
    backlog_meses = pendency_metrics.get('backlog_meses', 0)
    backlog_status = efficiency_metrics.get('backlog_status', 'poor')
    
    status_icons = {
        'excellent': 'üü¢',
        'good': 'üü°',
        'poor': 'üî¥'
    }
    
    card_html = create_metric_card(
        "Backlog Estimado",
        f"{status_icons[backlog_status]} {format_number(backlog_meses, 1)} meses",
        f"Meta: < {config.BENCHMARKS['backlog_atencao']} meses",
        "üìà",
        "negative" if backlog_status == 'poor' else "neutral"
    )
    st.markdown(card_html, unsafe_allow_html=True)

with col8:
    media_aging_laudos = pendency_metrics['laudos_pendentes'].get('media_dias', 0)
    media_aging_exames = pendency_metrics['exames_pendentes'].get('media_dias', 0)
    aging_medio = max(media_aging_laudos, media_aging_exames)
    
    status_icon = ("üî¥" if aging_medio > config.BENCHMARKS['aging_critico'] 
                  else "üü°" if aging_medio > config.BENCHMARKS['aging_atencao'] 
                  else "üü¢")
    
    card_html = create_metric_card(
        "Aging M√©dio",
        f"{status_icon} {format_number(aging_medio)} dias",
        f"P90: {format_number(max(pendency_metrics['laudos_pendentes'].get('p90_dias', 0), pendency_metrics['exames_pendentes'].get('p90_dias', 0)))} dias",
        "‚è±Ô∏è",
        "negative" if aging_medio > config.BENCHMARKS['aging_critico'] else "neutral"
    )
    st.markdown(card_html, unsafe_allow_html=True)

# ============ SISTEMA DE ALERTAS INTELIGENTES ============
class AlertSystem:
    """Sistema inteligente de alertas"""
    
    @staticmethod
    def generate_alerts(production: Dict, pendency: Dict, efficiency: Dict) -> List[Dict]:
        """Gera alertas baseados em regras de neg√≥cio"""
        alerts = []
        
        # Alertas cr√≠ticos
        backlog = pendency.get('backlog_meses', 0)
        if backlog > config.BENCHMARKS['backlog_critico']:
            alerts.append({
                'type': 'danger',
                'title': 'BACKLOG CR√çTICO',
                'message': f'Backlog de {format_number(backlog, 1)} meses excede limite cr√≠tico ({config.BENCHMARKS["backlog_critico"]} meses)',
                'priority': 1
            })
        
        taxa_conv = production.get('taxa_conversao', 0)
        if taxa_conv < config.BENCHMARKS['taxa_conversao_minima']:
            alerts.append({
                'type': 'danger',
                'title': 'EFICI√äNCIA CR√çTICA',
                'message': f'Taxa de convers√£o de {format_number(taxa_conv, 1)}% abaixo do m√≠nimo aceit√°vel ({config.BENCHMARKS["taxa_conversao_minima"]}%)',
                'priority': 1
            })
        
        # Alertas de aten√ß√£o
        cresc_laudos = production.get('crescimento_laudos', 0)
        if cresc_laudos < -15:
            alerts.append({
                'type': 'warning',
                'title': 'QUEDA NA PRODU√á√ÉO',
                'message': f'Redu√ß√£o significativa de {format_number(abs(cresc_laudos), 1)}% na emiss√£o de laudos',
                'priority': 2
            })
        
        # Alertas informativos
        if taxa_conv >= config.BENCHMARKS['taxa_conversao_excelente']:
            alerts.append({
                'type': 'info',
                'title': 'PERFORMANCE EXCELENTE',
                'message': f'Taxa de convers√£o de {format_number(taxa_conv, 1)}% acima da meta de excel√™ncia',
                'priority': 3
            })
        
        return sorted(alerts, key=lambda x: x['priority'])

alert_system = AlertSystem()
alerts = alert_system.generate_alerts(production_metrics, pendency_metrics, efficiency_metrics)

# Exibir alertas
if alerts:
    st.markdown('<h2 class="section-header">üö® Central de Alertas e Insights</h2>', unsafe_allow_html=True)
    
    # Organizar alertas por tipo
    critical_alerts = [a for a in alerts if a['type'] == 'danger']
    warning_alerts = [a for a in alerts if a['type'] == 'warning']
    info_alerts = [a for a in alerts if a['type'] == 'info']
    
    # Exibir alertas cr√≠ticos primeiro
    for alert in critical_alerts[:3]:  # M√°ximo 3 cr√≠ticos
        st.markdown(f"""
        <div class="alert alert-{alert['type']}">
            <strong>üî¥ {alert['title']}</strong><br>
            {alert['message']}
        </div>
        """, unsafe_allow_html=True)
    
    # Alertas de aten√ß√£o em colunas
    if warning_alerts:
        cols = st.columns(min(len(warning_alerts), 2))
        for i, alert in enumerate(warning_alerts[:2]):
            with cols[i]:
                st.markdown(f"""
                <div class="alert alert-{alert['type']}">
                    <strong>üü° {alert['title']}</strong><br>
                    {alert['message']}
                </div>
                """, unsafe_allow_html=True)
    
    # Alertas informativos
    if info_alerts and not critical_alerts:  # S√≥ mostrar se n√£o h√° cr√≠ticos
        st.markdown(f"""
        <div class="alert alert-{info_alerts[0]['type']}">
            <strong>‚ÑπÔ∏è {info_alerts[0]['title']}</strong><br>
            {info_alerts[0]['message']}
        </div>
        """, unsafe_allow_html=True)
else:
    st.markdown("""
    <div class="alert alert-success">
        <strong>‚úÖ SITUA√á√ÉO OPERACIONAL NORMAL</strong><br>
        Todos os indicadores est√£o dentro dos par√¢metros esperados. Sistema operando com efici√™ncia.
    </div>
    """, unsafe_allow_html=True)
