import io
import os
import re
from datetime import datetime, timedelta
from typing import Dict, Optional, Tuple, List

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ============ CONFIGURA√á√ÉO INICIAL ============
st.set_page_config(
    page_title="PCI/SC ‚Äì Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üè• Dashboard PCI/SC ‚Äì Produ√ß√£o & Pend√™ncias")
st.markdown("---")

# ============ CACHE E PERFORMANCE ============
@st.cache_data
def read_csv_optimized(file_content: bytes, filename: str) -> Optional[pd.DataFrame]:
    """L√™ CSV com detec√ß√£o autom√°tica de separador e encoding otimizada."""
    # Para arquivos PCI/SC, o separador principal √© ponto e v√≠rgula
    separators = [";", ",", "\t", "|"]
    encodings = ["utf-8", "latin-1", "cp1252"]
    
    for encoding in encodings:
        for sep in separators:
            try:
                bio = io.BytesIO(file_content)
                df = pd.read_csv(bio, sep=sep, encoding=encoding, engine="python")
                # Verifica se realmente separou as colunas (mais de 1 coluna)
                if df.shape[1] > 1:
                    # Remove aspas extras se existirem
                    df.columns = [col.strip('"').strip() for col in df.columns]
                    
                    # Limpa dados das c√©lulas tamb√©m
                    for col in df.columns:
                        if df[col].dtype == 'object':
                            df[col] = df[col].astype(str).str.strip('"').str.strip()
                    
                    return df
            except Exception:
                continue
    
    # Fallback para detec√ß√£o autom√°tica
    try:
        bio = io.BytesIO(file_content)
        df = pd.read_csv(bio, sep=None, engine="python", encoding="utf-8")
        if df.shape[1] > 1:
            df.columns = [col.strip('"').strip() for col in df.columns]
            return df
    except Exception:
        pass
    
    return None

@st.cache_data
def process_datetime_column(series: pd.Series, dayfirst: bool = True) -> Optional[pd.Series]:
    """Processa coluna de data/hora com m√∫ltiplos formatos."""
    if series is None or series.empty:
        return None
    
    # Primeiro tenta convers√£o direta
    dt_series = pd.to_datetime(
        series, 
        errors="coerce", 
        dayfirst=dayfirst, 
        infer_datetime_format=True
    )
    
    # Se muitas datas inv√°lidas, tenta outros formatos
    if dt_series.isna().sum() > len(dt_series) * 0.5:
        for fmt in ["%d/%m/%Y", "%Y-%m-%d", "%m/%d/%Y", "%d-%m-%Y"]:
            try:
                dt_series = pd.to_datetime(series, format=fmt, errors="coerce")
                if dt_series.notna().sum() > len(dt_series) * 0.5:
                    break
            except Exception:
                continue
    
    return dt_series if dt_series.notna().any() else None

# ============ UTILIT√ÅRIOS MELHORADOS ============
def format_number(value: float, decimal_places: int = 0) -> str:
    """Formata n√∫meros com separadores brasileiros."""
    if pd.isna(value):
        return "‚Äî"
    
    try:
        if decimal_places == 0:
            return f"{int(round(value)):,}".replace(",", ".")
        else:
            return f"{value:,.{decimal_places}f}".replace(",", "X").replace(".", ",").replace("X", ".")
    except (ValueError, TypeError):
        return "‚Äî"

def calculate_percentage(numerator: float, denominator: float) -> Optional[float]:
    """Calcula percentual com valida√ß√£o."""
    if pd.isna(numerator) or pd.isna(denominator) or denominator == 0:
        return None
    return (numerator / denominator) * 100

def get_period_filter_options(df: pd.DataFrame) -> List[str]:
    """Gera op√ß√µes de filtro de per√≠odo baseado nos dados."""
    if df is None or "anom√™s_dt" not in df.columns:
        return []
    
    dates = df["anom√™s_dt"].dropna()
    if dates.empty:
        return []
    
    periods = []
    min_date = dates.min()
    max_date = dates.max()
    
    # √öltimos per√≠odos
    now = pd.Timestamp.now()
    periods.extend([
        "√öltimos 3 meses",
        "√öltimos 6 meses", 
        "√öltimo ano",
        "Ano atual",
        "Todo o per√≠odo"
    ])
    
    return periods

# ============ DETEC√á√ÉO DE ARQUIVOS ============
@st.cache_data
def detect_data_sources():
    """Detecta se existem arquivos na pasta data/."""
    return os.path.exists("data") and any(
        p.endswith(".csv") for p in os.listdir("data")
    )

has_data_dir = detect_data_sources()

# ============ INTERFACE DE UPLOAD ============
st.sidebar.header("üìÅ Configura√ß√£o de Dados")

if not has_data_dir:
    st.sidebar.info("üí° Envie os arquivos CSV dispon√≠veis. O dashboard se adapta automaticamente.")

# Defini√ß√£o dos arquivos esperados
file_configs = {
    "Atendimentos_todos_Mensal": {
        "label": "Atendimentos Todos (Mensal)",
        "description": "Dados gerais de atendimentos por m√™s - agregados por compet√™ncia",
        "pattern": ["atendimentos_todos", "atendimentos todos"]
    },
    "Laudos_todos_Mensal": {
        "label": "Laudos Todos (Mensal)", 
        "description": "Dados gerais de laudos por m√™s - agregados por compet√™ncia",
        "pattern": ["laudos_todos", "laudos todos"]
    },
    "Atendimentos_especifico_Mensal": {
        "label": "Atendimentos Espec√≠ficos (Mensal)",
        "description": "Atendimentos detalhados por compet√™ncia e tipo",
        "pattern": ["atendimentos_especifico", "atendimentos especifico"]
    },
    "Laudos_especifico_Mensal": {
        "label": "Laudos Espec√≠ficos (Mensal)",
        "description": "Laudos detalhados por compet√™ncia e tipo",
        "pattern": ["laudos_especifico", "laudos especifico"]
    },
    "laudos_realizados": {
        "label": "Laudos Realizados",
        "description": "Hist√≥rico detalhado de laudos conclu√≠dos com TME",
        "pattern": ["laudos_realizados", "laudos realizados"]
    },
    "detalhes_laudospendentes": {
        "label": "Laudos Pendentes",
        "description": "Laudos aguardando conclus√£o com aging",
        "pattern": ["laudospendentes", "laudos_pendentes", "detalhes_laudospendentes"]
    },
    "detalhes_examespendentes": {
        "label": "Exames Pendentes", 
        "description": "Exames aguardando realiza√ß√£o com aging",
        "pattern": ["examespendentes", "exames_pendentes", "detalhes_examespendentes"]
    }
}

uploads = {}
for key, config in file_configs.items():
    if not has_data_dir:
        uploads[key] = st.sidebar.file_uploader(
            f"{config['label']} (.csv)",
            help=config['description'],
            key=f"upload_{key}"
        )
    else:
        uploads[key] = None

# ============ RESOLU√á√ÉO DE ARQUIVOS ============
def resolve_file_path(name: str) -> Optional[str]:
    """Resolve caminho do arquivo com toler√¢ncia a varia√ß√µes de nome."""
    if not os.path.exists("data"):
        return None
    
    # Usar padr√µes espec√≠ficos se dispon√≠veis
    config = file_configs.get(name, {})
    patterns = config.get("pattern", [name.lower().replace(" ", "_")])
    
    # Adiciona o nome original tamb√©m
    patterns.append(name.lower().replace(" ", "_"))
    
    for filename in os.listdir("data"):
        if not filename.lower().endswith(".csv"):
            continue
        
        base_name = os.path.splitext(filename)[0].lower()
        normalized_name = re.sub(r"[^\w]", "_", base_name)
        
        # Testa todos os padr√µes
        for pattern in patterns:
            if pattern in normalized_name or normalized_name.startswith(pattern):
                return os.path.join("data", filename)
    
    return None

# ============ DADOS SIMULADOS PARA DEMO ============
def create_sample_laudos_realizados() -> pd.DataFrame:
    """Cria dados simulados de laudos realizados baseados no screenshot."""
    
    # Dados de exemplo baseados no screenshot fornecido
    sample_data = []
    
    # Tipos de per√≠cia do screenshot
    tipos_pericia = [
        "Qu√≠mica Forense", "Criminal Local de crime contra o patrim√¥nio",
        "Criminal Local de crime contra a vida", "Criminal Engenharia Forense",
        "Criminal Identifica√ß√£o de ve√≠culos", "Criminal Identifica√ß√£o",
        "Inform√°tica Forense", "Bal√≠stica", "Traumatologia Forense"
    ]
    
    # Unidades
    unidades = ["Joinville", "Florian√≥polis", "Blumenau", "Chapec√≥", "Crici√∫ma"]
    
    # Diretorias
    diretorias = ["Diretoria Criminal", "Diretoria C√≠vel", "Diretoria Administrativa"]
    
    # Peritos
    peritos = [
        "Alcides Ogliardi Junior", "Dr. Silva Santos", "Dra. Maria Oliveira",
        "Dr. Jo√£o Pereira", "Dra. Ana Costa"
    ]
    
    # Gera dados simulados para os √∫ltimos 24 meses
    start_date = pd.Timestamp('2022-01-01')
    end_date = pd.Timestamp('2024-01-01')
    
    np.random.seed(42)  # Para reprodutibilidade
    
    for i in range(500):  # 500 laudos simulados
        # Datas
        solicitacao = start_date + pd.Timedelta(days=np.random.randint(0, (end_date - start_date).days))
        atendimento = solicitacao + pd.Timedelta(days=np.random.randint(1, 30))
        emissao = atendimento + pd.Timedelta(days=np.random.randint(1, 120))
        
        sample_data.append({
            'dhsolicitacao': solicitacao.strftime('%d/%m/%Y'),
            'dhatendimento': atendimento.strftime('%d/%m/%Y'),
            'dhemitido': emissao.strftime('%d/%m/%Y'),
            'n_laudo': f"L{2000 + i}",
            'ano_emissao': emissao.year,
            'mes_emissao': emissao.month,
            'unidade_emissao': np.random.choice(unidades),
            'diretoria': np.random.choice(diretorias),
            'txcompetencia': f"{emissao.year}-{emissao.month:02d}",
            'txtipopericia': np.random.choice(tipos_pericia),
            'perito': np.random.choice(peritos)
        })
    
    return pd.DataFrame(sample_data)

# ============ CARREGAMENTO DE DADOS MELHORADO ============
@st.cache_data
def load_all_data(file_sources: Dict) -> Dict[str, pd.DataFrame]:
    """Carrega todos os dados dispon√≠veis."""
    loaded_data = {}
    
    for name, upload_file in file_sources.items():
        df = None
        
        if has_data_dir:
            file_path = resolve_file_path(name)
            if file_path and os.path.exists(file_path):
                try:
                    with open(file_path, 'rb') as f:
                        content = f.read()
                    df = read_csv_optimized(content, name)
                    if df is not None:
                        st.sidebar.success(f"‚úÖ {name}: {len(df)} registros")
                except Exception as e:
                    st.sidebar.error(f"‚ùå Erro ao carregar {name}: {str(e)}")
        else:
            if upload_file is not None:
                try:
                    content = upload_file.read()
                    df = read_csv_optimized(content, name)
                    if df is not None:
                        st.sidebar.success(f"‚úÖ {name}: {len(df)} registros")
                except Exception as e:
                    st.sidebar.error(f"‚ùå Erro ao processar {name}: {str(e)}")
        
        if df is not None:
            # Normaliza nomes das colunas
            df.columns = [
                re.sub(r"\s+", " ", col.strip().lower()) 
                for col in df.columns
            ]
            loaded_data[name] = df
    
    # Se n√£o h√° dados de laudos realizados, cria dados simulados para demo
    if "laudos_realizados" not in loaded_data:
        st.sidebar.info("üìä Usando dados simulados para Laudos Realizados (demo)")
        loaded_data["laudos_realizados"] = create_sample_laudos_realizados()
    
    return loaded_data

# Carrega os dados
raw_dataframes = load_all_data(uploads)

if not raw_dataframes:
    st.warning("‚ö†Ô∏è Nenhum arquivo foi carregado. Por favor, envie os arquivos CSV pela barra lateral ou coloque-os na pasta `data/`.")
    st.info("üìù **Arquivos esperados:** " + ", ".join(file_configs.keys()))
    st.stop()

# ============ MAPEAMENTO DE COLUNAS CORRIGIDO ============
COLUMN_MAPPINGS = {
    "detalhes_laudospendentes": {
        "date": "data_solicitacao",
        "ano": "ano_sol", 
        "id": "caso_sirsaelp",
        "unidade": "unidade",
        "superintendencia": "superintendencia",
        "diretoria": "diretoria",
        "competencia": "competencia",
        "tipo": "tipopericia",
        "perito": "perito"
    },
    "detalhes_examespendentes": {
        "date": "data_solicitacao",
        "ano": "ano_sol",
        "id": "caso_sirsaelp", 
        "unidade": "unidade",
        "superintendencia": "superintendencia",
        "diretoria": "diretoria",
        "competencia": "competencia",
        "tipo": "tipopericia"
    },
    "Atendimentos_todos_Mensal": {
        "date": "data_interesse",
        "id": "idatendimento",
        "quantidade": "idatendimento"  # O ID representa a quantidade de atendimentos
    },
    "Atendimentos_especifico_Mensal": {
        "date": "data_interesse",
        "competencia": "txcompetencia",
        "id": "idatendimento",
        "quantidade": "idatendimento",  # O ID representa a quantidade de atendimentos
        "tipo": "txcompetencia"  # txcompetencia √© o tipo de per√≠cia
    },
    "Laudos_todos_Mensal": {
        "date": "data_interesse", 
        "id": "iddocumento",
        "quantidade": "iddocumento"  # O ID representa a quantidade de documentos
    },
    "Laudos_especifico_Mensal": {
        "date": "data_interesse",
        "competencia": "txcompetencia",
        "id": "iddocumento",
        "quantidade": "iddocumento",  # O ID representa a quantidade de documentos
        "tipo": "txcompetencia"  # txcompetencia √© o tipo de per√≠cia
    },
    "laudos_realizados": {
        "solicitacao": "dhsolicitacao",
        "atendimento": "dhatendimento", 
        "emissao": "dhemitido",
        "n_laudo": "n_laudo",
        "ano": "ano_emissao",
        "mes": "mes_emissao",
        "unidade": "unidade_emissao",
        "diretoria": "diretoria",
        "competencia": "txcompetencia",
        "tipo": "txtipopericia", 
        "perito": "perito"
    }
}

# ============ PADRONIZA√á√ÉO DE DADOS ============
@st.cache_data
def standardize_dataframe(name: str, df: pd.DataFrame) -> pd.DataFrame:
    """Padroniza estrutura do DataFrame para an√°lise unificada."""
    if df is None or df.empty:
        return pd.DataFrame()
    
    mapping = COLUMN_MAPPINGS.get(name, {})
    result = df.copy()
    
    # Para arquivos mensais, o valor na coluna ID j√° representa a quantidade
    if name in ["Atendimentos_todos_Mensal", "Laudos_todos_Mensal", 
                "Atendimentos_especifico_Mensal", "Laudos_especifico_Mensal"]:
        
        quantity_col = mapping.get("quantidade", mapping.get("id"))
        if quantity_col and quantity_col in result.columns:
            # Converte para num√©rico
            result["quantidade"] = pd.to_numeric(result[quantity_col], errors="coerce").fillna(0)
        else:
            result["quantidade"] = 1
    else:
        # Para outros arquivos, cada linha √© uma unidade
        result["quantidade"] = 1
    
    # Mapeia colunas dimensionais
    dimension_columns = [
        "diretoria", "superintendencia", "unidade", 
        "tipo", "perito", "id"
    ]
    
    for dim_col in dimension_columns:
        if dim_col in mapping and mapping[dim_col] in result.columns:
            result[dim_col] = result[mapping[dim_col]]
    
    # Processa datas e compet√™ncias
    anom√™s_dt = None
    
    # Prioridade: competencia -> date -> ano/mes
    if "competencia" in mapping and mapping["competencia"] in result.columns:
        # Para txcompetencia, precisamos agrupar por data + tipo
        if mapping["competencia"] == "txcompetencia":
            date_col = mapping.get("date")
            if date_col and date_col in result.columns:
                date_series = process_datetime_column(result[date_col])
                if date_series is not None:
                    anom√™s_dt = date_series.dt.to_period("M").dt.to_timestamp()
        else:
            # Para outras compet√™ncias, tenta converter diretamente
            anom√™s_dt = process_datetime_column(result[mapping["competencia"]])
            if anom√™s_dt is not None:
                anom√™s_dt = anom√™s_dt.dt.to_period("M").dt.to_timestamp()
    
    if anom√™s_dt is None and "date" in mapping and mapping["date"] in result.columns:
        date_col = process_datetime_column(result[mapping["date"]])
        if date_col is not None:
            anom√™s_dt = date_col.dt.to_period("M").dt.to_timestamp()
    
    # Para laudos_realizados: usar ano/mes se dispon√≠vel
    if anom√™s_dt is None and name == "laudos_realizados":
        ano_col = mapping.get("ano")
        mes_col = mapping.get("mes")
        
        if ano_col in result.columns and mes_col in result.columns:
            try:
                anos = pd.to_numeric(result[ano_col], errors="coerce")
                meses = pd.to_numeric(result[mes_col], errors="coerce")
                
                valid_mask = (~anos.isna()) & (~meses.isna()) & (meses >= 1) & (meses <= 12)
                if valid_mask.any():
                    dates = pd.to_datetime({
                        'year': anos,
                        'month': meses, 
                        'day': 1
                    }, errors="coerce")
                    anom√™s_dt = dates.dt.to_period("M").dt.to_timestamp()
            except Exception:
                pass
    
    # Adiciona colunas de tempo padronizadas
    if anom√™s_dt is not None:
        result["anom√™s_dt"] = anom√™s_dt
        result["anom√™s"] = result["anom√™s_dt"].dt.strftime("%Y-%m")
        result["ano"] = result["anom√™s_dt"].dt.year
        result["mes"] = result["anom√™s_dt"].dt.month
    
    # Adiciona data base para c√°lculos de aging
    if "date" in mapping and mapping["date"] in result.columns:
        result["data_base"] = process_datetime_column(result[mapping["date"]])
    
    # Processamento espec√≠fico para laudos realizados
    if name == "laudos_realizados":
        date_fields = ["solicitacao", "atendimento", "emissao"]
        
        for field in date_fields:
            col_name = mapping.get(field)
            if col_name and col_name in result.columns:
                result[f"dh{field}"] = process_datetime_column(result[col_name])
        
        # Calcula TME (Tempo M√©dio de Execu√ß√£o)
        if "dhemissao" in result.columns:
            base_date = (
                result.get("dhatendimento") 
                if "dhatendimento" in result.columns 
                else result.get("dhsolicitacao")
            )
            
            if base_date is not None:
                result["tme_dias"] = (result["dhemissao"] - base_date).dt.days
                result["sla_30_ok"] = result["tme_dias"] <= 30
                result["sla_60_ok"] = result["tme_dias"] <= 60
    
    # Limpeza e padroniza√ß√£o de texto
    text_columns = [
        "diretoria", "superintendencia", "unidade", 
        "tipo", "id", "perito", "anom√™s"
    ]
    
    for col in text_columns:
        if col in result.columns:
            result[col] = (
                result[col]
                .astype(str)
                .str.strip()
                .str.title()
                .replace({"Nan": None, "": None, "None": None})
            )
    
    # Para arquivos espec√≠ficos, agrupa por m√™s + tipo
    if name in ["Atendimentos_especifico_Mensal", "Laudos_especifico_Mensal"]:
        if "anom√™s_dt" in result.columns and "tipo" in result.columns:
            # J√° est√° no formato correto, apenas certifica que quantidade est√° correta
            pass
    
    return result
            except Exception:
                pass
    
    # Adiciona colunas de tempo padronizadas
    if anom√™s_dt is not None:
        result["anom√™s_dt"] = anom√™s_dt
        result["anom√™s"] = result["anom√™s_dt"].dt.strftime("%Y-%m")
        result["ano"] = result["anom√™s_dt"].dt.year
        result["mes"] = result["anom√™s_dt"].dt.month
    
    # Adiciona data base para c√°lculos de aging
    if "date" in mapping and mapping["date"] in result.columns:
        result["data_base"] = process_datetime_column(result[mapping["date"]])
    
    # Processamento espec√≠fico para laudos realizados
    if name == "laudos_realizados":
        date_fields = ["solicitacao", "atendimento", "emissao"]
        
        for field in date_fields:
            col_name = mapping.get(field)
            if col_name and col_name in result.columns:
                result[f"dh{field}"] = process_datetime_column(result[col_name])
        
        # Calcula TME (Tempo M√©dio de Execu√ß√£o)
        if "dhemissao" in result.columns:
            base_date = (
                result.get("dhatendimento") 
                if "dhatendimento" in result.columns 
                else result.get("dhsolicitacao")
            )
            
            if base_date is not None:
                result["tme_dias"] = (result["dhemissao"] - base_date).dt.days
                result["sla_30_ok"] = result["tme_dias"] <= 30
                result["sla_60_ok"] = result["tme_dias"] <= 60
    
    # Limpeza e padroniza√ß√£o de texto
    text_columns = [
        "diretoria", "superintendencia", "unidade", 
        "tipo", "id", "perito", "anom√™s"
    ]
    
    for col in text_columns:
        if col in result.columns:
            result[col] = (
                result[col]
                .astype(str)
                .str.strip()
                .str.title()
                .replace({"Nan": None, "": None, "None": None})
            )
    
    # Para arquivos espec√≠ficos, agrupa por m√™s + tipo
    if name in ["Atendimentos_especifico_Mensal", "Laudos_especifico_Mensal"]:
        if "anom√™s_dt" in result.columns and "tipo" in result.columns:
            # J√° est√° no formato correto, apenas certifica que quantidade est√° correta
            pass
    
    return result

# Padroniza todos os DataFrames
standardized_dfs = {}
processing_info = []

for name, df in raw_dataframes.items():
    standardized_df = standardize_dataframe(name, df)
    standardized_dfs[name] = standardized_df
    
    processing_info.append({
        "Arquivo": name,
        "Linhas": len(standardized_df),
        "Per√≠odo": f"{standardized_df['anom√™s'].min()} a {standardized_df['anom√™s'].max()}" 
                   if 'anom√™s' in standardized_df.columns and not standardized_df['anom√™s'].isna().all()
                   else "Sem dados temporais"
    })

# Exibe informa√ß√µes de processamento
with st.sidebar.expander("üìä Resumo dos Dados", expanded=False):
    info_df = pd.DataFrame(processing_info)
    st.dataframe(info_df, use_container_width=True)

# ============ FILTROS AVAN√áADOS ============
def extract_filter_values(column: str) -> List[str]:
    """Extrai valores √∫nicos de uma coluna em todos os DataFrames."""
    values = set()
    
    for df in standardized_dfs.values():
        if column in df.columns:
            unique_vals = df[column].dropna().astype(str).unique()
            values.update(v for v in unique_vals if v and v.lower() != "nan")
    
    return sorted(list(values))

st.sidebar.subheader("üîç Filtros")

# Filtros dimensionais
filter_diretoria = st.sidebar.multiselect(
    "Diretoria", 
    extract_filter_values("diretoria"),
    help="Selecione uma ou mais diretorias"
)

filter_superintendencia = st.sidebar.multiselect(
    "Superintend√™ncia", 
    extract_filter_values("superintendencia"),
    help="Selecione uma ou mais superintend√™ncias"
)

filter_unidade = st.sidebar.multiselect(
    "Unidade", 
    extract_filter_values("unidade"),
    help="Selecione uma ou mais unidades"
)

filter_tipo = st.sidebar.multiselect(
    "Tipo de Per√≠cia", 
    extract_filter_values("tipo"),
    help="Selecione um ou mais tipos"
)

# Filtro de per√≠odo
period_options = ["Todo o per√≠odo", "√öltimos 6 meses", "√öltimos 3 meses", "Ano atual"]
filter_periodo = st.sidebar.selectbox(
    "Per√≠odo de an√°lise",
    period_options,
    help="Selecione o per√≠odo para an√°lise"
)

# ============ APLICA√á√ÉO DE FILTROS ============
def apply_filters(df: pd.DataFrame) -> pd.DataFrame:
    """Aplica todos os filtros selecionados ao DataFrame."""
    if df is None or df.empty:
        return pd.DataFrame()
    
    filtered = df.copy()
    
    # Filtros dimensionais
    filter_mappings = [
        ("diretoria", filter_diretoria),
        ("superintendencia", filter_superintendencia), 
        ("unidade", filter_unidade),
        ("tipo", filter_tipo)
    ]
    
    for column, filter_values in filter_mappings:
        if column in filtered.columns and filter_values:
            filtered = filtered[
                filtered[column].astype(str).isin(filter_values)
            ]
    
    # Filtro de per√≠odo
    if "anom√™s_dt" in filtered.columns and filter_periodo != "Todo o per√≠odo":
        max_date = filtered["anom√™s_dt"].max()
        
        if pd.notna(max_date):
            if filter_periodo == "√öltimos 3 meses":
                cutoff_date = max_date - pd.DateOffset(months=3)
            elif filter_periodo == "√öltimos 6 meses": 
                cutoff_date = max_date - pd.DateOffset(months=6)
            elif filter_periodo == "Ano atual":
                cutoff_date = pd.Timestamp(max_date.year, 1, 1)
            
            filtered = filtered[filtered["anom√™s_dt"] >= cutoff_date]
    
    return filtered

# Aplica filtros a todos os DataFrames
filtered_dfs = {
    name: apply_filters(df) 
    for name, df in standardized_dfs.items()
}

# Extrai DataFrames filtrados para uso
df_atend_todos = filtered_dfs.get("Atendimentos_todos_Mensal")
df_laudos_todos = filtered_dfs.get("Laudos_todos_Mensal") 
df_atend_esp = filtered_dfs.get("Atendimentos_especifico_Mensal")
df_laudos_esp = filtered_dfs.get("Laudos_especifico_Mensal")
df_laudos_real = filtered_dfs.get("laudos_realizados")
df_pend_laudos = filtered_dfs.get("detalhes_laudospendentes")
df_pend_exames = filtered_dfs.get("detalhes_examespendentes")

# ============ C√ÅLCULO DE KPIS CORRIGIDOS ============
def calculate_total(df: pd.DataFrame) -> int:
    """Calcula total considerando a coluna quantidade."""
    if df is None or df.empty or "quantidade" not in df.columns:
        return 0
    return int(df["quantidade"].sum())

def calculate_monthly_average(df: pd.DataFrame) -> Optional[float]:
    """Calcula m√©dia mensal considerando quantidade."""
    if df is None or df.empty or "anom√™s_dt" not in df.columns or "quantidade" not in df.columns:
        return None
    
    monthly_totals = df.groupby("anom√™s_dt")["quantidade"].sum()
    return monthly_totals.mean() if len(monthly_totals) > 0 else None

def calculate_growth_rate(df: pd.DataFrame, periods: int = 3) -> Optional[float]:
    """Calcula taxa de crescimento dos √∫ltimos per√≠odos."""
    if df is None or df.empty or "anom√™s_dt" not in df.columns or "quantidade" not in df.columns:
        return None
    
    monthly_data = (
        df.groupby("anom√™s_dt")["quantidade"]
        .sum()
        .sort_index()
        .tail(periods * 2)
    )
    
    if len(monthly_data) < 2:
        return None
    
    mid_point = len(monthly_data) // 2
    first_half = monthly_data.iloc[:mid_point].mean()
    second_half = monthly_data.iloc[mid_point:].mean()
    
    if first_half > 0:
        return ((second_half - first_half) / first_half) * 100
    
    return None

def calculate_productivity_metrics(df_atend: pd.DataFrame, df_laudos: pd.DataFrame) -> Dict:
    """Calcula m√©tricas de produtividade comparativas."""
    metrics = {}
    
    if df_atend is not None and df_laudos is not None:
        # Taxa de convers√£o atendimento -> laudo
        total_atend = calculate_total(df_atend)
        total_laudos = calculate_total(df_laudos)
        
        if total_atend > 0:
            metrics["taxa_conversao"] = (total_laudos / total_atend) * 100
        
        # Efici√™ncia temporal (se h√° dados temporais)
        if ("anom√™s_dt" in df_atend.columns and "anom√™s_dt" in df_laudos.columns):
            atend_monthly = df_atend.groupby("anom√™s_dt")["quantidade"].sum()
            laudos_monthly = df_laudos.groupby("anom√™s_dt")["quantidade"].sum()
            
            # Correla√ß√£o entre atendimentos e laudos
            common_months = atend_monthly.index.intersection(laudos_monthly.index)
            if len(common_months) > 3:
                correlation = atend_monthly.loc[common_months].corr(laudos_monthly.loc[common_months])
                metrics["correlacao_atend_laudos"] = correlation
    
    return metrics

# Calcula KPIs principais
total_atendimentos = calculate_total(df_atend_todos)
total_laudos = calculate_total(df_laudos_todos)
total_pend_laudos = len(df_pend_laudos) if df_pend_laudos is not None and not df_pend_laudos.empty else 0
total_pend_exames = len(df_pend_exames) if df_pend_exames is not None and not df_pend_exames.empty else 0

# KPIs derivados
media_mensal_laudos = calculate_monthly_average(df_laudos_todos)
backlog_meses = (
    total_pend_laudos / media_mensal_laudos 
    if media_mensal_laudos and media_mensal_laudos > 0 
    else None
)

# M√©tricas de produtividade
produtividade_metrics = calculate_productivity_metrics(df_atend_todos, df_laudos_todos)
taxa_atendimento = produtividade_metrics.get("taxa_conversao")
correlacao_atend_laudos = produtividade_metrics.get("correlacao_atend_laudos")

crescimento_laudos = calculate_growth_rate(df_laudos_todos)
crescimento_atendimentos = calculate_growth_rate(df_atend_todos)

# KPIs de performance (laudos realizados)
tme_mediano = None
tme_medio = None
sla_30_percent = None
sla_60_percent = None

if df_laudos_real is not None and not df_laudos_real.empty:
    if "tme_dias" in df_laudos_real.columns:
        tme_values = pd.to_numeric(df_laudos_real["tme_dias"], errors="coerce").dropna()
        if not tme_values.empty:
            tme_mediano = tme_values.median()
            tme_medio = tme_values.mean()
    
    if "sla_30_ok" in df_laudos_real.columns:
        sla_30_percent = df_laudos_real["sla_30_ok"].mean() * 100
    
    if "sla_60_ok" in df_laudos_real.columns:
        sla_60_percent = df_laudos_real["sla_60_ok"].mean() * 100

# KPIs de aging (pend√™ncias)
aging_laudos_medio = None
aging_exames_medio = None

if df_pend_laudos is not None and not df_pend_laudos.empty and "data_base" in df_pend_laudos.columns:
    dates = pd.to_datetime(df_pend_laudos["data_base"], errors="coerce")
    if dates.notna().any():
        hoje = pd.Timestamp.now().normalize()
        dias_pendentes = (hoje - dates).dt.days
        aging_laudos_medio = dias_pendentes.mean()

if df_pend_exames is not None and not df_pend_exames.empty and "data_base" in df_pend_exames.columns:
    dates = pd.to_datetime(df_pend_exames["data_base"], errors="coerce")
    if dates.notna().any():
        hoje = pd.Timestamp.now().normalize()
        dias_pendentes = (hoje - dates).dt.days
        aging_exames_medio = dias_pendentes.mean()

# ============ EXIBI√á√ÉO DE KPIS MELHORADOS ============
st.subheader("üìà Indicadores Principais")

# Primeira linha de KPIs - Produ√ß√£o
col1, col2, col3, col4 = st.columns(4)

with col1:
    delta_atend = f"+{format_number(crescimento_atendimentos, 1)}%" if crescimento_atendimentos else None
    st.metric(
        "Atendimentos Totais",
        format_number(total_atendimentos),
        delta=delta_atend,
        help="Total de atendimentos no per√≠odo filtrado"
    )

with col2:
    delta_laudos = f"+{format_number(crescimento_laudos, 1)}%" if crescimento_laudos else None
    st.metric(
        "Laudos Emitidos", 
        format_number(total_laudos),
        delta=delta_laudos,
        help="Total de laudos emitidos no per√≠odo"
    )

with col3:
    st.metric(
        "Taxa de Convers√£o",
        f"{format_number(taxa_atendimento, 1)}%" if taxa_atendimento else "‚Äî",
        help="Percentual de atendimentos que resultaram em laudos"
    )

with col4:
    st.metric(
        "Produtividade Mensal",
        format_number(media_mensal_laudos, 1) if media_mensal_laudos else "‚Äî",
        help="M√©dia de laudos emitidos por m√™s"
    )

# Segunda linha de KPIs - Pend√™ncias
st.markdown("#### ‚è∞ Gest√£o de Pend√™ncias")
col5, col6, col7, col8 = st.columns(4)

with col5:
    st.metric(
        "Laudos Pendentes",
        format_number(total_pend_laudos),
        help="Laudos aguardando emiss√£o"
    )

with col6:
    st.metric(
        "Exames Pendentes", 
        format_number(total_pend_exames),
        help="Exames aguardando realiza√ß√£o"
    )

with col7:
    backlog_color = "normal"
    if backlog_meses:
        if backlog_meses > 6:
            backlog_color = "inverse"
        elif backlog_meses > 3:
            backlog_color = "off"
    
    st.metric(
        "Backlog (meses)",
        format_number(backlog_meses, 1) if backlog_meses else "‚Äî",
        help="Tempo estimado para liquidar pend√™ncias atuais baseado na produ√ß√£o m√©dia"
    )

with col8:
    aging_medio = aging_laudos_medio or aging_exames_medio
    st.metric(
        "Aging M√©dio (dias)",
        format_number(aging_medio, 0) if aging_medio else "‚Äî",
        help="Tempo m√©dio de pend√™ncia dos processos em aberto"
    )

# Terceira linha - Performance e SLAs
if tme_mediano is not None or sla_30_percent is not None:
    st.markdown("#### üéØ Indicadores de Performance")
    col9, col10, col11, col12 = st.columns(4)
    
    with col9:
        st.metric(
            "TME Mediano (dias)",
            format_number(tme_mediano, 1) if tme_mediano else "‚Äî", 
            help="Tempo mediano de execu√ß√£o dos laudos (mais robusto que a m√©dia)"
        )
    
    with col10:
        st.metric(
            "TME M√©dio (dias)",
            format_number(tme_medio, 1) if tme_medio else "‚Äî",
            help="Tempo m√©dio de execu√ß√£o dos laudos"
        )
    
    with col11:
        sla_30_delta = "normal" if sla_30_percent and sla_30_percent >= 80 else "inverse"
        st.metric(
            "SLA 30 dias",
            f"{format_number(sla_30_percent, 1)}%" if sla_30_percent else "‚Äî",
            help="Percentual de laudos emitidos em at√© 30 dias"
        )
    
    with col12:
        st.metric(
            "SLA 60 dias", 
            f"{format_number(sla_60_percent, 1)}%" if sla_60_percent else "‚Äî",
            help="Percentual de laudos emitidos em at√© 60 dias"
        )

# Alertas e insights autom√°ticos
st.markdown("#### üö® Alertas e Insights")
alerts = []

if backlog_meses and backlog_meses > 6:
    alerts.append("üî¥ **Backlog cr√≠tico**: Mais de 6 meses para liquidar pend√™ncias")
elif backlog_meses and backlog_meses > 3:
    alerts.append("üü° **Aten√ß√£o**: Backlog de pend√™ncias acima de 3 meses")

if sla_30_percent and sla_30_percent < 70:
    alerts.append("üî¥ **SLA 30 dias baixo**: Menos de 70% dos laudos emitidos no prazo")

if taxa_atendimento and taxa_atendimento < 50:
    alerts.append("üü° **Taxa de convers√£o baixa**: Menos de 50% dos atendimentos resultam em laudos")

if crescimento_laudos and crescimento_laudos < -10:
    alerts.append("üî¥ **Queda na produ√ß√£o**: Redu√ß√£o de mais de 10% nos laudos emitidos")

if correlacao_atend_laudos and correlacao_atend_laudos < 0.5:
    alerts.append("üü° **Descorrela√ß√£o**: Atendimentos e laudos n√£o est√£o alinhados temporalmente")

if alerts:
    for alert in alerts:
        st.markdown(alert)
else:
    st.success("‚úÖ **Indicadores saud√°veis**: Todos os KPIs est√£o dentro dos par√¢metros esperados")
st.markdown("---")

# ============ ABAS DO DASHBOARD ============
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìä Vis√£o Geral", 
    "üìà Tend√™ncias", 
    "üèÜ Rankings", 
    "‚è∞ Pend√™ncias", 
    "üìã Dados",
    "üìë Relat√≥rios"
])

# ============ ABA 1: VIS√ÉO GERAL ============
with tab1:
    st.subheader("üìä Resumo Executivo")
    
    # M√©tricas de efici√™ncia
    if df_laudos_todos is not None and not df_laudos_todos.empty:
        col_left, col_right = st.columns(2)
        
        with col_left:
            st.markdown("#### üè¢ Performance por Unidade")
            
            if "unidade" in df_laudos_todos.columns:
                unidade_summary = (
                    df_laudos_todos
                    .groupby("unidade", as_index=False)["quantidade"]
                    .sum()
                    .sort_values("quantidade", ascending=False)
                    .head(15)
                )
                
                fig_unidades = px.bar(
                    unidade_summary,
                    x="quantidade", 
                    y="unidade",
                    orientation="h",
                    title="Top 15 Unidades - Laudos Emitidos",
                    color="quantidade",
                    color_continuous_scale="Blues",
                    text="quantidade"
                )
                fig_unidades.update_traces(texttemplate='%{text}', textposition='outside')
                fig_unidades.update_layout(height=500, showlegend=False)
                st.plotly_chart(fig_unidades, use_container_width=True)
        
        with col_right:
            st.markdown("#### üîç Distribui√ß√£o por Tipo")
            
            if "tipo" in df_laudos_todos.columns:
                tipo_summary = (
                    df_laudos_todos
                    .groupby("tipo", as_index=False)["quantidade"]
                    .sum()
                    .sort_values("quantidade", ascending=False)
                    .head(10)
                )
                
                fig_tipos = px.pie(
                    tipo_summary,
                    values="quantidade",
                    names="tipo", 
                    title="Top 10 Tipos de Per√≠cia"
                )
                fig_tipos.update_traces(textposition='inside', textinfo='percent+label')
                fig_tipos.update_layout(height=500)
                st.plotly_chart(fig_tipos, use_container_width=True)
    
    # An√°lise temporal consolidada
    if (df_atend_todos is not None and df_laudos_todos is not None and 
        "anom√™s_dt" in df_atend_todos.columns and "anom√™s_dt" in df_laudos_todos.columns):
        
        st.markdown("#### üìÖ Evolu√ß√£o Temporal Consolidada")
        
        # Combina dados mensais
        atend_monthly = (
            df_atend_todos
            .groupby("anom√™s_dt")["quantidade"]
            .sum()
            .reset_index()
        )
        atend_monthly["Tipo"] = "Atendimentos"
        atend_monthly.rename(columns={"quantidade": "Total"}, inplace=True)
        
        laudos_monthly = (
            df_laudos_todos
            .groupby("anom√™s_dt")["quantidade"] 
            .sum()
            .reset_index()
        )
        laudos_monthly["Tipo"] = "Laudos"
        laudos_monthly.rename(columns={"quantidade": "Total"}, inplace=True)
        
        combined_data = pd.concat([atend_monthly, laudos_monthly])
        combined_data["M√™s"] = combined_data["anom√™s_dt"].dt.strftime("%Y-%m")
        
        fig_temporal = px.line(
            combined_data,
            x="M√™s",
            y="Total",
            color="Tipo",
            markers=True,
            title="Evolu√ß√£o Mensal: Atendimentos vs Laudos",
            line_shape="spline"
        )
        
        fig_temporal.update_layout(
            height=400,
            hovermode="x unified",
            xaxis_title="Per√≠odo",
            yaxis_title="Quantidade"
        )
        
        st.plotly_chart(fig_temporal, use_container_width=True)
        
        # Taxa de convers√£o ao longo do tempo
        merged_monthly = pd.merge(
            atend_monthly.rename(columns={"Total": "Atendimentos"}),
            laudos_monthly.rename(columns={"Total": "Laudos"}),
            on="anom√™s_dt",
            how="inner"
        )
        
        if not merged_monthly.empty:
            merged_monthly["Taxa_Conversao"] = (
                merged_monthly["Laudos"] / merged_monthly["Atendimentos"] * 100
            )
            merged_monthly["M√™s"] = merged_monthly["anom√™s_dt"].dt.strftime("%Y-%m")
            
            fig_conversao = px.line(
                merged_monthly,
                x="M√™s",
                y="Taxa_Conversao",
                markers=True,
                title="Taxa de Convers√£o Mensal (%)",
                line_shape="spline"
            )
            
            # Adiciona linha de meta (70%)
            fig_conversao.add_hline(
                y=70, 
                line_dash="dash", 
                line_color="red",
                annotation_text="Meta: 70%"
            )
            
            fig_conversao.update_layout(
                height=350,
                yaxis_title="Taxa de Convers√£o (%)",
                xaxis_title="Per√≠odo"
            )
            
            st.plotly_chart(fig_conversao, use_container_width=True)

# ============ ABA 2: TEND√äNCIAS ============
with tab2:
    st.subheader("üìà An√°lise de Tend√™ncias")
    
    def create_enhanced_time_series(df: pd.DataFrame, title: str, color: str = "blue") -> None:
        """Cria gr√°fico de s√©rie temporal com an√°lises avan√ßadas."""
        if df is None or df.empty or "anom√™s_dt" not in df.columns:
            st.info(f"Dados insuficientes para {title}")
            return
        
        monthly_data = (
            df.groupby("anom√™s_dt", as_index=False)["quantidade"]
            .sum()
            .sort_values("anom√™s_dt")
        )
        
        if monthly_data.empty:
            st.info(f"Sem dados temporais para {title}")
            return
        
        monthly_data["M√™s"] = monthly_data["anom√™s_dt"].dt.strftime("%Y-%m")
        
        # Cria subplots
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=(title, "Varia√ß√£o Percentual Mensal"),
            vertical_spacing=0.15,
            row_heights=[0.7, 0.3]
        )
        
        # Gr√°fico principal com linha e m√©dia m√≥vel
        fig.add_trace(
            go.Scatter(
                x=monthly_data["M√™s"],
                y=monthly_data["quantidade"],
                mode="lines+markers",
                name="Valores",
                line=dict(color=color, width=2)
            ),
            row=1, col=1
        )
        
        # M√©dia m√≥vel (3 meses)
        if len(monthly_data) >= 3:
            monthly_data["media_movel"] = (
                monthly_data["quantidade"]
                .rolling(window=3, center=True)
                .mean()
            )
            
            fig.add_trace(
                go.Scatter(
                    x=monthly_data["M√™s"],
                    y=monthly_data["media_movel"],
                    mode="lines",
                    name="M√©dia M√≥vel (3m)",
                    line=dict(dash="dash", color="red", width=2)
                ),
                row=1, col=1
            )
        
        # Varia√ß√£o percentual
        monthly_data["variacao_pct"] = monthly_data["quantidade"].pct_change() * 100
        
        colors = ['red' if x < 0 else 'green' for x in monthly_data["variacao_pct"].fillna(0)]
        
        fig.add_trace(
            go.Bar(
                x=monthly_data["M√™s"],
                y=monthly_data["variacao_pct"],
                name="Varia√ß√£o %",
                marker_color=colors,
                showlegend=False
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            height=600,
            hovermode="x unified",
            showlegend=True
        )
        
        fig.update_xaxes(title_text="Per√≠odo", row=2, col=1)
        fig.update_yaxes(title_text="Quantidade", row=1, col=1)
        fig.update_yaxes(title_text="Varia√ß√£o (%)", row=2, col=1)
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Gr√°ficos de tend√™ncia em colunas
    col1, col2 = st.columns(2)
    
    with col1:
        create_enhanced_time_series(
            df_atend_todos,
            "üè• Atendimentos - An√°lise Temporal",
            "blue"
        )
        
        # An√°lise sazonal para atendimentos
        if df_atend_todos is not None and "anom√™s_dt" in df_atend_todos.columns:
            st.markdown("#### üìÖ Sazonalidade - Atendimentos")
            
            seasonal_data = df_atend_todos.copy()
            seasonal_data["mes_nome"] = seasonal_data["anom√™s_dt"].dt.month_name()
            seasonal_data["mes_num"] = seasonal_data["anom√™s_dt"].dt.month
            
            monthly_totals = (
                seasonal_data
                .groupby(["mes_num", "mes_nome"])["quantidade"]
                .sum()
                .reset_index()
                .sort_values("mes_num")
            )
            
            fig_sazonal = px.bar(
                monthly_totals,
                x="mes_nome",
                y="quantidade",
                title="Distribui√ß√£o Sazonal",
                color="quantidade",
                color_continuous_scale="Blues"
            )
            
            fig_sazonal.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig_sazonal, use_container_width=True)
    
    with col2:
        create_enhanced_time_series(
            df_laudos_todos,
            "üìÑ Laudos - An√°lise Temporal", 
            "green"
        )
        
        # An√°lise sazonal para laudos
        if df_laudos_todos is not None and "anom√™s_dt" in df_laudos_todos.columns:
            st.markdown("#### üìÖ Sazonalidade - Laudos")
            
            seasonal_data = df_laudos_todos.copy()
            seasonal_data["mes_nome"] = seasonal_data["anom√™s_dt"].dt.month_name()
            seasonal_data["mes_num"] = seasonal_data["anom√™s_dt"].dt.month
            
            monthly_totals = (
                seasonal_data
                .groupby(["mes_num", "mes_nome"])["quantidade"]
                .sum()
                .reset_index()
                .sort_values("mes_num")
            )
            
            fig_sazonal = px.bar(
                monthly_totals,
                x="mes_nome",
                y="quantidade",
                title="Distribui√ß√£o Sazonal",
                color="quantidade",
                color_continuous_scale="Greens"
            )
            
            fig_sazonal.update_layout(height=300, showlegend=False)
            st.plotly_chart(fig_sazonal, use_container_width=True)
    
    # An√°lise de correla√ß√£o
    if (df_atend_todos is not None and df_laudos_todos is not None and 
        "anom√™s_dt" in df_atend_todos.columns and "anom√™s_dt" in df_laudos_todos.columns):
        
        st.markdown("#### üîó An√°lise de Correla√ß√£o")
        
        atend_monthly = df_atend_todos.groupby("anom√™s_dt")["quantidade"].sum()
        laudos_monthly = df_laudos_todos.groupby("anom√™s_dt")["quantidade"].sum()
        
        # Per√≠odos em comum
        common_periods = atend_monthly.index.intersection(laudos_monthly.index)
        
        if len(common_periods) > 3:
            correlation_data = pd.DataFrame({
                "Atendimentos": atend_monthly.loc[common_periods],
                "Laudos": laudos_monthly.loc[common_periods]
            }).reset_index()
            
            correlation_data["Per√≠odo"] = correlation_data["anom√™s_dt"].dt.strftime("%Y-%m")
            
            fig_scatter = px.scatter(
                correlation_data,
                x="Atendimentos",
                y="Laudos",
                hover_data=["Per√≠odo"],
                title="Correla√ß√£o: Atendimentos vs Laudos",
                trendline="ols"
            )
            
            correlation_coef = correlation_data["Atendimentos"].corr(correlation_data["Laudos"])
            fig_scatter.add_annotation(
                text=f"Correla√ß√£o: {correlation_coef:.3f}",
                xref="paper", yref="paper",
                x=0.02, y=0.98,
                showarrow=False,
                bgcolor="rgba(255,255,255,0.8)"
            )
            
            fig_scatter.update_layout(height=400)
            st.plotly_chart(fig_scatter, use_container_width=True)

# ============ ABA 3: RANKINGS ============
with tab3:
    st.subheader("üèÜ Rankings e Comparativos")
    
    def create_enhanced_ranking(df: pd.DataFrame, dimension: str, title: str, top_n: int = 20) -> None:
        """Cria gr√°fico de ranking com informa√ß√µes adicionais."""
        if df is None or df.empty or dimension not in df.columns:
            st.info(f"Dados insuficientes para {title}")
            return
        
        ranking_data = (
            df.groupby(dimension)
            .agg({
                "quantidade": ["sum", "count", "mean"]
            })
            .round(2)
        )
        
        ranking_data.columns = ["Total", "Registros", "M√©dia"]
        ranking_data = ranking_data.sort_values("Total", ascending=False).head(top_n)
        ranking_data.reset_index(inplace=True)
        
        if ranking_data.empty:
            st.info(f"Sem dados para {title}")
            return
        
        # Gr√°fico principal
        fig = px.bar(
            ranking_data,
            x="Total",
            y=dimension,
            orientation="h",
            title=title,
            color="Total",
            color_continuous_scale="Viridis",
            hover_data=["Registros", "M√©dia"]
        )
        
        fig.update_layout(
            height=max(400, len(ranking_data) * 30),
            showlegend=False,
            yaxis={"categoryorder": "total ascending"}
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Tabela de detalhes
        with st.expander(f"üìä Detalhes - {title}"):
            st.dataframe(ranking_data, use_container_width=True)
    
    # Rankings em abas
    rank_tab1, rank_tab2, rank_tab3, rank_tab4 = st.tabs([
        "Por Diretoria", "Por Unidade", "Por Tipo", "Comparativo"
    ])
    
    with rank_tab1:
        col1, col2 = st.columns(2)
        with col1:
            create_enhanced_ranking(
                df_atend_todos,
                "diretoria", 
                "üè• Atendimentos por Diretoria"
            )
        with col2:
            create_enhanced_ranking(
                df_laudos_todos,
                "diretoria",
                "üìÑ Laudos por Diretoria"
            )
    
    with rank_tab2:
        col1, col2 = st.columns(2)
        with col1:
            create_enhanced_ranking(
                df_atend_todos,
                "unidade",
                "üè• Atendimentos por Unidade",
                25
            )
        with col2:
            create_enhanced_ranking(
                df_laudos_todos,
                "unidade", 
                "üìÑ Laudos por Unidade",
                25
            )
    
    with rank_tab3:
        col1, col2 = st.columns(2)
        with col1:
            create_enhanced_ranking(
                df_atend_esp,
                "tipo",
                "üè• Atendimentos por Tipo",
                20
            )
        with col2:
            create_enhanced_ranking(
                df_laudos_esp,
                "tipo",
                "üìÑ Laudos por Tipo",
                20
            )
    
    with rank_tab4:
        st.markdown("#### üìä An√°lise Comparativa de Efici√™ncia")
        
        # Compara efici√™ncia por unidade
        if (df_atend_todos is not None and df_laudos_todos is not None and
            "unidade" in df_atend_todos.columns and "unidade" in df_laudos_todos.columns):
            
            atend_por_unidade = (
                df_atend_todos
                .groupby("unidade")["quantidade"]
                .sum()
                .reset_index()
                .rename(columns={"quantidade": "Atendimentos"})
            )
            
            laudos_por_unidade = (
                df_laudos_todos
                .groupby("unidade")["quantidade"]
                .sum()
                .reset_index()
                .rename(columns={"quantidade": "Laudos"})
            )
            
            eficiencia_data = pd.merge(
                atend_por_unidade,
                laudos_por_unidade,
                on="unidade",
                how="inner"
            )
            
            if not eficiencia_data.empty:
                eficiencia_data["Taxa_Conversao"] = (
                    eficiencia_data["Laudos"] / eficiencia_data["Atendimentos"] * 100
                )
                eficiencia_data = eficiencia_data.sort_values("Taxa_Conversao", ascending=False)
                
                fig_eficiencia = px.scatter(
                    eficiencia_data.head(20),
                    x="Atendimentos",
                    y="Laudos",
                    size="Taxa_Conversao",
                    hover_name="unidade",
                    title="Efici√™ncia por Unidade (Atendimentos vs Laudos)",
                    color="Taxa_Conversao",
                    color_continuous_scale="RdYlGn"
                )
                
                fig_eficiencia.update_layout(height=500)
                st.plotly_chart(fig_eficiencia, use_container_width=True)
                
                # Top 10 mais eficientes
                st.markdown("**ü•á Top 10 Unidades Mais Eficientes:**")
                top_eficientes = eficiencia_data.head(10)[["unidade", "Taxa_Conversao", "Atendimentos", "Laudos"]]
                st.dataframe(top_eficientes, use_container_width=True)

# ============ ABA 4: PEND√äNCIAS ============
with tab4:
    st.subheader("‚è∞ Gest√£o de Pend√™ncias")
    
    def calculate_aging_analysis(df: pd.DataFrame, date_column: str = "data_base") -> Tuple[pd.DataFrame, pd.Series, Dict]:
        """Calcula aging das pend√™ncias com an√°lises detalhadas."""
        if df is None or df.empty:
            return pd.DataFrame(), pd.Series(dtype="int64"), {}
        
        # Busca coluna de data v√°lida
        available_date_columns = [col for col in df.columns if "data" in col.lower()]
        if date_column not in df.columns and available_date_columns:
            date_column = available_date_columns[0]
        
        if date_column not in df.columns:
            return df, pd.Series(dtype="int64"), {}
        
        result = df.copy()
        dates = pd.to_datetime(result[date_column], errors="coerce")
        
        if dates.isna().all():
            return df, pd.Series(dtype="int64"), {}
        
        hoje = pd.Timestamp.now().normalize()
        dias_pendentes = (hoje - dates).dt.days
        
        # Categorias de aging mais detalhadas
        faixas_aging = pd.cut(
            dias_pendentes,
            bins=[-1, 15, 30, 60, 90, 180, 365, float('inf')],
            labels=["0-15 dias", "16-30 dias", "31-60 dias", 
                   "61-90 dias", "91-180 dias", "181-365 dias", "> 365 dias"]
        )
        
        result["dias_pendentes"] = dias_pendentes
        result["faixa_aging"] = faixas_aging
        
        # Cria categoria de prioridade
        result["prioridade"] = pd.cut(
            dias_pendentes,
            bins=[-1, 30, 90, 180, float('inf')],
            labels=["Normal", "Aten√ß√£o", "Urgente", "Cr√≠tico"]
        )
        
        distribuicao = faixas_aging.value_counts().sort_index()
        
        # Estat√≠sticas adicionais
        stats = {
            "total": len(result),
            "media_dias": dias_pendentes.mean(),
            "mediana_dias": dias_pendentes.median(),
            "max_dias": dias_pendentes.max(),
            "criticos": len(result[result["prioridade"] == "Cr√≠tico"]),
            "urgentes": len(result[result["prioridade"] == "Urgente"])
        }
        
        return result, distribuicao, stats
    
    # An√°lise de Laudos Pendentes
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìÑ Laudos Pendentes")
        
        if df_pend_laudos is not None and not df_pend_laudos.empty:
            laudos_aged, dist_laudos, stats_laudos = calculate_aging_analysis(df_pend_laudos)
            
            # M√©tricas principais
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("Total", format_number(stats_laudos.get("total", 0)))
            with col_b:
                st.metric("Cr√≠ticos", stats_laudos.get("criticos", 0))
            with col_c:
                st.metric("M√©dia (dias)", format_number(stats_laudos.get("media_dias", 0), 1))
            
            # Gr√°fico de distribui√ß√£o por aging
            if not dist_laudos.empty:
                fig_aging_laudos = px.bar(
                    x=dist_laudos.index,
                    y=dist_laudos.values,
                    title="Distribui√ß√£o por Tempo de Pend√™ncia",
                    color=dist_laudos.values,
                    color_continuous_scale="Reds",
                    text=dist_laudos.values
                )
                fig_aging_laudos.update_traces(texttemplate='%{text}', textposition='outside')
                fig_aging_laudos.update_layout(
                    height=350,
                    showlegend=False,
                    xaxis_title="Faixa de Dias",
                    yaxis_title="Quantidade"
                )
                st.plotly_chart(fig_aging_laudos, use_container_width=True)
            
            # Gr√°fico de prioridades
            if "prioridade" in laudos_aged.columns:
                prioridade_dist = laudos_aged["prioridade"].value_counts()
                
                fig_prioridade = px.pie(
                    values=prioridade_dist.values,
                    names=prioridade_dist.index,
                    title="Distribui√ß√£o por Prioridade",
                    color_discrete_map={
                        "Normal": "green",
                        "Aten√ß√£o": "yellow", 
                        "Urgente": "orange",
                        "Cr√≠tico": "red"
                    }
                )
                fig_prioridade.update_layout(height=300)
                st.plotly_chart(fig_prioridade, use_container_width=True)
            
            # Top pend√™ncias mais antigas
            st.markdown("**üî¥ Top 10 Mais Antigas:**")
            if "dias_pendentes" in laudos_aged.columns:
                oldest = (
                    laudos_aged
                    .nlargest(10, "dias_pendentes")
                    [["id", "unidade", "tipo", "dias_pendentes", "prioridade"]]
                    if all(col in laudos_aged.columns for col in ["id", "unidade", "tipo"])
                    else laudos_aged.nlargest(10, "dias_pendentes")
                )
                st.dataframe(oldest, use_container_width=True, height=250)
        else:
            st.info("Sem dados de laudos pendentes dispon√≠veis.")
    
    with col2:
        st.markdown("#### üî¨ Exames Pendentes")
        
        if df_pend_exames is not None and not df_pend_exames.empty:
            exames_aged, dist_exames, stats_exames = calculate_aging_analysis(df_pend_exames)
            
            # M√©tricas principais
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("Total", format_number(stats_exames.get("total", 0)))
            with col_b:
                st.metric("Cr√≠ticos", stats_exames.get("criticos", 0))
            with col_c:
                st.metric("M√©dia (dias)", format_number(stats_exames.get("media_dias", 0), 1))
            
            # Gr√°fico de distribui√ß√£o por aging
            if not dist_exames.empty:
                fig_aging_exames = px.bar(
                    x=dist_exames.index,
                    y=dist_exames.values,
                    title="Distribui√ß√£o por Tempo de Pend√™ncia",
                    color=dist_exames.values,
                    color_continuous_scale="Oranges",
                    text=dist_exames.values
                )
                fig_aging_exames.update_traces(texttemplate='%{text}', textposition='outside')
                fig_aging_exames.update_layout(
                    height=350,
                    showlegend=False,
                    xaxis_title="Faixa de Dias",
                    yaxis_title="Quantidade"
                )
                st.plotly_chart(fig_aging_exames, use_container_width=True)
            
            # Gr√°fico de prioridades
            if "prioridade" in exames_aged.columns:
                prioridade_dist = exames_aged["prioridade"].value_counts()
                
                fig_prioridade = px.pie(
                    values=prioridade_dist.values,
                    names=prioridade_dist.index,
                    title="Distribui√ß√£o por Prioridade",
                    color_discrete_map={
                        "Normal": "green",
                        "Aten√ß√£o": "yellow",
                        "Urgente": "orange", 
                        "Cr√≠tico": "red"
                    }
                )
                fig_prioridade.update_layout(height=300)
                st.plotly_chart(fig_prioridade, use_container_width=True)
            
            # Top pend√™ncias mais antigas
            st.markdown("**üî¥ Top 10 Mais Antigas:**")
            if "dias_pendentes" in exames_aged.columns:
                oldest = (
                    exames_aged
                    .nlargest(10, "dias_pendentes")
                    [["id", "unidade", "tipo", "dias_pendentes", "prioridade"]]
                    if all(col in exames_aged.columns for col in ["id", "unidade", "tipo"])
                    else exames_aged.nlargest(10, "dias_pendentes")
                )
                st.dataframe(oldest, use_container_width=True, height=250)
        else:
            st.info("Sem dados de exames pendentes dispon√≠veis.")
    
    # An√°lise consolidada por unidade
    st.markdown("#### üè¢ An√°lise de Pend√™ncias por Unidade")
    
    pendencias_por_unidade = []
    
    # Processa laudos pendentes
    if df_pend_laudos is not None and "unidade" in df_pend_laudos.columns:
        laudos_unidade = (
            df_pend_laudos.groupby("unidade")
            .agg({
                "quantidade": "count" if "quantidade" in df_pend_laudos.columns else lambda x: len(x)
            })
            .rename(columns={"quantidade": "Laudos_Pendentes"})
            .reset_index()
        )
        if "Laudos_Pendentes" not in laudos_unidade.columns:
            laudos_unidade["Laudos_Pendentes"] = df_pend_laudos.groupby("unidade").size().values
        pendencias_por_unidade.append(laudos_unidade)
    
    # Processa exames pendentes
    if df_pend_exames is not None and "unidade" in df_pend_exames.columns:
        exames_unidade = (
            df_pend_exames.groupby("unidade")
            .agg({
                "quantidade": "count" if "quantidade" in df_pend_exames.columns else lambda x: len(x)
            })
            .rename(columns={"quantidade": "Exames_Pendentes"})
            .reset_index()
        )
        if "Exames_Pendentes" not in exames_unidade.columns:
            exames_unidade["Exames_Pendentes"] = df_pend_exames.groupby("unidade").size().values
        pendencias_por_unidade.append(exames_unidade)
    
    if pendencias_por_unidade:
        from functools import reduce
        
        pendencias_consolidadas = reduce(
            lambda left, right: pd.merge(left, right, on="unidade", how="outer"),
            pendencias_por_unidade
        ).fillna(0)
        
        pendencias_consolidadas["Total_Pendencias"] = (
            pendencias_consolidadas.get("Laudos_Pendentes", 0) + 
            pendencias_consolidadas.get("Exames_Pendentes", 0)
        )
        
        pendencias_consolidadas = pendencias_consolidadas.sort_values("Total_Pendencias", ascending=False)
        
        # Gr√°fico de barras empilhadas
        fig_pendencias = go.Figure()
        
        if "Laudos_Pendentes" in pendencias_consolidadas.columns:
            fig_pendencias.add_trace(go.Bar(
                name='Laudos Pendentes',
                y=pendencias_consolidadas["unidade"].head(15),
                x=pendencias_consolidadas["Laudos_Pendentes"].head(15),
                orientation='h',
                marker_color='lightcoral'
            ))
        
        if "Exames_Pendentes" in pendencias_consolidadas.columns:
            fig_pendencias.add_trace(go.Bar(
                name='Exames Pendentes',
                y=pendencias_consolidadas["unidade"].head(15),
                x=pendencias_consolidadas["Exames_Pendentes"].head(15),
                orientation='h',
                marker_color='lightsalmon'
            ))
        
        fig_pendencias.update_layout(
            title="Top 15 Unidades com Mais Pend√™ncias",
            barmode='stack',
            height=500,
            xaxis_title="Quantidade de Pend√™ncias",
            yaxis={'categoryorder': 'total ascending'}
        )
        
        st.plotly_chart(fig_pendencias, use_container_width=True)
        
        # Tabela de detalhes
        st.markdown("**üìä Detalhamento por Unidade:**")
        st.dataframe(
            pendencias_consolidadas.head(20),
            use_container_width=True,
            height=300
        )

# ============ ABA 5: DADOS ============
with tab5:
    st.subheader("üìã Explora√ß√£o dos Dados")
    
    # Resumo geral dos datasets
    st.markdown("#### üìä Resumo dos Datasets Carregados")
    
    data_summary = []
    for name, df in standardized_dfs.items():
        if df is not None and not df.empty:
            periodo_info = "Sem dados temporais"
            if 'anom√™s' in df.columns and not df['anom√™s'].isna().all():
                min_periodo = df['anom√™s'].min()
                max_periodo = df['anom√™s'].max()
                periodo_info = f"{min_periodo} a {max_periodo}"
            
            data_summary.append({
                "Dataset": name.replace("_", " ").title(),
                "Registros": f"{len(df):,}".replace(",", "."),
                "Colunas": len(df.columns),
                "Per√≠odo": periodo_info,
                "Tamanho (MB)": round(df.memory_usage(deep=True).sum() / 1024 / 1024, 2),
                "Status": "‚úÖ Carregado"
            })
    
    if data_summary:
        summary_df = pd.DataFrame(data_summary)
        st.dataframe(summary_df, use_container_width=True)
        
        # Estat√≠sticas gerais
        total_registros = sum(int(row["Registros"].replace(".", "")) for row in data_summary)
        total_tamanho = sum(row["Tamanho (MB)"] for row in data_summary)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total de Registros", f"{total_registros:,}".replace(",", "."))
        with col2:
            st.metric("Datasets Carregados", len(data_summary))
        with col3:
            st.metric("Tamanho Total (MB)", f"{total_tamanho:.1f}")
        with col4:
            avg_size = total_tamanho / len(data_summary) if data_summary else 0
            st.metric("Tamanho M√©dio (MB)", f"{avg_size:.1f}")
    
    st.markdown("#### üîç Explora√ß√£o Detalhada")
    
    # Seletor de dataset
    available_datasets = [name for name, df in standardized_dfs.items() if df is not None]
    
    if available_datasets:
        selected_dataset = st.selectbox(
            "Selecione o dataset para explorar:",
            available_datasets,
            format_func=lambda x: x.replace("_", " ").title(),
            help="Escolha qual conjunto de dados deseja analisar em detalhes"
        )
        
        if selected_dataset:
            df_selected = standardized_dfs[selected_dataset]
            
            # Informa√ß√µes b√°sicas do dataset
            st.markdown(f"#### üìÑ {selected_dataset.replace('_', ' ').title()}")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Registros", f"{len(df_selected):,}".replace(",", "."))
            with col2:
                st.metric("Colunas", len(df_selected.columns))
            with col3:
                valores_nulos = df_selected.isnull().sum().sum()
                st.metric("Valores Nulos", f"{valores_nulos:,}".replace(",", "."))
            with col4:
                if 'anom√™s_dt' in df_selected.columns:
                    unique_months = df_selected['anom√™s_dt'].nunique()
                    st.metric("Meses √önicos", unique_months)
                else:
                    st.metric("Per√≠odo", "N/A")
            
            # An√°lise de qualidade dos dados
            with st.expander("üîç An√°lise de Qualidade dos Dados", expanded=False):
                quality_info = []
                
                for col in df_selected.columns:
                    dtype = str(df_selected[col].dtype)
                    null_count = df_selected[col].isnull().sum()
                    null_percent = (null_count / len(df_selected)) * 100
                    unique_count = df_selected[col].nunique()
                    
                    # Determina qualidade da coluna
                    if null_percent == 0:
                        quality = "üü¢ Excelente"
                    elif null_percent < 5:
                        quality = "üü° Boa"
                    elif null_percent < 20:
                        quality = "üü† Regular"
                    else:
                        quality = "üî¥ Ruim"
                    
                    quality_info.append({
                        "Coluna": col,
                        "Tipo": dtype,
                        "Nulos": f"{null_count:,}".replace(",", "."),
                        "% Nulos": f"{null_percent:.1f}%",
                        "√önicos": f"{unique_count:,}".replace(",", "."),
                        "Qualidade": quality
                    })
                
                quality_df = pd.DataFrame(quality_info)
                st.dataframe(quality_df, use_container_width=True)
            
            # Filtros para visualiza√ß√£o
            st.markdown("**üéõÔ∏è Controles de Visualiza√ß√£o:**")
            
            viz_col1, viz_col2, viz_col3 = st.columns(3)
            
            with viz_col1:
                max_rows = st.number_input(
                    "M√°ximo de linhas:",
                    min_value=10,
                    max_value=5000,
                    value=500,
                    step=50,
                    help="N√∫mero m√°ximo de linhas a exibir"
                )
            
            with viz_col2:
                if 'anom√™s' in df_selected.columns:
                    available_months = sorted(df_selected['anom√™s'].dropna().unique(), reverse=True)
                    selected_months = st.multiselect(
                        "Filtrar por per√≠odo:",
                        available_months,
                        default=available_months[:6] if len(available_months) > 6 else available_months,
                        help="Selecione os meses para an√°lise"
                    )
                else:
                    selected_months = []
            
            with viz_col3:
                # Filtro por colunas
                all_columns = list(df_selected.columns)
                selected_columns = st.multiselect(
                    "Colunas a exibir:",
                    all_columns,
                    default=all_columns[:10] if len(all_columns) > 10 else all_columns,
                    help="Selecione as colunas para visualiza√ß√£o"
                )
            
            # Aplica filtros
            df_display = df_selected.copy()
            
            if selected_months and 'anom√™s' in df_display.columns:
                df_display = df_display[df_display['anom√™s'].isin(selected_months)]
            
            if selected_columns:
                df_display = df_display[selected_columns]
            
            df_display = df_display.head(max_rows)
            
            # Estat√≠sticas descritivas
            if not df_display.empty:
                st.markdown("**üìà Estat√≠sticas Descritivas:**")
                
                # Apenas colunas num√©ricas
                numeric_cols = df_display.select_dtypes(include=[np.number]).columns
                
                if len(numeric_cols) > 0:
                    stats = df_display[numeric_cols].describe().round(2)
                    st.dataframe(stats, use_container_width=True)
                else:
                    st.info("Nenhuma coluna num√©rica encontrada para estat√≠sticas.")
            
            # Exibe os dados
            st.markdown(f"**üìã Dados Filtrados ({len(df_display):,} de {len(df_selected):,} registros):**".replace(",", "."))
            st.dataframe(
                df_display,
                use_container_width=True,
                height=400
            )
            
            # Op√ß√µes de download
            col_down1, col_down2 = st.columns(2)
            
            with col_down1:
                # Download dos dados filtrados
                csv_data = df_display.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• Download Dados Filtrados (CSV)",
                    data=csv_data,
                    file_name=f"{selected_dataset}_filtrado_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    help="Baixa apenas os dados atualmente vis√≠veis"
                )
            
            with col_down2:
                # Download do dataset completo
                csv_complete = df_selected.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• Download Dataset Completo (CSV)",
                    data=csv_complete,
                    file_name=f"{selected_dataset}_completo_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    help="Baixa o dataset completo sem filtros"
                )

# ============ ABA 6: RELAT√ìRIOS ============
with tab6:
    st.subheader("üìë Relat√≥rios Executivos")
    
    # Seletor de tipo de relat√≥rio
    tipo_relatorio = st.selectbox(
        "Tipo de Relat√≥rio:",
        [
            "Relat√≥rio Executivo Completo",
            "Relat√≥rio de Produ√ß√£o",
            "Relat√≥rio de Pend√™ncias", 
            "Relat√≥rio de Performance",
            "Relat√≥rio Comparativo"
        ],
        help="Escolha o tipo de relat√≥rio que deseja gerar"
    )
    
    # Fun√ß√£o para gerar relat√≥rios
    def gerar_relatorio_executivo() -> str:
        """Gera relat√≥rio executivo completo."""
        timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        
        relatorio = f"""
# RELAT√ìRIO EXECUTIVO PCI/SC
**Data de Gera√ß√£o:** {timestamp}
**Per√≠odo de An√°lise:** {filter_periodo}

## üìä RESUMO EXECUTIVO

### Indicadores Principais
- **Atendimentos Totais:** {format_number(total_atendimentos)}
- **Laudos Emitidos:** {format_number(total_laudos)}
- **Taxa de Convers√£o:** {format_number(taxa_atendimento, 1) if taxa_atendimento else 'N/A'}%
- **Produtividade Mensal:** {format_number(media_mensal_laudos, 1) if media_mensal_laudos else 'N/A'} laudos/m√™s

### Gest√£o de Pend√™ncias
- **Laudos Pendentes:** {format_number(total_pend_laudos)}
- **Exames Pendentes:** {format_number(total_pend_exames)}
- **Backlog Estimado:** {format_number(backlog_meses, 1) if backlog_meses else 'N/A'} meses
- **Aging M√©dio:** {format_number(aging_laudos_medio or aging_exames_medio, 0) if (aging_laudos_medio or aging_exames_medio) else 'N/A'} dias

### Performance Operacional
- **TME Mediano:** {format_number(tme_mediano, 1) if tme_mediano else 'N/A'} dias
- **SLA 30 dias:** {format_number(sla_30_percent, 1) if sla_30_percent else 'N/A'}%
- **SLA 60 dias:** {format_number(sla_60_percent, 1) if sla_60_percent else 'N/A'}%

## üìà AN√ÅLISE DE TEND√äNCIAS
"""
        
        # Adiciona an√°lise de crescimento
        if crescimento_laudos is not None:
            if crescimento_laudos > 5:
                relatorio += f"- **Crescimento Positivo:** Laudos cresceram {format_number(crescimento_laudos, 1)}% no per√≠odo\n"
            elif crescimento_laudos < -5:
                relatorio += f"- **Alerta:** Laudos decresceram {format_number(abs(crescimento_laudos), 1)}% no per√≠odo\n"
            else:
                relatorio += f"- **Estabilidade:** Varia√ß√£o de {format_number(crescimento_laudos, 1)}% nos laudos\n"
        
        # Adiciona alertas
        relatorio += "\n## üö® ALERTAS E RECOMENDA√á√ïES\n"
        
        alertas_relatorio = []
        
        if backlog_meses and backlog_meses > 6:
            alertas_relatorio.append("üî¥ **CR√çTICO:** Backlog superior a 6 meses - necess√°rio plano de a√ß√£o imediato")
        elif backlog_meses and backlog_meses > 3:
            alertas_relatorio.append("üü° **ATEN√á√ÉO:** Backlog entre 3-6 meses - monitorar tend√™ncia")
        
        if sla_30_percent and sla_30_percent < 70:
            alertas_relatorio.append("üî¥ **CR√çTICO:** SLA 30 dias abaixo de 70% - revisar processos")
        
        if taxa_atendimento and taxa_atendimento < 50:
            alertas_relatorio.append("üü° **ATEN√á√ÉO:** Taxa de convers√£o baixa - analisar gargalos")
        
        if alertas_relatorio:
            relatorio += "\n".join(alertas_relatorio)
        else:
            relatorio += "‚úÖ **Situa√ß√£o Normal:** Todos os indicadores dentro dos par√¢metros esperados"
        
        relatorio += f"""

## üìã DATASETS UTILIZADOS
"""
        
        for name, df in standardized_dfs.items():
            if df is not None and not df.empty:
                relatorio += f"- **{name.replace('_', ' ').title()}:** {len(df):,} registros\n"
        
        relatorio += f"""

---
*Relat√≥rio gerado automaticamente pelo Dashboard PCI/SC*
*Sistema de Monitoramento de Produ√ß√£o e Pend√™ncias*
        """
        
        return relatorio.strip()
    
    # Gera relat√≥rio baseado na sele√ß√£o
    if tipo_relatorio == "Relat√≥rio Executivo Completo":
        relatorio_texto = gerar_relatorio_executivo()
        
        st.markdown("#### üìÑ Visualiza√ß√£o do Relat√≥rio")
        st.markdown(relatorio_texto)
        
        # Download do relat√≥rio
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            label="üì• Download Relat√≥rio Executivo",
            data=relatorio_texto.encode('utf-8'),
            file_name=f"relatorio_executivo_pci_sc_{timestamp}.md",
            mime="text/markdown",
            help="Baixa o relat√≥rio em formato Markdown"
        )
    
    elif tipo_relatorio == "Relat√≥rio de Produ√ß√£o":
        st.markdown("#### üìä Relat√≥rio de Produ√ß√£o")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**M√©tricas de Produ√ß√£o:**")
            if df_laudos_todos is not None:
                prod_mensal = (
                    df_laudos_todos
                    .groupby("anom√™s")["quantidade"]
                    .sum()
                    .reset_index()
                    .sort_values("anom√™s")
                )
                
                st.line_chart(
                    prod_mensal.set_index("anom√™s")["quantidade"],
                    height=300
                )
        
        with col2:
            st.markdown("**Top Produtores:**")
            if df_laudos_todos is not None and "unidade" in df_laudos_todos.columns:
                top_unidades = (
                    df_laudos_todos
                    .groupby("unidade")["quantidade"]
                    .sum()
                    .sort_values(ascending=False)
                    .head(10)
                )
                
                st.bar_chart(top_unidades, height=300)
    
    # Continua com outros tipos de relat√≥rio...
    else:
        st.info(f"Relat√≥rio '{tipo_relatorio}' em desenvolvimento.")

# ============ RODAP√â ============
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 14px; padding: 20px;'>
    <p><strong>Dashboard PCI/SC v2.0</strong> - Sistema Avan√ßado de Monitoramento</p>
    <p>üìä Produ√ß√£o ‚Ä¢ ‚è∞ Pend√™ncias ‚Ä¢ üìà Performance ‚Ä¢ üìã Gest√£o</p>
    <p>Para suporte t√©cnico ou sugest√µes: <strong>equipe-ti@pci.sc.gov.br</strong></p>
    <p><em>√öltima atualiza√ß√£o: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}</em></p>
</div>
""", unsafe_allow_html=True)

# ============ ABA 4: PEND√äNCIAS ============
with tab4:
    st.subheader("‚è∞ An√°lise de Pend√™ncias")
    
    def calculate_aging(df: pd.DataFrame, date_column: str = "data_base") -> Tuple[pd.DataFrame, pd.Series]:
        """Calcula aging das pend√™ncias."""
        if df is None or df.empty:
            return pd.DataFrame(), pd.Series(dtype="int64")
        
        # Usa data_base se dispon√≠vel, sen√£o procura outras colunas de data
        if date_column not in df.columns:
            date_columns = [col for col in df.columns if "data" in col.lower()]
            if date_columns:
                date_column = date_columns[0]
            else:
                return df, pd.Series(dtype="int64")
        
        result = df.copy()
        dates = pd.to_datetime(result[date_column], errors="coerce")
        
        if dates.isna().all():
            return df, pd.Series(dtype="int64")
        
        hoje = pd.Timestamp.now().normalize()
        dias_pendentes = (hoje - dates).dt.days
        
        # Categorias de aging
        faixas_aging = pd.cut(
            dias_pendentes,
            bins=[-1, 30, 60, 90, 180, 365, float('inf')],
            labels=["0-30 dias", "31-60 dias", "61-90 dias", 
                   "91-180 dias", "181-365 dias", "> 365 dias"]
        )
        
        result["dias_pendentes"] = dias_pendentes
        result["faixa_aging"] = faixas_aging
        
        distribuicao = faixas_aging.value_counts().sort_index()
        
        return result, distribuicao
    
    col1, col2 = st.columns(2)
    
    # An√°lise de Laudos Pendentes
    with col1:
        st.markdown("#### üìÑ Laudos Pendentes")
        
        if df_pend_laudos is not None and not df_pend_laudos.empty:
            laudos_aged, dist_laudos = calculate_aging(df_pend_laudos)
            
            # Gr√°fico de distribui√ß√£o de aging
            if not dist_laudos.empty:
                fig_aging_laudos = px.bar(
                    x=dist_laudos.index,
                    y=dist_laudos.values,
                    title="Distribui√ß√£o por Tempo de Pend√™ncia",
                    color=dist_laudos.values,
                    color_continuous_scale="Reds"
                )
                fig_aging_laudos.update_layout(
                    height=300,
                    showlegend=False,
                    xaxis_title="Faixa de Dias",
                    yaxis_title="Quantidade"
                )
                st.plotly_chart(fig_aging_laudos, use_container_width=True)
            
            # Tabela resumo
            if "dias_pendentes" in laudos_aged.columns:
                resumo_laudos = {
                    "Total": len(laudos_aged),
                    "M√©dia de dias": laudos_aged["dias_pendentes"].mean(),
                    "Mediana": laudos_aged["dias_pendentes"].median(),
                    "M√°ximo": laudos_aged["dias_pendentes"].max()
                }
                
                for metric, value in resumo_laudos.items():
                    if metric == "Total":
                        st.metric(metric, format_number(value))
                    else:
                        st.metric(f"{metric} (dias)", format_number(value, 1))
            
            # Amostra dos dados
            st.markdown("**Amostra dos Dados:**")
            display_columns = [
                col for col in ["id", "unidade", "diretoria", "tipo", "dias_pendentes", "faixa_aging"]
                if col in laudos_aged.columns
            ]
            st.dataframe(
                laudos_aged[display_columns].head(100),
                use_container_width=True,
                height=250
            )
        else:
            st.info("Sem dados de laudos pendentes dispon√≠veis.")
    
    # An√°lise de Exames Pendentes
    with col2:
        st.markdown("#### üî¨ Exames Pendentes")
        
        if df_pend_exames is not None and not df_pend_exames.empty:
            exames_aged, dist_exames = calculate_aging(df_pend_exames)
            
            # Gr√°fico de distribui√ß√£o de aging
            if not dist_exames.empty:
                fig_aging_exames = px.bar(
                    x=dist_exames.index,
                    y=dist_exames.values,
                    title="Distribui√ß√£o por Tempo de Pend√™ncia",
                    color=dist_exames.values,
                    color_continuous_scale="Oranges"
                )
                fig_aging_exames.update_layout(
                    height=300,
                    showlegend=False,
                    xaxis_title="Faixa de Dias",
                    yaxis_title="Quantidade"
                )
                st.plotly_chart(fig_aging_exames, use_container_width=True)
            
            # Tabela resumo
            if "dias_pendentes" in exames_aged.columns:
                resumo_exames = {
                    "Total": len(exames_aged),
                    "M√©dia de dias": exames_aged["dias_pendentes"].mean(),
                    "Mediana": exames_aged["dias_pendentes"].median(),
                    "M√°ximo": exames_aged["dias_pendentes"].max()
                }
                
                for metric, value in resumo_exames.items():
                    if metric == "Total":
                        st.metric(metric, format_number(value))
                    else:
                        st.metric(f"{metric} (dias)", format_number(value, 1))
            
            # Amostra dos dados
            st.markdown("**Amostra dos Dados:**")
            display_columns = [
                col for col in ["id", "unidade", "diretoria", "tipo", "dias_pendentes", "faixa_aging"] 
                if col in exames_aged.columns
            ]
            st.dataframe(
                exames_aged[display_columns].head(100),
                use_container_width=True,
                height=250
            )
        else:
            st.info("Sem dados de exames pendentes dispon√≠veis.")
    
    # An√°lise consolidada de pend√™ncias por unidade
    st.markdown("#### üè¢ Pend√™ncias por Unidade")
    
    pendencias_consolidadas = []
    
    if df_pend_laudos is not None and "unidade" in df_pend_laudos.columns:
        laudos_por_unidade = (
            df_pend_laudos.groupby("unidade")
            .size()
            .reset_index(name="Laudos_Pendentes")
        )
        pendencias_consolidadas.append(laudos_por_unidade)
    
    if df_pend_exames is not None and "unidade" in df_pend_exames.columns:
        exames_por_unidade = (
            df_pend_exames.groupby("unidade")
            .size()
            .reset_index(name="Exames_Pendentes")
        )
        pendencias_consolidadas.append(exames_por_unidade)
    
    if pendencias_consolidadas:
        from functools import reduce
        
        pendencias_df = reduce(
            lambda left, right: pd.merge(left, right, on="unidade", how="outer"),
            pendencias_consolidadas
        ).fillna(0)
        
        pendencias_df["Total_Pendencias"] = (
            pendencias_df.get("Laudos_Pendentes", 0) + 
            pendencias_df.get("Exames_Pendentes", 0)
        )
        
        pendencias_df = pendencias_df.sort_values("Total_Pendencias", ascending=False)
        
        fig_pendencias = px.bar(
            pendencias_df.head(20),
            x="Total_Pendencias",
            y="unidade",
            orientation="h",
            title="Top 20 Unidades com Mais Pend√™ncias",
            color="Total_Pendencias",
            color_continuous_scale="Reds"
        )
        
        fig_pendencias.update_layout(
            height=600,
            showlegend=False,
            yaxis={"categoryorder": "total ascending"}
        )
        
        st.plotly_chart(fig_pendencias, use_container_width=True)

# ============ ABA 5: DADOS ============
with tab5:
    st.subheader("üìã Explora√ß√£o dos Dados")
    
    st.markdown("#### üìä Resumo dos DataFrames Carregados")
    
    # Tabela resumo dos dados
    data_summary = []
    for name, df in standardized_dfs.items():
        if df is not None and not df.empty:
            data_summary.append({
                "Dataset": name,
                "Registros": len(df),
                "Colunas": len(df.columns),
                "Per√≠odo": (
                    f"{df['anom√™s'].min()} a {df['anom√™s'].max()}"
                    if 'anom√™s' in df.columns and not df['anom√™s'].isna().all()
                    else "Sem dados temporais"
                ),
                "Mem√≥ria (MB)": round(df.memory_usage(deep=True).sum() / 1024 / 1024, 2)
            })
    
    if data_summary:
        summary_df = pd.DataFrame(data_summary)
        st.dataframe(summary_df, use_container_width=True)
    
    st.markdown("#### üîç Visualiza√ß√£o Detalhada")
    
    # Seletor de dataset
    available_datasets = [name for name, df in standardized_dfs.items() if df is not None]
    
    if available_datasets:
        selected_dataset = st.selectbox(
            "Selecione o dataset para visualizar:",
            available_datasets,
            help="Escolha qual conjunto de dados deseja explorar"
        )
        
        if selected_dataset:
            df_selected = standardized_dfs[selected_dataset]
            
            # Informa√ß√µes b√°sicas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Registros", format_number(len(df_selected)))
            with col2:
                st.metric("Colunas", len(df_selected.columns))
            with col3:
                valores_nulos = df_selected.isnull().sum().sum()
                st.metric("Valores Nulos", format_number(valores_nulos))
            with col4:
                if 'anom√™s_dt' in df_selected.columns:
                    unique_months = df_selected['anom√™s_dt'].nunique()
                    st.metric("Meses √önicos", format_number(unique_months))
            
            # Filtros para visualiza√ß√£o
            st.markdown("**Filtros de Visualiza√ß√£o:**")
            
            viz_col1, viz_col2 = st.columns(2)
            
            with viz_col1:
                max_rows = st.number_input(
                    "M√°ximo de linhas a exibir:",
                    min_value=10,
                    max_value=10000,
                    value=500,
                    step=50
                )
            
            with viz_col2:
                if 'anom√™s' in df_selected.columns:
                    available_months = sorted(df_selected['anom√™s'].dropna().unique(), reverse=True)
                    selected_months = st.multiselect(
                        "Filtrar por m√™s:",
                        available_months,
                        default=available_months[:6] if len(available_months) > 6 else available_months
                    )
                else:
                    selected_months = []
            
            # Aplica filtros de visualiza√ß√£o
            df_display = df_selected.copy()
            
            if selected_months and 'anom√™s' in df_display.columns:
                df_display = df_display[df_display['anom√™s'].isin(selected_months)]
            
            # Limita n√∫mero de linhas
            df_display = df_display.head(max_rows)
            
            # Exibe informa√ß√µes das colunas
            with st.expander("üìã Informa√ß√µes das Colunas", expanded=False):
                column_info = []
                for col in df_selected.columns:
                    dtype = str(df_selected[col].dtype)
                    null_count = df_selected[col].isnull().sum()
                    null_percent = (null_count / len(df_selected)) * 100
                    unique_count = df_selected[col].nunique()
                    
                    column_info.append({
                        "Coluna": col,
                        "Tipo": dtype,
                        "Nulos": null_count,
                        "% Nulos": round(null_percent, 2),
                        "√önicos": unique_count
                    })
                
                column_df = pd.DataFrame(column_info)
                st.dataframe(column_df, use_container_width=True)
            
            # Exibe os dados
            st.markdown(f"**Dados ({len(df_display)} de {len(df_selected)} registros):**")
            st.dataframe(
                df_display,
                use_container_width=True,
                height=400
            )
            
            # Op√ß√£o de download
            csv_data = df_display.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Download dos dados filtrados (CSV)",
                data=csv_data,
                file_name=f"{selected_dataset}_filtrado.csv",
                mime="text/csv"
            )

# ============ ABA 6: RELAT√ìRIOS ============
with tab6:
    st.subheader("üìë Relat√≥rios Executivos")
    
    st.markdown("#### üìà Resumo Executivo")
    
    # Gera relat√≥rio executivo autom√°tico
    relatorio_sections = []
    
    # Se√ß√£o 1: Produ√ß√£o
    if total_laudos > 0:
        relatorio_sections.append(f"""
        **üìä PRODU√á√ÉO**
        - Total de laudos emitidos: {format_number(total_laudos)}
        - M√©dia mensal de produ√ß√£o: {format_number(media_mensal_laudos, 1) if media_mensal_laudos else 'N/A'} laudos
        - Taxa de atendimento: {format_number(taxa_atendimento, 1) if taxa_atendimento else 'N/A'}%
        - Crescimento recente: {format_number(crescimento_laudos, 1) if crescimento_laudos else 'N/A'}%
        """)
    
    # Se√ß√£o 2: Pend√™ncias
    if total_pend_laudos > 0 or total_pend_exames > 0:
        relatorio_sections.append(f"""
        **‚è∞ PEND√äNCIAS**
        - Laudos pendentes: {format_number(total_pend_laudos)}
        - Exames pendentes: {format_number(total_pend_exames)}
        - Backlog estimado: {format_number(backlog_meses, 1) if backlog_meses else 'N/A'} meses
        """)
    
    # Se√ß√£o 3: Performance
    if tme_mediano is not None or sla_30_percent is not None:
        relatorio_sections.append(f"""
        **üéØ PERFORMANCE**
        - TME mediano: {format_number(tme_mediano, 1) if tme_mediano else 'N/A'} dias
        - SLA 30 dias: {format_number(sla_30_percent, 1) if sla_30_percent else 'N/A'}%
        - SLA 60 dias: {format_number(sla_60_percent, 1) if sla_60_percent else 'N/A'}%
        """)
    
    # Exibe o relat√≥rio
    if relatorio_sections:
        relatorio_completo = "\n".join(relatorio_sections)
        st.markdown(relatorio_completo)
        
        # Bot√£o para download do relat√≥rio
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        relatorio_txt = f"""
RELAT√ìRIO EXECUTIVO PCI/SC
Data de Gera√ß√£o: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}
Per√≠odo de An√°lise: {filter_periodo}

{relatorio_completo}

---
Dashboard PCI/SC - Sistema de Monitoramento de Produ√ß√£o e Pend√™ncias
        """.strip()
        
        st.download_button(
            label="üì• Download Relat√≥rio Executivo",
            data=relatorio_txt.encode('utf-8'),
            file_name=f"relatorio_executivo_pci_sc_{timestamp}.txt",
            mime="text/plain"
        )
    else:
        st.info("Dados insuficientes para gerar relat√≥rio executivo.")
    
    st.markdown("#### üìä An√°lises Adicionais")
    
    # An√°lise de sazonalidade
    if df_laudos_todos is not None and 'anom√™s_dt' in df_laudos_todos.columns:
        st.markdown("**üìÖ An√°lise de Sazonalidade**")
        
        monthly_production = (
            df_laudos_todos
            .groupby(df_laudos_todos['anom√™s_dt'].dt.month)['quantidade']
            .sum()
            .reset_index()
        )
        monthly_production['mes_nome'] = monthly_production['anom√™s_dt'].map({
            1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Abr', 5: 'Mai', 6: 'Jun',
            7: 'Jul', 8: 'Ago', 9: 'Set', 10: 'Out', 11: 'Nov', 12: 'Dez'
        })
        
        fig_sazonalidade = px.bar(
            monthly_production,
            x='mes_nome',
            y='quantidade',
            title='Produ√ß√£o de Laudos por M√™s (Agregado)',
            color='quantidade',
            color_continuous_scale='Blues'
        )
        
        fig_sazonalidade.update_layout(
            height=400,
            xaxis_title='M√™s',
            yaxis_title='Total de Laudos'
        )
        
        st.plotly_chart(fig_sazonalidade, use_container_width=True)

# ============ RODAP√â ============
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 14px;'>
    <p>Dashboard PCI/SC - Sistema de Monitoramento de Produ√ß√£o e Pend√™ncias</p>
    <p>üìß Para sugest√µes e melhorias, entre em contato com a equipe de TI</p>
</div>
""", unsafe_allow_html=True)
